[ { "title": "AI Certificate for Everyone - Associate", "url": "/posts/Certificate_AICE_ASSOCIATE/", "categories": "Study, L-Certificate", "tags": "certificate, AI, AICE, Associate", "date": "2025-07-12 09:52:42 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "8. 단백질 합성", "url": "/posts/8_Protein_synthesis/", "categories": "Study, L-Molecular_Biology", "tags": "molecular, biology", "date": "2024-06-22 19:02:33 +0900", "snippet": "tRNA와 리보솜 기능_단백질 합성(translation)https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Polypeptidehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_tRNA의 기능https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Wobble 법칙https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Wobble 법칙https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 tRAN의 anticodon과 mRNA의 codon은 base pairing rule을 따르지 않는 경우가 있습니다._Aminoacyl tRNA synthetasehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Ribosomehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634단백질 합성 시작, 신장, 종결_단백질 합성 시작: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 시작: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 시작: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 시작: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 신장: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 신장: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 신장: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 신장: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 신장: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 신장: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 신장: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 신장: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 종결: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 종결: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 종결: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 종결: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 종결: Bacteriahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634세균과 진핵생물 단백질 합성 차이 박테리아에서는 전사와 번역이 couple되어 진행됩니다. 반면에 eukaryote에서는 RNA polymerase와 ribosome이 다른 compartment에서 작용하므로 couple이 불가능합니다._박테리아에서의 전사와 번역 couplinghttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_박테리아에서의 전사와 번역 couplinghttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Polysomehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Polysomehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 시작: eukaryotehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 시작: eukaryotehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 시작: eukaryotehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 시작: eukaryotehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 시작: eukaryotehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 시작: eukaryotehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 시작: eukaryotehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 시작: eukaryotehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 신장: eukaryotehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 합성 종결: eukaryotehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634단백질 합성 조절 및 분해_단백질 합성 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_SECIS elementhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Molecular chaperonehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Post-translational modificationhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Ubiquitylationhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Ub Porteasome Systemhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Protein quality controlhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 응집체에 의한 Ub pool dynamics 파괴https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634" }, { "title": "7. 진핵생물의 전사조절", "url": "/posts/7_Transcription_Regulation_of_Eukaryote/", "categories": "Study, L-Molecular_Biology", "tags": "molecular, biology", "date": "2024-06-22 10:42:02 +0900", "snippet": "진핵세포 전사조절 특징_Eukaryote mRNA 특징https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Eukaryote mRNA 특징https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Histone을 chromatin이 둘러싸고 있을 때는 전사가 억제됩니다. 전사인자가 DNA promoter로 접근할 수 있도록 풀려야 전사가 진행됩니다._Transcription factorhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Insulator에 의한 enhancer 작용 억제https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Enhancer 작용 억제 모델은 두 가지가 제시되었습니다._Enhancer 작용 억제 모델https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Drosophila의 gypsy insulator와 Su(Hw) IBPhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Drosophila의 gypsy insulator와 Su(Hw) IBPhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634NDA 메틸화에 의한 전사 억제 및 X 염색체 불활성화_Insulator의 메틸화https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_메틸화에 의한 유전자 발현 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_메틸화에 의한 유전자 발현 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_메틸화에 의한 genomic imprinting 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_메틸화에 의한 genomic imprinting 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_메틸화에 의한 genomic imprinting 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Egg, Sperm은 DNA 저장, 보존의 목적이 크기 때문에 메틸화가 많이 되어있습니다._발생 과정 중 DNA 메틸화 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_발생 과정 중 DNA 메틸화 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_X 염색체 불활성화https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_X 염색체 불활성화https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Xist RNA에 의한 X 염색체 불활성화https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634RNA 간섭 및 마이크로 RNA RNA 간섭(interference)는 바이러스에 대한 방어 기전에서 유래되었습니다._dsRNA에 의한 gene silencinghttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_dsRNA에 의한 gene silencinghttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_dsRNA에 의한 gene silencinghttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 miRNA에 의한 조절은 발생 과정에 필요한 기전입니다._miRNA에 의한 유전자 발현 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_miRNA에 의한 유전자 발현 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_miRNA에 의한 유전자 발현 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_siRNA vs. miRNAhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Dicer와 Argonaute 구조https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Target mRNA를 인식하는 모델은 두 가지 종류가 있습니다._Two-state modelhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Fixed-end modelhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_RdRP에 의한 신호 증폭https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634진핵생물에서 유전자 가위 활용 유전자 가위는 CRISPR(Clustered Regularly Interspaced Short Palindromic Repeats)로 박테리아의 bacteriophage에 대한 방어 또는 면역 시스템에 필요한 DNA 서열입니다._CRISPRhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_CRISPR-Cas9 시스템의 원리https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_CRISPR-Cas9 시스템의 원리https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_CRISPR-Cas9 시스템의 원리https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_sgRNA 활용https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_CRISPR-Cas9 시스템을 유전자 편집 도구로 활용https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_CRISPR-Cas9 시스템을 유전자 편집 도구로 활용https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_CRISPR-Cas9 시스템을 유전자 편집 도구로 활용https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Cas9 mutant의 활용https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Cas9 mutant의 활용https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_CRISPR-Cas9 시스템의 장단점https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_CRISPR-Cas9 시스템의 미래https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634" }, { "title": "6. 원핵생물의 전사조절", "url": "/posts/6_Transcription_Regulation_of_Prokaryote/", "categories": "Study, L-Molecular_Biology", "tags": "molecular, biology", "date": "2024-06-15 11:02:34 +0900", "snippet": "세균 전령 RNA 특징_Prokaryote mRNA 특징https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Ribosome 결합으로 안정화 되어있지 않은 mRNA는 RNase E에 의해 분해될 수 있습니다._Prokaryote sigma factorhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Riboswitchhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Protein에 의한 riboswitchhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_온도에 의한 riboswitchhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Heat shock sigma factorhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Heat shock sigma factorhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634전사조절의 중요성 및 음양조절_Prokaryote의 전사 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote 음성/양성 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Glucose 레벨에 의한 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Anti-termination에 의한 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Anti-termination에 의한 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634세균 오페론 모델에 대한 이해_Prokaryote 오페론 구성https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote 오페론 종류https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote Tryptophan 오페론https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote Tryptophan 오페론https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote Tryptophan 오페론 attenuationhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote Aribinose 오페론https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote Aribinose 오페론https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote Aribinose 오페론https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634젖당 오페론 모델에 대한 이해_Prokaryote Lactose 오페론https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote Lactose 오페론https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote Lactose 오페론https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote lac 오페론 - 효소의 역할https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote lac 오페론 - 효소의 역할https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote lac 오페론 - 효소의 역할https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote lac 오페론의 inducerhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote glucose에 의한 세포내 lactose 농도 변화https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote lac 오페론 on/offhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634" }, { "title": "5. 유전자 전사와 RNA 가공", "url": "/posts/5_Transcription_and_RNA_preprocessing/", "categories": "Study, L-Molecular_Biology", "tags": "molecular, biology", "date": "2024-06-09 13:22:04 +0900", "snippet": "세균 RNA 중합효소와 전사 시작, 종결, 활성화, 억제 과정_전사 - RNA 합성https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 세포 내에는 다양한 종류의 RNA가 존재합니다._RNA 종류https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Prokaryote 유전자 구조는 polycistronic mRNA로 구성되어 있습니다._Prokaryote 유전자 구조https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote 유전자 구조https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Eukaryote 유전자 구조는 monocistronic mRNA로 구성되어 있습니다. 하나의 mRNA가 한 개의 protein을 암호화 합니다._Eukaryote 유전자 구조https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Eukaryote 유전자 구조https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 전사 시작은 RNA polymerase에 의해 진행됩니다._RNA polymerasehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_RNA polymerasehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 전사 종결은 prokaryote의 경우 Rho-dependent 또는 intrinsic 방식으로 진행됩니다._Prokaryote 전사 종결https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Prokaryote 전사 종결https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 전사 조절은 inducer가 activator에 결합하여 전사를 활성화합니다._Prokaryote 전사 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 또는 inducer가 repressor에 결합하여 전사를 억제합니다._Prokaryote 전사 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634진핵세포 RNA 중합효소와 전사인자_진핵세포 RNA polymerasehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_진핵세포 RNA polymerasehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_진핵세포 RNA polymerase II 결합 부위https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 RNA polymerase II 전사 시작은 PIC(preinitiation complex) 형성부터 시작합니다._RNA polymerase II 전사 시작https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_RNA polymerase II 전사 시작https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_RNA polymerase II 전사 시작https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 전사 신장(transcription elongation)은 다음과 같은 과정으로 진행됩니다._전사 신장https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_전사 신장https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 전사 활성화는 다음과 같은 과정으로 진행됩니다._전사 활성화https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 전사 신장 조절은 다음과 같은 과정으로 진행됩니다._전사 신장 조절https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634RNA 가공 과정1 - 캡, 꼬리_RNA 가공https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Eukaryote에서 rDNA는 tandom repeat으로 이루어져 있으며 necleus 안에 존재합니다._pre-mRNA 가공 (Eukaryote)https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Prokaryote pre-rRNA 특징은 tRNA를 가지고 있다는 점입니다._pre-mRNA 가공 (Prokaryote)https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_tRNA 가공 (Eukaryote)https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_pre-mRNA 가공https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Capping은 mRNA 가공 첫 번째 과정입니다. cap은 mRNA 보호, nuclea export 도움, 번역 활성화 기능을 합니다._Cappinghttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Cappinghttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Poly-A tail은 mRNA 가공 마지막 과정입니다._Poly-A tailhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Poly-A tailhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_전사와 가공의 관계https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634RNA 가공 과정2 - 스플라이싱_RNA splicinghttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_RNA splicinghttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_RNA splicing 기전 - spliceosomehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_RNA splicing 기전 - selfhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_RNA splicing 기전 - spliceosomehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_RNA splicing 기전 - spliceosomehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_RNA splicing 기전 - spliceosomehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_SR 단백질과 ESEhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Alternative splicinghttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Alternative splicinghttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 NMD(Nonsense-mediate mRNA decay)는 EJC보다 upstream에 non-sense variant가 발생하여 생기는 stop codon에 의해 EJC가 제거되지 않게 되어 발생하는 현상입니다._NMDhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_NMDhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_NMDhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634" }, { "title": "4. 돌연변이와 DNA 수선", "url": "/posts/4_DNA-mutation/", "categories": "Study, L-Molecular_Biology", "tags": "molecular, biology", "date": "2024-06-09 09:12:33 +0900", "snippet": "돌연변이(mutation)_돌연변이https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 돌연변이는 다양한 결과를 초래하는데 frameshift mutation으로 갈수록 더 나쁜 결과를 나타냅니다._돌연변이의 다양한 결과https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_염색체 구조 변화 유발 돌연변이https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_염색체 구조 변화 유발 돌연변이https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634돌연변이 유발 원인 염기(base)는 두 가지 화학 구조로 존재할 수 있습니다. 에너지 안정성으로 보면 amino/keto form이 더 안정적입니다._자발적 돌연변이(spontaneous mutation)1https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 이처럼 염기의 화학 구조에 따라 비정상적인 염기쌍을 이룰 수 있으며 자발적 돌연변이를 초래합니다._자발적 돌연변이(spontaneous mutation)1https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_자발적 돌연변이(spontaneous mutation)2https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_자발적 돌연변이(spontaneous mutation)2https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 또한 tandom repeat region에서 DNA polymerase의 미끄러짐으로 인해 DNA mispairing이 발생하고 돌연변이를 유발하는 경우입니다._자발적 돌연변이(spontaneous mutation)3https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_자발적 돌연변이(spontaneous mutation)3https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_자발적 돌연변이(spontaneous mutation)3https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 방사선(radiation)에 의한 돌연변이가 발생할 수 있습니다._방사선(radiation)에 의한 돌연변이https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 자외선(UV)에 의한 돌연변이가 발생할 수 있습니다._자외선(UV)에 의한 돌연변이https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Ethidium과 같은 DNA 삽입제(intercalating agent)에 의해 돌연변이가 발생할 수 있습니다._화학적 돌연변이원https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_화학적 돌연변이원https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_화학적 돌연변이원https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634DNA 수선 기전_DNA repair 필요성https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 DNA mismatch repair(MMR)는 MutSHL 시스템에 의해 작동됩니다. DNA 복제 직후 가닥은 hemi-methylated 되어있는데, 이렇게 새롭게 복제된 가닥을 대상으로 만약 MutS가 mismatch pairing을 인식한다면 아래 과정에 따라 MMR이 진행됩니다._MMRhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_MMRhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Prokaryote에서 Nucleotide excision repair(NER)는 UvrABC 시스템에 의해 작동됩니다._NER in prokaryotehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_NER in prokaryotehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Eukaryote에서 Nucleotide excision repair(NER)는 두 가지 시스템에 의해 작동됩니다. 첫 번째는 global genomic NER 시스템으로 유전자 전사 여부와 상관 없이 전체 유전체를 대상으로 수선합니다._NER in eukaryote - global genomic NERhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 두 번째는 transcription-coupled NER 시스템으로 전사가 활발히 진행되고 있는 유전자를 우선적으로 수선합니다._NER in eukaryote - transcription coupled NERhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Base excision repair(BER)는 prokaryote, eukaryote 모두 잘 보존된 수선 시스템으로 염기만 제거합니다._Base excision repair(BER)https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Base excision repair(BER)https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 UV로 유발된 thymine dimer를 수선하는 방법 중 하나로 광회복(photoreactivation)이 있습니다. 하지만 사람은 진화 과정에서 해당 기능이 사라졌다고 알려져 있습니다._광회복https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_광회복https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 효소(enzyme)의 작용으로 인해 수선하는 방법도 존재합니다._효소(enzyme)에 의한 수선https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 DNA double strand가 모두 잘린 경우 DSBR(DNA double strand break repair)가 이를 수선합니다. 첫 번째는 Non-homologous end joining 방식입니다._DSBR - Non-homologous end joininghttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DSBR - Non-homologous end joininghttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 두 번째는 homologous recombination 방식입니다._DSBR - homologous recombinationhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DSBR - homologous recombinationhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DSBR - homologous recombinationhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 모든 수선 과정을 시도해도 복구할 수 없을 떄 마지막으로 시도할 수 있는 SOS response 방법이 존재합니다._SOS response - E.colihttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_SOS response - E.colihttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 DNA 손상에도 불구하고 TLS(DNA translesion synthesis)에 의해 반대가닥 합성이 가능합니다._TLShttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 Suppressor mutation은 발생한 mutation의 효과를 상쇄하기 위해서 또다른 mutation을 일으키는 방식입니다._Suppressor mutationhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634" }, { "title": "3. DNA 복제", "url": "/posts/3_DNA-replication/", "categories": "Study, L-Molecular_Biology", "tags": "molecular, biology", "date": "2024-06-08 15:04:01 +0900", "snippet": "DNA 복제와 세균 DNA 중합효소_DNA 반보전적 복제https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_replication fork와 replisomehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634박테리아의 DNA 복제_박테리아의 DNA 복제https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634DNA 중합효소 III에 의한 DNA 합성_DNA polymerase IIIhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DNA polymerase IIIhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DNA polymerase IIIhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DNA polymerase IIIhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DNA polymerase IIIhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DNA polymerase IIIhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DNA polymerase IIIhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DNA polymerase IIIhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DNA polymerase IIIhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634세균 DNA 복제_OriC: 세균 DNA 복제의 시작https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_복제된 DNA의 변형: methylationhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Ter sites: 세균 DNA 복제의 종료https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DNA 회전효소 IVhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_박테리아 염색체 복제 이후 세포분열https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_박테리아 염색체 복제 이후 세포분열https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634진핵세포 DNA 복제 과정 및 특징_진핵세포 DNA 복제https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_선형 DNA 복제https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Telomerehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_Telomerasehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_진핵세포 DNA polymerase 특징https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_진핵세포 replisomehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634" }, { "title": "2. DNA 구조와 핵산 기술", "url": "/posts/2_DNA-structure-and-technology/", "categories": "Study, L-Molecular_Biology", "tags": "molecular, biology", "date": "2024-06-08 11:50:41 +0900", "snippet": "유전체 (genome)_유전체 크기https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_진핵생물 genomehttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 사람 genome의 97.5%는 non-coding DNA입니다._진핵생물 genome - exon, intronhttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 사람 genome의 약 50%는 반복서열(repetitive sequence)입니다._진핵생물 genome - 반복서열https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_진핵생물 genome - 직렬반복 DNA1https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_진핵생물 genome - 직렬반복 DNA2https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_진핵생물 genome - 산재반복https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634DNA 및 진핵세포 염색질 구조_DNA 초나선꼬임(supercoil)https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_진핵세초 염색질(chromatin) 구조https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_히스톤 꼬리의 화학적 변형https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_진핵세포 염색체의 packaging 과정https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634핵산 조작 기술_박테리아 제한효소(resriction enzyme)https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_제한효소(resriction enzyme) 명명법, 절단 방법https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DNA 연결효소(ligase)https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_클로닝(cloning)https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_자외선(UV)을 이용한 핵산 농도 측정https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634" }, { "title": "1. DNA, RNA, Protein", "url": "/posts/1_DNA-RNA-Protein/", "categories": "Study, L-Molecular_Biology", "tags": "molecular, biology", "date": "2024-06-08 09:41:02 +0900", "snippet": "원핵생물 (prokaryote)_원핵생물https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 세균(bacteria) 염색법은 세포벽(cell wall)을 염색하는 방식으로 이루어집니다. 염색이 잘되는 그람 양성균과 잘되지 않는 그람 음성균으로 구분합니다._세균(bacteria) 염색법https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_그람 양성균 vs. 그람 음성균https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634진핵생물 (eukaryote)_진핵생물https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 원색생물과 달리 염색체가 선형(linear)입니다. 가장 단순한 구조의 진핵생물은 단세포 진핵생물인 효모(yeast) 입니다. _효모(yeast)https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 다세포 동물 모델(animal model)로는 생쥐(Mus musculus), 사람 세포(HeLa cells) 등이 있습니다._다세포 동물 모델https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634유전학 기초_유전학 기초1https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_유전학 기초2https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634핵산의 화학적 구조_핵산의 화학적 구조https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 뉴클레오타이드는 인산이에스테르 결합으로 연결되어 있습니다. 5’-phosphate group(-P)과 3’-hydroxyl group(-OH)의 결합입니다._뉴클레오타이드 인산이에스테르 결합https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634DNA 이중나선 구조_DNA 이중나선 구조1https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_DNA 이중나선 구조2https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634중심원리(Central Dogma) 중심원리(Central Dogma)는 DNA → RNA → Protein으로 전달되는 세포 내 유전정보의 흐름입니다._Central Dogmahttps://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 전사(transcription)는 DNA → RNA로 유전정보를 전달하는 과정입니다._전사(Transcription)https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 번역(translation)은 mRNA → Protein을 합성하는 과정입니다. 이 때 단백질 합성 기구인 리보솜(ribosome)이 사용됩니다. _번역(Translation)https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634리보솜(ribosome) 구성 요소 리보솜(ribosome)의 S값은 원심분리 했을 때 침강 속도를 의미합니다. 즉, S값이 클수록 원심분리시 침강 속도가 빠름을 의미합니다._리보솜(ribosome) 구성 요소https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634유전암호(genetic code)와 아미노산_유전암호(genetic code)와 아미노산https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_코돈(codon) 읽기https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_리보솜 peptide 사슬 신장https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634아미노산(amino acid)의 기본 구조_아미노산의 기본 구조https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 아미노산 간의 연결은 펩타이드 결합으로 이루어져 있습니다._아미노산 펩타이드 결합https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 1차, 2차 구조https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634_단백질 3차, 4차 구조https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 단백질이 이처럼 복잡한 구조를 가지는 이유 중 하나는, 단백질이 접힘에 따라 에너지가 안정화 되기 때문입니다._단백질 접힘과 안정화https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634 또다른 이유는 단백질이 접힘에 따라 활성부위(active site)가 형성되고 특정 기능을 발휘하기 때문입니다._단백질 접힘과 기능화https://www.kmooc.kr/view/course/detail/7288?tm=20240608201634" }, { "title": "(LAIDD) ADMET 데이터 101", "url": "/posts/Certificate_ADMET/", "categories": "Study, L-Certificate", "tags": "certificate, ADMET, LAIDD", "date": "2024-01-07 11:54:33 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) AI 신약개발시 알아야 할 항암제 개요", "url": "/posts/Certificate_ai_antitumor/", "categories": "Study, L-Certificate", "tags": "certificate, AI, drug, LAIDD", "date": "2024-01-07 09:10:12 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 질환 및 표적 작용 약물", "url": "/posts/Certificate_disease_drug/", "categories": "Study, L-Certificate", "tags": "certificate, disease, drug, LAIDD", "date": "2024-01-07 00:41:40 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 의약품 허가 및 상업용 생산을 위한 기술이전", "url": "/posts/Certificate_certificate_drug/", "categories": "Study, L-Certificate", "tags": "certificate, drug, LAIDD", "date": "2024-01-06 19:03:41 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 인공지능 빅데이터 활용 신약개발 연구동향 및 연구사례", "url": "/posts/Certificate_AI-bigdata-develop-drug/", "categories": "Study, L-Certificate", "tags": "certificate, AI, bigdata, drug, LAIDD", "date": "2024-01-06 15:30:12 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 신약개발전략과 TPP의 이해", "url": "/posts/Certificate_tpp/", "categories": "Study, L-Certificate", "tags": "certificate, TPP, drug, LAIDD", "date": "2024-01-06 13:41:45 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 의약화학 기초", "url": "/posts/Certificate_chemistry/", "categories": "Study, L-Certificate", "tags": "certificate, chemistry, LAIDD", "date": "2024-01-06 11:05:05 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 신약개발과정 개요", "url": "/posts/Certificate_develop_drug/", "categories": "Study, L-Certificate", "tags": "certificate, drug, LAIDD", "date": "2024-01-06 08:03:41 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 파이썬 프로그래밍 기초", "url": "/posts/Certificate_python_programming/", "categories": "Study, L-Certificate", "tags": "certificate, python, LAIDD", "date": "2024-01-01 15:22:10 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 신약타겟 단백질구조결정학", "url": "/posts/Certificate_protein_crystalophy/", "categories": "Study, L-Certificate", "tags": "certificate, protein, drug, LAIDD", "date": "2024-01-01 11:04:52 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 단백질 서열 정렬 알고리즘과 실습", "url": "/posts/Certificate_protein_alignment_algorithm/", "categories": "Study, L-Certificate", "tags": "certificate, alignment, protein, LAIDD", "date": "2023-12-31 14:52:12 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 알파폴드를 이용한 단백질 구조 예측 및 평가", "url": "/posts/Certificate_predict_protein_structure_using_alphafold/", "categories": "Study, L-Certificate", "tags": "certificate, ai, alphafold, protein, LAIDD", "date": "2023-12-31 11:18:42 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 단백질 언어 모델을 활용한 컨텍트 예측", "url": "/posts/Certificate_predict_contact_for_protein/", "categories": "Study, L-Certificate", "tags": "certificate, ai, protein, LAIDD", "date": "2023-12-31 08:05:21 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "ch15. K-Nearest Neighbor", "url": "/posts/ch15_KNN/", "categories": "Study, B-ML_with_Python_Cookbook", "tags": "ml, python, study, KNN, sklearn, model", "date": "2023-12-30 19:05:12 +0900", "snippet": "SummaryKNN 분류기는 지도 학습용 머신러닝 모델에서 가장 간단하지만 널리 사용하는 것 중 하나입니다. KNN은 종종 게으른 학습기로 불립니다. 기술적으로 예측을 만들기 위해 모델을 훈련하지 않기 때문입니다. 대신 가장 가까운 k개의 샘플에서 다수의 클래스를 그 샘플의 클래스로 예측합니다. 샘플의 최근접 이웃 찾기 (15.1) K-최근접 이웃 분류기 만들기 (15.2) 최선의 이웃 개수 결정하기 (15.3) Practice" }, { "title": "ch14. Tree and Random Forest", "url": "/posts/ch14_Tree_and_Random_Forest/", "categories": "Study, B-ML_with_Python_Cookbook", "tags": "ml, python, study, tree, randomforest, sklearn, model", "date": "2023-12-30 16:40:04 +0900", "snippet": "Summary트리 기반 학습 알고리즘은 분류와 회귀에서 모두 인기있고 널리 사용되는 비모수 지도 학습 방법입니다. 결정 트리 분류기 훈련하기 (14.1) 결정 트리 회귀 훈련하기 (14.2) 결정 트리 모델 시각화하기 (14.3) 랜덤 포레스트 분류기 훈련하기 (14.4) 랜덤 포레스트 회귀 훈련하기 (14.5) 랜덤 포레스트에서 중요한 특성 구분하기 (14.6) Practice" }, { "title": "ch13. Linear Regression", "url": "/posts/ch13_Linear_Regression/", "categories": "Study, B-ML_with_Python_Cookbook", "tags": "ml, python, study, linear, regression, sklearn, model", "date": "2023-12-30 13:04:51 +0900", "snippet": "Summary선형 회귀는 가장 간단한 지도 학습 알고리즘 중 하나입니다. 직선 학습하기 (13.1) 교차 특성 다루기 (13.2) 비선형 관계 학습하기 (13.3) 규제로 분산 줄이기 (13.4) 라소 회귀로 특성 줄이기 (13.5) Practice" }, { "title": "ch12. Model Selection", "url": "/posts/ch12_Model_Selection/", "categories": "Study, B-ML_with_Python_Cookbook", "tags": "ml, python, study, sklearn, model", "date": "2023-12-30 10:42:01 +0900", "snippet": "Summary최선의 학습 알고리즘을 선택하는 것와 최선의 하이퍼파라미터를 선택하는 것을 모델 선택이라고 정의합니다. 완전 탐색을 사용해 최선의 모델 선택하기 (12.1) 랜덤 탐색을 사용해 최선의 모델 선택하기 (12.2) 여러 학습 알고리즘에서 최선의 모델 선택하기 (12.3) 전처리와 함께 최선의 모델 선택하기 (12.4) 병렬화로 모델 선택 속도 높이기 (12.5) Practice" }, { "title": "(LAIDD) 신약개발을 위한 단백질 구조 예측 및 상호작용 예측", "url": "/posts/Certificate_predict_protein_structure_for_develop_drug/", "categories": "Study, L-Certificate", "tags": "certificate, drug, ai, protein, LAIDD", "date": "2023-12-30 09:14:05 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 인공지능을 활용한 멀티오믹스 기반 바이오마커 발굴", "url": "/posts/Certificate_predict_biomarker_with_ai/", "categories": "Study, L-Certificate", "tags": "certificate, multiomics, ai, biomarker, LAIDD", "date": "2023-12-29 21:05:52 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 네트워크 기반 멀티오믹스 데이터 통합 실습", "url": "/posts/Certificate_network_based_multiomics/", "categories": "Study, L-Certificate", "tags": "certificate, multiomics, LAIDD", "date": "2023-12-29 19:49:50 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 생물학 and 생물정보학 역량강화 교육과정", "url": "/posts/Certificate_intensive_biology_and_bioinformatics/", "categories": "Study, L-Certificate", "tags": "certificate, biology, bioinformatics, LAIDD", "date": "2023-12-28 22:25:49 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 시스템 생물학을 활용한 신호전달 경로 모델링", "url": "/posts/Certificate_pathway_modeling_with_system_biology/", "categories": "Study, L-Certificate", "tags": "certificate, system, biology, model, LAIDD", "date": "2023-12-28 20:05:22 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 빅데이터를 활용한 비임상시험 동물모델 개발", "url": "/posts/Certificate_animal_model_with_bigdata/", "categories": "Study, L-Certificate", "tags": "certificate, bigdata, animal, model, LAIDD", "date": "2023-12-25 14:42:55 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 기계학습 및 네트워크 구조를 활용한 정밀의학", "url": "/posts/Certificate_ML_and_Precision_Medicine/", "categories": "Study, L-Certificate", "tags": "certificate, ML, precision, medicine, LAIDD", "date": "2023-12-25 11:04:05 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 시스템 생물학", "url": "/posts/Certificate_system_biology/", "categories": "Study, L-Certificate", "tags": "certificate, system, biology, LAIDD", "date": "2023-12-25 08:41:22 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 바이오 네트워크 모델링", "url": "/posts/Certificate_Bio_Network_Modeling/", "categories": "Study, L-Certificate", "tags": "certificate, network, modeling, LAIDD", "date": "2023-12-23 21:04:45 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 바이오 데이터베이스의 활용", "url": "/posts/Certificate_Using_Bio_Databases/", "categories": "Study, L-Certificate", "tags": "certificate, database, LAIDD", "date": "2023-12-23 18:49:40 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 타겟발굴을 위한 유전체 변이분석기술", "url": "/posts/Certificate_Genome_Analysis_for_Target_Discovery/", "categories": "Study, L-Certificate", "tags": "certificate, drug, genome, LAIDD", "date": "2023-12-23 16:04:50 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 신약개발에서의 바이오마커 예측", "url": "/posts/Certificate_Biomarker_Prediction/", "categories": "Study, L-Certificate", "tags": "certificate, drug, biomarker, LAIDD", "date": "2023-12-23 14:51:33 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) Multiomics Analysis", "url": "/posts/Certificate_Multiomics_Analysis/", "categories": "Study, L-Certificate", "tags": "certificate, omics, LAIDD", "date": "2023-12-23 10:11:04 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) 약물-전사체 기반 약물 기전해석 및 신약재창출", "url": "/posts/Certificate_Drug_Transcriptome/", "categories": "Study, L-Certificate", "tags": "certificate, drug, transcriptome, NGS, bioinformatics, LAIDD", "date": "2023-10-16 00:42:12 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) R programming for bioinformatics", "url": "/posts/Certificate_R_programming_for_bioinformatics/", "categories": "Study, L-Certificate", "tags": "certificate, R, NGS, bioinformatics, LAIDD", "date": "2023-10-15 20:04:09 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(LAIDD) Cancer Genome Analysis", "url": "/posts/Certificate_Cancer_Genome_Analysis/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, bioinformatics, LAIDD", "date": "2023-10-15 10:42:05 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "Special Sort Algorithm - Counting Sort", "url": "/posts/Algorithm_Special_Sort_Counting/", "categories": "Programming, Algorithm", "tags": "algorithm, sort, python", "date": "2023-09-27 15:41:02 +0900", "snippet": "계수 정렬계수 정렬은 원소의 배열을 훑어보고 1부터 k까지의 자연수가 각각 몇 번 나타나는지 헤아립니다. 이 정보를 바탕으로 A[1, …, n]의 각 원소가 몇 번째 놓이면 되는지 계산하는 알고리즘 입니다.계수 정렬은 평균 시간 복잡도가 \\(\\theta(n)\\)으로 소요되는 알고리즘 입니다.구현def countingsort(array): size = len(array) output = [0] * size # Initialize count array count = [0] * 10 # Store the count of each elements in count array for i in range(0, size): count[array[i]] += 1 # Store the cummulative count for i in range(1, 10): count[i] += count[i - 1] # Find the index of each element of the original array in count array # place the elements in output array i = size - 1 while i &amp;gt;= 0: output[count[array[i]] - 1] = array[i] count[array[i]] -= 1 i -= 1 # Copy the sorted elements into original array for i in range(0, size): array[i] = output[i] return arraytest_data = [4, 2, 2, 8, 3, 3, 1]print(countingsort(test_data))시간 복잡도계수 정렬은 평균 시간 복잡도가 \\(\\theta(n)\\)입니다. 하지만 k가 O(n)을 초과하면 시간 복잡도는 \\(\\theta(k))\\)를 초과합니다." }, { "title": "Special Sort Algorithm - Radix Sort", "url": "/posts/Algorithm_Special_Sort_Radix/", "categories": "Programming, Algorithm", "tags": "algorithm, sort, python", "date": "2023-09-27 11:50:41 +0900", "snippet": "기수 정렬기수 정렬은 입력이 모두 k 자릿수 이하의 자연수인 특수한 경우(자연수가 아닌 제한된 종류를 가진 알파벳 등도 해당)에 사용할 수 있는 정렬 방법입니다.기수 정렬은 평균 시간 복잡도가 \\(\\theta(n)\\)으로 소요되는 알고리즘 입니다.우선 가장 낮은 자릿수만 가지고 모든 수를 재배열(정렬) 합니다. 그리고 같은 방법으로 더 이상 자릿수가 남지 않을 때까지 반복합니다. 여기서 ‘안정성을 유지하면서 정렬한다’는 사실이 매우 중요한데, 값이 같은 원소끼리는 정렬 후에 원래의 순서가 바뀌지 않는 성질임을 뜻합니다. (stable sort)구현# Counting sort 사용def countingsort(array, place): size = len(array) output = [0] * size count = [0] * 10 # calculate count of elements for i in range(0, size): index = array[i] // place count[index % 10] += 1 # calculate cumulative count for i in range(1, 10): count[i] += count[i-1] # place the elements in sorted order i = size - 1 while i &amp;gt;= 0: index = array[i] // place output[count[index % 10] - 1] = array[i] count[index % 10] -= 1 i -= 1 for i in range(0, size): array[i] = output[i]# radix sort def radixsort(array): # get maximum element max_element = max(array) # apply counting sort to sort elements based on place value place = 1 while max_element // place &amp;gt; 0: countingsort(array, place) place *= 10 return arraytest_data = [842, 9, 4810, 582, 990, 5592, 42]print(radixsort(test_data))시간 복잡도기수 정렬은 평균 시간 복잡도와 최악 시간 복잡도 모두 \\(\\theta(n)\\)으로 빠른 정렬 알고리즘입니다." }, { "title": "Advanced Sort Algorithm - Heap Sort", "url": "/posts/Algorithm_Advanced_Heap_Quick/", "categories": "Programming, Algorithm", "tags": "algorithm, sort, python", "date": "2023-09-23 14:41:02 +0900", "snippet": "힙 정렬힙 정렬은 힙 자료구조를 기반으로 동작하는 알고리즘 입니다.힙 정렬은 평균 시간 복잡도와 최악 시간 복잡도 모두 \\(\\theta(nlogn)\\)으로 빠른 정렬 알고리즘입니다.구현# 힙 구성def heapify(array, n, i): largest = i # root node left = 2 * i + 1 right = 2 * i + 2 # left &amp;gt; root if left &amp;lt; n and array[i] &amp;lt; array[left]: largest = left # right &amp;gt; root or largest child if right &amp;lt; n and array[largest] &amp;lt; array[right]: largest = right if largest != i: array[i], array[largest] = array[largest], array[i] heapify(array, n, largest)# 힙 정렬array = [5, 3, 7, 1, 4, 2, 6, 8]def heap_sort(array): n = len(array) for i in range(n // 2 - 1, -1, -1): heapify(array, n, i) for i in range(n - 1, 0, -1): array[i], array[0] = array[0], array[i] heapify(array, i, 0) return arrayprint(heap_sort(array))시간 복잡도힙 정렬은 평균 시간 복잡도와 최악 시간 복잡도 모두 \\(\\theta(nlogn)\\)으로 빠른 정렬 알고리즘입니다." }, { "title": "Epigenetics VI - 후성유전체 데이터 생산과 분석1", "url": "/posts/Epigenetics6/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, epigenetics", "date": "2023-08-16 07:42:01 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 포항공과대학교 노태영 교수님의 후성유전체 데이터 생산과 분석1를 정리한 내용입니다.Intro 시퀀싱의 원리를 이해합니다. ChIP-Seq 기술을 이해하고 데이터 생산과 분석 과정을 학습합니다. 시퀀싱 기술의 기초Sanger sequencing은 template DNA와 primer, ddNTP, dNTP를 이용하여 서열을 분석하는 방법입니다.Sanger Sequencinghttps://www.edwith.org/epigenome-2023/lecture/1473438최근에는 다양한 NGS platform이 개발되어 서열분석에 사용되고 있습니다. DNA methylation, TF binding regions 분석은 ChIP-Seq을 사용하여 분석할 수 있습니다.ChIP-SeqCell lysis를 통해 chromatin을 얻고 MNase digestion/sonication을 통해 뉴클레오좀 단위로 분해합니다. Immumo-precipitation을 통해 뉴클레오좀만 분리한 뒤 히스톤 단백질 가수분해 효소를 처리하여 DNA를 얻습니다. 이후 library를 생성하고 시퀀싱하여 서열을 분석합니다.ChIP-Seqhttps://www.edwith.org/epigenome-2023/lecture/1473438ChIP-Seq 데이터 분석 파이프라인은 다음과 같습니다. Rawdata를 얻은 뒤 QC를 거쳐 reference genome에 mapping, peak detection을 합니다. 이후 statistical 분석과 functional 분석을 통해 각종 epigenetic 정보를 확인합니다.ChIP-Seq Analysishttps://www.edwith.org/epigenome-2023/lecture/1473438Take Home Message후성유전적 변화에 따른 세포 운명 결정을 알아봤습니다. 발생과 분화 단계의 후성유전적 변화 및 질환에서 발견되는 후성유전적 이상을 알아봤습니다." }, { "title": "Epigenetics V- 세포운명 결정의 후성유전학", "url": "/posts/Epigenetics5/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, epigenetics", "date": "2023-08-15 15:59:21 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 포항공과대학교 노태영 교수님의 세포운명 결정의 후성유전학를 정리한 내용입니다.Intro 후성유전적 변화에 따른 세포 운명 결정을 학습합니다. 발생과 분화 단계의 후성유전적 변화에 대해 학습합니다. 암 후성유전학에 대해 학습합니다. 후성유전적 변형과 유전자 발현일반적으로 transient signal은 primary signal로서 작용하여 스위치를 on 시키고, primary signal이 사라지면 스위치는 다시 off 상태로 바뀝니다.반복적인 recurring signal은 primary signal과 함께 히스톤 modification을 일으킵니다. primary signal이 사라지더라도 히스톤 modification이 marking된 상태로 남아있습니다. (epigenetic memory)Epigenetic program은 recurring signal에 의한 단편적인 epigenetic memory를 넘어서서 chromatin 자체에 변형을 가져오는 remodeling 시스템이 작동하여 전반적인 변형을 일으키는 현상입니다.후성유전적 변형과 유전자 발현 조절 기전https://www.edwith.org/epigenome-2023/lecture/1473437환경의 영향 및 다양한 요인에 의해 세포의 운명과 질병 발병이 결정됩니다.후성유전적 변형과 세포의 운명 결정https://www.edwith.org/epigenome-2023/lecture/1473437분화 단계에서 stem cells의 경우 open chromatin 구조를 보이지만 differentiated cells에서는 dense chromatin 구조를 보입니다. 확연한 차이를 보이는 것을 알 수 있습니다.분화 단계에서 크로마틴 구조의 변화https://www.edwith.org/epigenome-2023/lecture/1473437후성유전적 변형과 암의 관계를 나타내는 그림입니다. 이와 같은 관계를 연구하면서 암 치료제 개발을 위한 연구가 진행되고 있습니다.후성유전적 변형과 암의 관계https://www.edwith.org/epigenome-2023/lecture/1473437암에서 흔히 발견되는 methylation, histone modification은 다음과 같습니다. 이러한 양상을 파악하여 암 바이오마커로서 사용하고 있습니다.암에서 발견되는 후성유전적 변형https://www.edwith.org/epigenome-2023/lecture/1473437암에서 발견되는 후성유전적 변형https://www.edwith.org/epigenome-2023/lecture/1473437동일한 염기서열을 가지고 있더라도 서로 다른 세포로 분화되고 기능할 수 있는 이유는 후성유전학이 있기 때문입니다. 같은 가사라도 어떤 음정을 붙이느냐에 따라 다른 노래가 되는 이치와 같습니다.후성유전학의 역할https://www.edwith.org/epigenome-2023/lecture/1473437Take Home Message후성유전적 변화에 따른 세포 운명 결정을 알아봤습니다. 발생과 분화 단계의 후성유전적 변화 및 질환에서 발견되는 후성유전적 이상을 알아봤습니다." }, { "title": "Epigenetics IV- ncRNA에 의한 전사조절", "url": "/posts/Epigenetics4/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, epigenetics", "date": "2023-08-15 14:24:01 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 포항공과대학교 노태영 교수님의 ncRNA에 의한 전사조절를 정리한 내용입니다.Intro ncRNA의 정의와 종류에 대해 학습합니다. ncRNA의 생성과 기능에 대해 학습합니다. 전사조절과 ncRNA에 대해 학습합니다. ncRNA(non-coding RNA)DNA에서 전사는 되지만 단백질로 번역되지 않는 functional RNA입니다. ncRNA 종류로는 miRNA, siRNA, piRNA, XiRNA, lncRNA 등이 있습니다. ncRNA는 유전자 전사 단계 혹은 그 이후 단계에서 유전자 발현을 조절하는 기능을 가지고 있습니다.ncRNAhttps://www.edwith.org/epigenome-2023/lecture/1473436ncRNA 종류https://www.edwith.org/epigenome-2023/lecture/1473436miRNA는 single strand에서 pre-miRNA가 생성되고 microprocessor와 dicer에 의해 miRNA로 변하면서 RISC 구조로서 target RNA에 붙어 translational repression이나 activation of mRNA를 일으킵니다.반면 siRNA는 bi-directional transcription으로 생성되어 miRNA처럼 RISC 구조로서 작동하거나 RITS 구조로서 siRNA-dependent chromatin modification을 일으킵니다.piRNA는 프로세싱 과정이 명확히 알려져있지 않지만 PIWI 단백질과 구조를 이루어 epigenetic regulation이나 transposon control 작용을 합니다.ncRNA 프로세싱https://www.edwith.org/epigenome-2023/lecture/1473436ncRNA 프로세싱https://www.edwith.org/epigenome-2023/lecture/1473436miRNA의 조절 작용에 영향을 미치는 인자는 여러 가지가 있습니다.ncRNA 조절 작용에 영향을 미치는 인자https://www.edwith.org/epigenome-2023/lecture/1473436lncRNA는 guide, architect, enhancer로서 기능을 수행합니다.lncRNA의 역할https://www.edwith.org/epigenome-2023/lecture/1473436RNA에 의해 유도되는 크로마틴 상태 변화는 아래와 같습니다.RNA에 의해 유도되는 크로마틴 상태 변화https://www.edwith.org/epigenome-2023/lecture/1473436암줄기세포에서의 후성유전적 조절에 대한 그림입니다.암줄기세포에서의 후성유전적 조절https://www.edwith.org/epigenome-2023/lecture/1473436Take Home MessagencRNA의 정의와 종류, 생성과 기능에 대해 알아봤습니다. 암세포에서 후성유전적 조절 기작을 알아봤습니다." }, { "title": "Epigenetics III - 히스톤 변형과 DNA 메틸화", "url": "/posts/Epigenetics3/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, epigenetics", "date": "2023-08-13 10:04:12 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 포항공과대학교 노태영 교수님의 히스톤 변형과 DNA 메틸화를 정리한 내용입니다.Intro 히스톤의 구조와 특징을 학습합니다. 히스톤 변형에 대해 학습합니다. DNA 메틸화의 기능과 역할을 학습합니다. 히스톤 단백질히스톤 단백질은 H1(linker histone), H2A, H2B(core histones), H3, H4 등 다섯 가지 종류로 구성되어 있습니다.히스톤 단백질 종류https://www.edwith.org/epigenome-2023/lecture/1473435히스톤 아세틸화의 역할/기능히스톤의 아세틸화는 N-말단이 멀어지게 하여 크로마틴 구조가 열리도록 역할을 합니다.히스톤 단백질의 아세틸화https://www.edwith.org/epigenome-2023/lecture/1473435히스톤 메틸화의 역할/기능히스톤의 메틸화는 히스톤 단백질의 다양한 부위에 일어나며, transcription regulation과 DNA repair와 연관된 역할을 합니다.히스톤 단백질의 메틸화https://www.edwith.org/epigenome-2023/lecture/1473435히스톤 단백질의 메틸화https://www.edwith.org/epigenome-2023/lecture/1473435DNA 메틸화 효소는 DNMT(DNA Methyltransferase)가 사용됩니다. DNMT마다 서로 다른 기능을 가지고 있습니다.DNMThttps://www.edwith.org/epigenome-2023/lecture/1473435DNMT 기능https://www.edwith.org/epigenome-2023/lecture/1473435Mammalian DNA methylation 과정을 나타낸 그림입니다.Mammalian DNA methylationhttps://www.edwith.org/epigenome-2023/lecture/1473435Cancer에서 나타나는 DNA methylation에 대해 연구가 진행중이며, 이와 관련된 FDA 인증 치료제들이 존재합니다.Epigenetic Drugs for Cancer Therapyhttps://www.edwith.org/epigenome-2023/lecture/1473435Take Home Message히스톤의 구조와 특징에 대해 확인 했습니다. 히스톤 변형과 DNA 메틸화의 기능, 역할을 확인 했습니다." }, { "title": "Epigenetics II - 크로마틴 구조", "url": "/posts/Epigenetics2/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, epigenetics", "date": "2023-08-12 12:40:04 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 포항공과대학교 노태영 교수님의 크로마틴 구조를 정리한 내용입니다.Intro 크로마틴과 크로모좀의 구조를 학습합니다. 뉴클레오좀의 형성과 구조를 학습합니다. 유전체 구조(Genome Structure)Chromosome의 개수는 생물 종의 biological features와 연관이 없습니다. 단적인 예로 yeast는 16개, 초파리는 4개, 사람은 24개의 chromosome을 가진 것을 볼 수 있습니다.크로마틴 연구의 역사1944년 DNA가 유전물질로 밝혀졌습니다.1953년 Watson과 Crick에 의해 DNA의 double-helical 구조가 밝혀졌습니다.1964년 히스톤 단백질 변형과 크로마틴 transcription의 연관성이 밝혀졌습니다.1974년 크로마틴 subunit 모델이 제안되었습니다.1975년 뉴클레오좀이 제안되었습니다.1993년 epigenetic information이 히스톤 tail에 담겨있다는 이론이 나왔습니다.크로마틴 연구의 역사https://www.edwith.org/epigenome-2023/lecture/1473434크로마틴 구조먼저 mammalian cell nucleus의 구조를 살펴봅니다. 세포 내 nucelolus가 있고 주변에 chromosome별로 분리된 영역이 있습니다.Organization of the Mammalian Cell Nucleushttps://www.edwith.org/epigenome-2023/lecture/1473434크로마틴의 구조를 살펴봅니다. Chromosome은 크로마틴 fiber 형태의 구조로 이루어져 있습니다. 이러한 fiber는 히스톤 단백질을 둘러싼 구조로 이루어져 있습니다.Chromatin Structurehttps://www.edwith.org/epigenome-2023/lecture/1473434이를 구조별로 좀 더 상세하게 살펴봅니다.DNA Packaginghttps://www.edwith.org/epigenome-2023/lecture/1473434Chromosome의 존재는 염색법을 통해 확인할 수 있는데, chromosome에 따라 염색되는 패턴이 다르기 떄문입니다.Chromosome Staininghttps://www.edwith.org/epigenome-2023/lecture/1473434Human Karyogramhttps://www.edwith.org/epigenome-2023/lecture/1473434핵 안의 DNA 구조에 대한 전체정리 그림입니다.DNA Packaginghttps://www.edwith.org/epigenome-2023/lecture/1473434이 중 DNA와 nuclear matrix가 접촉하는 부위를 좀 더 자세히 살펴봅니다. 해당부위는 MAR(Matrix-Associated Region) 혹은 SAR(Scaffold Attachment Region)로 부르고, AT-rich region으로 유전자 발현이 잘 되지 않는 영역입니다. 실제로 크로마틴이 highly packaged 영역에서는 새로운 유전자 시퀀스가 삽입되어도 거의 발현되지 않지만, 일반 크로마틴 영역에 삽입되면 유전자 발현이 잘 일어납니다. 이를 ‘Position Effect’라고 합니다.DNA-Nuclear Matrixhttps://www.edwith.org/epigenome-2023/lecture/1473434크로마틴 Packeged vs. Normalhttps://www.edwith.org/epigenome-2023/lecture/1473434뉴클레오좀의 구조를 좀 더 상세히 살펴봅니다.뉴클레오좀 구조https://www.edwith.org/epigenome-2023/lecture/1473434Take Home Message크로마틴과 크로모좀의 구조를 확인했습니다. 뉴클레오좀의 형성과 구조에 대해 확인했습니다." }, { "title": "Epigenetics I - 후성유전학의 개요", "url": "/posts/Epigenetics1/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, epigenetics", "date": "2023-08-09 07:33:05 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 포항공과대학교 노태영 교수님의 후성유전학의 개요를 정리한 내용입니다.Intro 후성유전학의 개념 및 전사 조절 기전을 이해합니다. 후성유전에 의한 세포 운명 결정 현상을 이해합니다. 후성유전체 데이터의 생산 및 기본 분석 방향을 이해합니다. 후성유전학(Epigenetics)이란?후성유전학은 DNA 자체에 생기는 mutation이 아니라 DNA 이외에 변화가 생기는 현상입니다. 즉, histone 단백질, Methylation, ncRNA 등에 변화가 생기는 현상입니다.후성유전학이란?https://www.edwith.org/epigenome-2023/lecture/1473433환경에 의한 개체의 운명이 결정되는 사례는 꿀벌에서 찾아볼 수 있습니다. 여왕벌은 일벌과 동일한 DNA를 가지고 있습니다. 하지만 여왕벌의 수명은 일벌에 비하여 40배나 깁니다. DNA methylaton 과정을 비교해보니 여왕벌은 DNMT3 inhibitor가 activation 되는 차이점을 보였습니다.후성유전적 메모리는 평생가는 기억입니다. 어린 쥐 양육 방식에 따라 성격이 달라지는 사례를 들 수 있습니다. 어렸을 때부터 어미 쥐에게서 보살핌을 받은 쥐는 차분하고 조용한 성격을 가지는 반면, 보살핌을 받지 못한 쥐는 불안 증세를 보입니다. 이는 어린 쥐가 보살핌을 받을 때 GR(Glucocorticoid Receptor)의 크로마틴 구조가 열릴 가능성이 높아지는데, GT은 스트레스 반응을 차단하는데 도움을 주는 것으로 알려져 있습니다. 즉, 보살핌의 여부는 GR의 후성유전학 변화를 불러일으켜 쥐의 성격을 결정하게 됩니다.유전적으로 동일하고 나이도 같지만 생김새가 다른 쥐의 사례도 볼 수 있습니다. 임신한 어미 쥐가 어떤 먹이를 먹느냐에 따라 새끼 쥐의 생김새가 달라집니다. BPA를 섭취한 어미 쥐의 새끼는 비만이면서 노란 색의 털이 나고 콜린, 엽산, 비타민B12를 섭취한 어미 쥐의 새끼는 정상 생김새를 보입니다. 이는 agouti 유전자에 methylation이 발생하면 유전자 발현이 저해되어 노란색 털의 발현을 막습니다. 하지만 methylation이 일어나지 않으면 노란색 털이 발현되고 암이나 당뇨의 발병 가능성이 높아집니다.어미 쥐의 먹이에 따라 달라지는 새끼 쥐의 생김새https://www.edwith.org/epigenome-2023/lecture/1473433후성유전학은 1942년 Conrad Waddington이 처음 사용한 개념입니다. DNA 정보는 변하지 않으면서 DNA 자체 또는 DNA와 결합하고 있는 단백질(히스톤)의 변형에 의하여 유전자의 발현이 조절되는 현상입니다. 세포별, 개체별, 질환별 유전자 발현 차이의 새로운 원인으로 대두되고 있습니다. 동일한 단백질이라 하더라도 어떤 세포, 조직, 개체이느냐에 따라 단백질의 양은 크게 달라질 수 있습니다. 후성 유전 인자는 환경에 영향을 받으며 다음 세대로 유전되는 특징이 있습니다.후성유전학은 마치 골짜기 상단에 놓인 공의 운명과 같은데, 어디로 흘러가느냐에 따라 공의 운명이 달라지기 때문입니다. 이를 세포 분화상태와 비교하면 아래 그림과 같습니다.Cellular Potential and Epigenetic Landscapehttps://www.edwith.org/epigenome-2023/lecture/1473433DNA 구조는 아래 그림과 같은데, 후성유전학을 결정하는 인자들이 모두 DNA 구조에 포함되어 있습니다.Epigenetics Structurehttps://www.edwith.org/epigenome-2023/lecture/1473433유전자가 발현하도록 역할을 하는 HATs, HDemethylases와 발현을 억제하는 HDACs, DMTases가 있습니다.Epigenetics Factorshttps://www.edwith.org/epigenome-2023/lecture/1473433히스톤 단백질 변형의 종류와 그에 상응하는 구조, 영향을 나타낸 그림입니다.히스톤 단백질 변형https://www.edwith.org/epigenome-2023/lecture/1473433히스톤 단백질의 methylation, acetylation에 의해 closed/open chromatin 구조를 보입니다.히스톤 단백질의 methylation, acetylationhttps://www.edwith.org/epigenome-2023/lecture/1473433히스톤 단백질의 변형이 일어나면 후성유전적 조절 인자의 상호 작용으로 인하여 주변의 히스톤 단백질도 영향을 받아 변형되기 쉽습니다. Take Home Message환경과 유전자 발현을 후성유전학과 연계하여 알아봤습니다. 후성유전학의 정의와 후성유전적 인자에 대해 알아봤습니다." }, { "title": "생물정보학을 위한 R프로그래밍 V - 데이터 시각화", "url": "/posts/R_for_Bioinformatics_5/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, R", "date": "2023-08-08 07:29:30 +0900", "snippet": "본 post는 LAIAD에서 제공하는 부산대학교 이해승 교수님의 생물정보학을 위한 R프로그래밍을 정리한 내용입니다.Intro R 프로그래밍의 데이터 시각화를 학습합니다.데이터 시각화데이터의 의미를 통찰하고 전달하는 가장 좋은 방법은 시각적으로 표현하는 것입니다. 데이터 시각화는 데이터를 관찰하는 과정에서 선택 사항이 아니라 반드시 거쳐야 하는 필수 과정입니다.기술 통계량은 데이터 특성을 파악하기 위해 데이터를 요약한 값입니다. 기술 통계량 관련 함수는 다음과 같습니다. 함수 기능 x &amp;lt;- 1:10 일 때 결과 mean 평균, 절사평균 mean(x) -&amp;gt; 5.5 var 분사 var(x) -&amp;gt; 9.166667 sd 표준편차 sd(x) -&amp;gt; 3.02765 sum 합 sum(x) -&amp;gt; 55 min 최소 min(x) -&amp;gt; 1 max 최대 max(x) -&amp;gt; 10 range 범위, 최소와 최댓값을 출력 range(x) -&amp;gt; c(1, 10) median 중앙값(중위수) median(x) -&amp;gt; 5.5 quantile 분위수 - IQR 사분위수 범위 IQR(x) -&amp;gt; 4.5 cor 상관계수 - 예제 데이터를 통해 데이터 시각화의 필요성을 알아보겠습니다. anscombe 예제 데이터에서 통계 지표와 분석 수치만으로 비교해보면 네 개의 데이터 셋은 거의 동일하다고 판단할 수 있습니다. 하지만 그래프로 나타내보면 서로 다른 분포를 가진 데이터임을 알 수 있습니다. 이처럼 데이터 시각화를 통해 데이터를 파악하는 것은 매우 중요합니다.anscombe# x1 x2 x3 x4 y1 y2 y3 y4#1 10 10 10 8 8.04 9.14 7.46 6.58#2 8 8 8 8 6.95 8.14 6.77 5.76#3 13 13 13 8 7.58 8.74 12.74 7.71#4 9 9 9 8 8.81 8.77 7.11 8.84#5 11 11 11 8 8.33 9.26 7.81 8.47#6 14 14 14 8 9.96 8.10 8.84 7.04#7 6 6 6 8 7.24 6.13 6.08 5.25#8 4 4 4 19 4.26 3.10 5.39 12.50#9 12 12 12 8 10.84 9.13 8.15 5.56#10 7 7 7 8 4.82 7.26 6.42 7.91#11 5 5 5 8 5.68 4.74 5.73 6.89apply(anscombe, 2, mean) # 평균# x1 x2 x3 x4 y1 y2 y3 y4 #9.0 9.0 9.0 9.0 7.5 7.5 7.5 7.5 apply(anscombe, 2, var) # 분산# x1 x2 x3 x4 y1 y2 y3 y4 #11.00 11.00 11.00 11.00 4.13 4.13 4.12 4.12 cor(anscombe$x1, anscombe$y1) # 상관관계(상관계수)#[1] 0.816cor(anscombe$x2, anscombe$y2)#[1] 0.816cor(anscombe$x3, anscombe$y3)#[1] 0.816cor(anscombe$x4, anscombe$y4)#[1] 0.817par(mfrow = c(2, 2))plot(anscombe$x1, anscombe$y1)plot(anscombe$x2, anscombe$y2)plot(anscombe$x3, anscombe$y3)plot(anscombe$x4, anscombe$y4)데이터 시각화 필요성https://www.laidd.org/local/ubonline/view.php?id=181&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==데이터 시각화의 기본 기능데이터 시각화는 많은 양의 데이터를 올바로 해석할 수 있게 해주는 동시에 효과적으로 관찰할 수 있도록 도와줍니다.데이터 시각화의 효과는 다음과 같습니다. 직관(insight)을 얻을 수 있습니다. 핵심을 명확하게 이해할 수 있습니다. 평균적인 경향과 더불어 이상값(outlier)도 발견할 수 있습니다. 데이터에서 문제를 빨리 찾아낼 수 있습니다. 조건에 맞는 요소를 추출하는 방법 형식 []에 행/열 조건 명시 변수명[행 조건식, 열 조건식] if문 활용 (if / else if / else) if(조건식) 표현식 ifelse문 활용 ifelse(조건식, 참인 경우 반환값, 거짓인 경우 반환값) ### []에 행/열 조건 명시## 벡터의 경우test = c(15, 20, 30, NA, 45) # 벡터 생성test[test&amp;lt;40] # 값이 40 미만인 요소 추출#[1] 15 20 30 NAtest[test%%3!=0] # 값이 3으로 나누어 떨어지지 않는 요소 추출#[1] 20 NAtest[is.na(test)] # NA인 요소 추출#[1] NAtest[!is.na(test)] # NA가 아닌 요소 추출#[1] 15 20 30 45test[test%%2==0&amp;amp;!is.na(test)] # 2의 배수면서 NA가 아닌 요소 추출#[1] 20 30## 데이터프레임인 경우characters = data.frame(name=c(&quot;길동&quot;, &quot;춘향&quot;, &quot;철수&quot;), age=c(30, 16, 21), gender=factor(c(&quot;M&quot;, &quot;F&quot;, &quot;M&quot;))) # 데이터프레임 생성characters# name age gender#1 길동 30 M#2 춘향 16 F#3 철수 21 Mcharacters[characters$gender==&quot;F&quot;,] # 성별이 여성인 행 추출# name age gender#2 춘향 16 Fcharacters[characters$age&amp;lt;30&amp;amp;characters$gender==&quot;M&quot;, ] # 30살 미만의 남성 행 추출# name age gender#3 철수 21 M### if문 사용 (if, else if, else)## 두 가지 조건 분기가 필요한 경우x = 5if(x %% 2==0) { print(&#39;x는 짝수&#39;) # 조건식이 참일 때 수행} else { print(&#39;x는 홀수&#39;) # 조건식이 거짓일 때 수행}#[1] &quot;x는 홀수&quot;## 세 가지 조건 분시가 필요한 경우x = -1if(x&amp;gt;0) { print(&#39;x is a positive value.&#39;) # x가 0보다 크면 출력} else if(x&amp;lt;0) { print(&#39;x is a negative value.&#39;) # 위 조건을 만족하지 않고 x가 0보다 작으면 출력} else { print(&#39;x is zero.&#39;) # 위 조건을 모두 만족하지 않으면 출력}#[1] &quot;x is a negative value.&quot;## ifelse문 사용x = c(-5:5)options(digits=3) # 숫자 표현 시 유효자릿수를 3자리로 설정sqrt(x)# [1] NaN NaN NaN NaN NaN 0.00 1.00 1.41 1.73 2.00 2.24#Warning message:#In sqrt(x) : NaNs producedsqrt(ifelse(x&amp;gt;=0, x, NA)) # NaN이 발생하지 않게 음수면 NA로 표시# [1] NA NA NA NA NA 0.00 1.00 1.41 1.73 2.00 2.24데이터 정제를 위한 반복문데이터 검토 시 반복적으로 값을 변경하면서 사용해야 하는 경우에 사용합니다. R에서 제공하는 반복문은 repeat, while, for 문이 있습니다. 반복문 의미 repeat {&amp;lt;/br&amp;gt; 반복 수행할 문장&amp;lt;/br&amp;gt;} 블록 안의 문장을 반복해서 수행합니다. while(조건식) {&amp;lt;/br&amp;gt; 조건식이 참일 때 수행할 문장&amp;lt;/br&amp;gt;} 조건식이 참일 때 블록 안의 문장을 수행합니다. for(변수 in 데이터) {&amp;lt;/br&amp;gt; 반복 수행할 문장} 데이터의 각 요소를 변수에 할당하면서 각각에 대해 블록 안의 문장을 수행합니다. ## 1부터 10까지 수를 1씩 증가시키기for(i in 1:10) { print(i)}#[1] 1#[1] 2#[1] 3# ...## 구구단 2~9단 만들기for(i in 2:9) { for(j in 1:9) { print(paste(i, &quot;X&quot;, j, &quot;=&quot;, i*j)) }}#[1] &quot;2 X 1 = 2&quot;#[1] &quot;2 X 2 = 4&quot;#[1] &quot;2 X 3 = 6&quot;# ...## 1에서 10까지의 수 중 짝수만 출력하기for(i in 1:10) { if(i%%2==0) { print(i) }}#[1] 2#[1] 4#[1] 6#[1] 8#[1] 10## 1에서 10까지의 수 중 소수 출력하기for(i in 1:10) { check=0 for(j in 1:i) { if(i%%j==0) { check=check+1 } } if(check==2) { print(i) }}#[1] 2#[1] 3#[1] 5#[1] 7사용자 정의 함수: 원하는 기능 묶기함수는 입력과 출력간의 관계식을 의미합니다. 사용자의 목적에 맞는 다양한 함수를 만들 수 있습니다.사용자 정의 함수의 구조는 아래와 같습니다.#함수명 = function (전달인자1, 전달인자2, ...) {# 함수 동작 시 수행할 코드# return(반환값)#}## 계승을 구하는 함수fact = function(x) { # 함수의 이름은 fact, 입력은 x fa = 1 # 계승값을 저장할 변수 while(x&amp;gt;1) { # x가 1보가 큰 동안 반복 fa=fa*x # x 값을 fa에 곱한 후 fa에 다시 저장 x=x-1 # x 값을 1 감소 } return(fa) # 최종 계산된 fa 반환}fact(5) # 5 factorial을 계산한 결과 출력#[1] 120결측값 처리데이터에는 결측값(missing value)이 존재할 수 있는데, 데이터 중 고의 또는 실수로 누락된 값을 의미합니다. 결측값을 그대로 놔둔 채 데이터 가공을 하면 결과값에 오류가 뜨거나 잘못된 연산이 수행될 수 있으므로 정제과정에서 적절한 처리가 필요합니다.결측값 처리에는 다음과 같은 방법이 있습니다. 방법 설명 is.na 함수 이용 NA인 데이터가 있으면 T,&amp;lt;/br&amp;gt;없으면 F로 나타냅니다. na.omit 함수 이용 NA인 데이터를 제거합니다.&amp;lt;/br&amp;gt;즉, NA가 포함된 행을 지웁니다. 함수의 속성 이용 na.rm=T로 하여 함수 수행 시 NA를 제외합니다. ## na.omit 함수 이용air_narm = na.omit(airquality)mean(air_narm$Ozone)#[1] 42.1## 함수 속성인 na.rm=T 설정mean(airquality$Ozone, na.rm=T)#[1] 42.1이상값 처리결측값과 더불어 데이터에는 논리적 혹은 통계학적으로 이상한 데이터가 입력되어 있을 수 있습니다. 이러한 데이터를 이상값(outlier)이라 합니다. 통계학에서 이상값이란 다른 관측값과 멀리 떨어진 관측값입니다.patients = data.frame( name=c(&quot;환자1&quot;, &quot;환자2&quot;, &quot;환자3&quot;, &quot;환자4&quot;, &quot;환자5&quot;), age=c(22, 20, 25, 30, 27), gender=factor(c(&quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;K&quot;, &quot;F&quot;)), blood.type=factor(c(&quot;A&quot;, &quot;O&quot;, &quot;B&quot;, &quot;AB&quot;, &quot;C&quot;)))patients# name age gender blood.type#1 환자1 22 M A#2 환자2 20 F O#3 환자3 25 M B#4 환자4 30 K AB#5 환자5 27 F C# 성별에 K, 혈액형에 c 값은 명백한 이상값입니다.# 성별에서 이상값 제거patients_outrm = patients[patients$gender==&quot;M&quot;|patients$gender==&quot;F&quot;, ]patients_outrm# name age gender blood.type#1 환자1 22 M A#2 환자2 20 F O#3 환자3 25 M B#5 환자5 27 F C# 성별과 혈액형에서 이상값 제거patirents_outrm1 = patients[ (patients$gender==&quot;M&quot;|patients$gender==&quot;F&quot;) &amp;amp; (patients$blood.type==&quot;A&quot;|patients$blood.type==&quot;B&quot;|patients$blood.type==&quot;O&quot;|patients$blood.type==&quot;AB&quot;), ]patirents_outrm1# name age gender blood.type#1 환자1 22 M A#2 환자2 20 F O#3 환자3 25 M B좀 더 실질적인 데이터를 활용하여 이상값을 처리해 봅니다. 실제 데이터에서는 이상값을 정의하기 모호한 경우가 많습니다. 이 때 boxplot을 활용하여 정상값과 이상값을 구분할 수 있습니다.boxplot(airquality[, c(1:4)]) # Ozone, Solar.R, Wind, Temp에 대한 boxplotboxplot(airquality[, 1])$stats# [,1]#[1,] 1.0 -&amp;gt; 이 값 미만은 이상값으로 분류할 수 있음#[2,] 18.0#[3,] 31.5#[4,] 63.5#[5,] 122.0 -&amp;gt; 이 값 초과는 이상값으로 부류할 수 있음air = airquality # 임시 저장 변수로 airquality 데이터 복사table(is.na(air$Ozone)) # Ozone의 현재 NA 개수 확인#FALSE TRUE # 116 37 ## 이상값을 NA로 처리한 후 NA를 제거함air$Ozone = ifelse(air$Ozone&amp;lt;1|air$Ozone&amp;gt;122, NA, air$Ozone)table(is.na(air$Ozone))#FALSE TRUE # 114 39 # NA 제거air_narm = air[!is.na(air$Ozone), ]mean(air_narm$Ozone)#[1] 40.2boxplothttps://www.laidd.org/local/ubonline/view.php?id=181&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==Take Home Message R 프로그래밍의 데이터 취득과 정제에 대해 알아보고 실습을 통해 학습했습니다." }, { "title": "생물정보학을 위한 R프로그래밍 IV - 데이터 취득과 정제", "url": "/posts/R_for_Bioinformatics_4/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, R", "date": "2023-08-05 09:12:41 +0900", "snippet": "본 post는 LAIAD에서 제공하는 부산대학교 이해승 교수님의 생물정보학을 위한 R프로그래밍을 정리한 내용입니다.Intro R 프로그래밍의 데이터 취득과 정제에 대해 알아봅니다.파일 읽고 쓰기대부분 데이터는 파일 형태로 존재합니다. R에서 제공하는 파일 읽고 쓰기 함수는 다음과 같습니다. 패키지 함수 base scan, write, write.table, read.table&amp;lt;/br&amp;gt;save, load, write.csv, read.csv 등 readr write_csv, read_csv data.table fwite, fread feather write_feather, read_feather read.table 함수는 일반 텍스트 파일을 읽을 때 사용합니다.read.csv 함수는 CSV(comma-separated values) 파일을 읽을 때 사용합니다.write.table 함수는 일반 텍스트 파일로 저장할 때 사용합니다.write.csv 함수는 CSV 파일로 저장할 때 사용합니다.save()와 load() 함수는 변수를 저장하고 불러올 때 사용합니다.파일 읽고 쓰기https://www.laidd.org/local/ubonline/view.php?id=181&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==데이터 정제를 위한 조건문데이터 정제를 위해 특정 조건에 맞는 값을 찾아내거나 일부 구간의 값을 추출하여 연산하는 등 다양한 목적에 맞게 작업할 수 있습니다. 조건문 형식은 다음과 같습니다. 조건에 맞는 요소를 추출하는 방법 형식 []에 행/열 조건 명시 변수명[행 조건식, 열 조건식] if문 활용 (if / else if / else) if(조건식) 표현식 ifelse문 활용 ifelse(조건식, 참인 경우 반환값, 거짓인 경우 반환값) ### []에 행/열 조건 명시## 벡터의 경우test = c(15, 20, 30, NA, 45) # 벡터 생성test[test&amp;lt;40] # 값이 40 미만인 요소 추출#[1] 15 20 30 NAtest[test%%3!=0] # 값이 3으로 나누어 떨어지지 않는 요소 추출#[1] 20 NAtest[is.na(test)] # NA인 요소 추출#[1] NAtest[!is.na(test)] # NA가 아닌 요소 추출#[1] 15 20 30 45test[test%%2==0&amp;amp;!is.na(test)] # 2의 배수면서 NA가 아닌 요소 추출#[1] 20 30## 데이터프레임인 경우characters = data.frame(name=c(&quot;길동&quot;, &quot;춘향&quot;, &quot;철수&quot;), age=c(30, 16, 21), gender=factor(c(&quot;M&quot;, &quot;F&quot;, &quot;M&quot;))) # 데이터프레임 생성characters# name age gender#1 길동 30 M#2 춘향 16 F#3 철수 21 Mcharacters[characters$gender==&quot;F&quot;,] # 성별이 여성인 행 추출# name age gender#2 춘향 16 Fcharacters[characters$age&amp;lt;30&amp;amp;characters$gender==&quot;M&quot;, ] # 30살 미만의 남성 행 추출# name age gender#3 철수 21 M### if문 사용 (if, else if, else)## 두 가지 조건 분기가 필요한 경우x = 5if(x %% 2==0) { print(&#39;x는 짝수&#39;) # 조건식이 참일 때 수행} else { print(&#39;x는 홀수&#39;) # 조건식이 거짓일 때 수행}#[1] &quot;x는 홀수&quot;## 세 가지 조건 분시가 필요한 경우x = -1if(x&amp;gt;0) { print(&#39;x is a positive value.&#39;) # x가 0보다 크면 출력} else if(x&amp;lt;0) { print(&#39;x is a negative value.&#39;) # 위 조건을 만족하지 않고 x가 0보다 작으면 출력} else { print(&#39;x is zero.&#39;) # 위 조건을 모두 만족하지 않으면 출력}#[1] &quot;x is a negative value.&quot;## ifelse문 사용x = c(-5:5)options(digits=3) # 숫자 표현 시 유효자릿수를 3자리로 설정sqrt(x)# [1] NaN NaN NaN NaN NaN 0.00 1.00 1.41 1.73 2.00 2.24#Warning message:#In sqrt(x) : NaNs producedsqrt(ifelse(x&amp;gt;=0, x, NA)) # NaN이 발생하지 않게 음수면 NA로 표시# [1] NA NA NA NA NA 0.00 1.00 1.41 1.73 2.00 2.24데이터 정제를 위한 반복문데이터 검토 시 반복적으로 값을 변경하면서 사용해야 하는 경우에 사용합니다. R에서 제공하는 반복문은 repeat, while, for 문이 있습니다. 반복문 의미 repeat {&amp;lt;/br&amp;gt; 반복 수행할 문장&amp;lt;/br&amp;gt;} 블록 안의 문장을 반복해서 수행합니다. while(조건식) {&amp;lt;/br&amp;gt; 조건식이 참일 때 수행할 문장&amp;lt;/br&amp;gt;} 조건식이 참일 때 블록 안의 문장을 수행합니다. for(변수 in 데이터) {&amp;lt;/br&amp;gt; 반복 수행할 문장} 데이터의 각 요소를 변수에 할당하면서 각각에 대해 블록 안의 문장을 수행합니다. ## 1부터 10까지 수를 1씩 증가시키기for(i in 1:10) { print(i)}#[1] 1#[1] 2#[1] 3# ...## 구구단 2~9단 만들기for(i in 2:9) { for(j in 1:9) { print(paste(i, &quot;X&quot;, j, &quot;=&quot;, i*j)) }}#[1] &quot;2 X 1 = 2&quot;#[1] &quot;2 X 2 = 4&quot;#[1] &quot;2 X 3 = 6&quot;# ...## 1에서 10까지의 수 중 짝수만 출력하기for(i in 1:10) { if(i%%2==0) { print(i) }}#[1] 2#[1] 4#[1] 6#[1] 8#[1] 10## 1에서 10까지의 수 중 소수 출력하기for(i in 1:10) { check=0 for(j in 1:i) { if(i%%j==0) { check=check+1 } } if(check==2) { print(i) }}#[1] 2#[1] 3#[1] 5#[1] 7사용자 정의 함수: 원하는 기능 묶기함수는 입력과 출력간의 관계식을 의미합니다. 사용자의 목적에 맞는 다양한 함수를 만들 수 있습니다.사용자 정의 함수의 구조는 아래와 같습니다.#함수명 = function (전달인자1, 전달인자2, ...) {# 함수 동작 시 수행할 코드# return(반환값)#}## 계승을 구하는 함수fact = function(x) { # 함수의 이름은 fact, 입력은 x fa = 1 # 계승값을 저장할 변수 while(x&amp;gt;1) { # x가 1보가 큰 동안 반복 fa=fa*x # x 값을 fa에 곱한 후 fa에 다시 저장 x=x-1 # x 값을 1 감소 } return(fa) # 최종 계산된 fa 반환}fact(5) # 5 factorial을 계산한 결과 출력#[1] 120결측값 처리데이터에는 결측값(missing value)이 존재할 수 있는데, 데이터 중 고의 또는 실수로 누락된 값을 의미합니다. 결측값을 그대로 놔둔 채 데이터 가공을 하면 결과값에 오류가 뜨거나 잘못된 연산이 수행될 수 있으므로 정제과정에서 적절한 처리가 필요합니다.결측값 처리에는 다음과 같은 방법이 있습니다. 방법 설명 is.na 함수 이용 NA인 데이터가 있으면 T,&amp;lt;/br&amp;gt;없으면 F로 나타냅니다. na.omit 함수 이용 NA인 데이터를 제거합니다.&amp;lt;/br&amp;gt;즉, NA가 포함된 행을 지웁니다. 함수의 속성 이용 na.rm=T로 하여 함수 수행 시 NA를 제외합니다. ## na.omit 함수 이용air_narm = na.omit(airquality)mean(air_narm$Ozone)#[1] 42.1## 함수 속성인 na.rm=T 설정mean(airquality$Ozone, na.rm=T)#[1] 42.1이상값 처리결측값과 더불어 데이터에는 논리적 혹은 통계학적으로 이상한 데이터가 입력되어 있을 수 있습니다. 이러한 데이터를 이상값(outlier)이라 합니다. 통계학에서 이상값이란 다른 관측값과 멀리 떨어진 관측값입니다.patients = data.frame( name=c(&quot;환자1&quot;, &quot;환자2&quot;, &quot;환자3&quot;, &quot;환자4&quot;, &quot;환자5&quot;), age=c(22, 20, 25, 30, 27), gender=factor(c(&quot;M&quot;, &quot;F&quot;, &quot;M&quot;, &quot;K&quot;, &quot;F&quot;)), blood.type=factor(c(&quot;A&quot;, &quot;O&quot;, &quot;B&quot;, &quot;AB&quot;, &quot;C&quot;)))patients# name age gender blood.type#1 환자1 22 M A#2 환자2 20 F O#3 환자3 25 M B#4 환자4 30 K AB#5 환자5 27 F C# 성별에 K, 혈액형에 c 값은 명백한 이상값입니다.# 성별에서 이상값 제거patients_outrm = patients[patients$gender==&quot;M&quot;|patients$gender==&quot;F&quot;, ]patients_outrm# name age gender blood.type#1 환자1 22 M A#2 환자2 20 F O#3 환자3 25 M B#5 환자5 27 F C# 성별과 혈액형에서 이상값 제거patirents_outrm1 = patients[ (patients$gender==&quot;M&quot;|patients$gender==&quot;F&quot;) &amp;amp; (patients$blood.type==&quot;A&quot;|patients$blood.type==&quot;B&quot;|patients$blood.type==&quot;O&quot;|patients$blood.type==&quot;AB&quot;), ]patirents_outrm1# name age gender blood.type#1 환자1 22 M A#2 환자2 20 F O#3 환자3 25 M B좀 더 실질적인 데이터를 활용하여 이상값을 처리해 봅니다. 실제 데이터에서는 이상값을 정의하기 모호한 경우가 많습니다. 이 때 boxplot을 활용하여 정상값과 이상값을 구분할 수 있습니다.boxplot(airquality[, c(1:4)]) # Ozone, Solar.R, Wind, Temp에 대한 boxplotboxplot(airquality[, 1])$stats# [,1]#[1,] 1.0 -&amp;gt; 이 값 미만은 이상값으로 분류할 수 있음#[2,] 18.0#[3,] 31.5#[4,] 63.5#[5,] 122.0 -&amp;gt; 이 값 초과는 이상값으로 부류할 수 있음air = airquality # 임시 저장 변수로 airquality 데이터 복사table(is.na(air$Ozone)) # Ozone의 현재 NA 개수 확인#FALSE TRUE # 116 37 ## 이상값을 NA로 처리한 후 NA를 제거함air$Ozone = ifelse(air$Ozone&amp;lt;1|air$Ozone&amp;gt;122, NA, air$Ozone)table(is.na(air$Ozone))#FALSE TRUE # 114 39 # NA 제거air_narm = air[!is.na(air$Ozone), ]mean(air_narm$Ozone)#[1] 40.2boxplothttps://www.laidd.org/local/ubonline/view.php?id=181&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==Take Home Message R 프로그래밍의 데이터 취득과 정제에 대해 알아보고 실습을 통해 학습했습니다." }, { "title": "생물정보학을 위한 R프로그래밍 III - 데이터형과 연산", "url": "/posts/R_for_Bioinformatics_3/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, R", "date": "2023-08-01 07:40:11 +0900", "snippet": "본 post는 LAIAD에서 제공하는 부산대학교 이해승 교수님의 생물정보학을 위한 R프로그래밍을 정리한 내용입니다.Intro R 프로그래밍의 데이터형과 연산에 대해 알아봅니다.배열배열은 열과 행으로 구성된 데이터형입니다. array 함수는 N차원 배열을 생성합니다.벡터와 배열의 구성 형태https://www.laidd.org/local/ubonline/view.php?id=181&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==x = array(1:5, c(2,4))# [,1] [,2] [,3] [,4]# [1,] 1 3 5 2# [2,] 2 4 1 3matrix 함수는 2차원 배열을 생성합니다. nrow는 행의 수를 결정합니다. byrow는 데이터를 행 단위로 배치할지 여부를 결정합니다.x = 1:12[1] 1 2 3 4 5 6 7 8 9 10 11 12matrix(x, nrow=3)# [,1] [,2] [,3] [,4]# [1,] 1 4 7 10# [2,] 2 5 8 11# [3,] 3 6 9 12matrix(x, nrow=3, byrow=T)# [,1] [,2] [,3] [,4]# [1,] 1 2 3 4# [2,] 5 6 7 8# [3,] 9 10 11 12cbind, rbind 함수는 열, 행 단위로 묶어 배열을 생성합니다.v1 = c(1, 2, 3, 4)v2 = c(5, 6, 7, 8)v3 = c(9, 10, 11, 12)cbind(v1, v2, v3)# v1 v2 v3#[1,] 1 5 9#[2,] 2 6 10#[3,] 3 7 11#[4,] 4 8 12rbind(v1, v2, v3)# [,1] [,2] [,3] [,4]#v1 1 2 3 4#v2 5 6 7 8#v3 9 10 11 12배열(행렬) 연산자는 다음과 같습니다. 연산자 설명 +, - 행렬의 덧셈과 뺄셈 * R에서의 행렬 곱셈&amp;lt;/br&amp;gt;(각 열별 곱셈) %*% 수학적인 행렬 곱셈 t(), apem() 전치 행렬 solve() 역행렬 det() 행렬식 x = array(1:4, dim=c(2,2))y = array(5:8, dim=c(2,2))x# [,1] [,2]#[1,] 1 3#[2,] 2 4y# [,1] [,2]#[1,] 5 7#[2,] 6 8x*y# [,1] [,2]#[1,] 5 21#[2,] 12 32x%*%y# [,1] [,2]#[1,] 23 31#[2,] 34 46t(x)# [,1] [,2]#[1,] 1 2#[2,] 3 4solve(x)# [,1] [,2]#[1,] -2 1.5#[2,] 1 -0.5det(x)#[1] -2배열에서 사용 가능한 유용한 함수가 있습니다.apply 함수는 배열의 행 또는 열별로 함수를 적용합니다.dim 함수는 배열의 크기(차원의 수)를 출력합니다.sample 함수는 벡터나 배열에서 샘플 데이터를 추출합니다.x = array(1:12, c(3,4))x# [,1] [,2] [,3] [,4]#[1,] 1 4 7 10#[2,] 2 5 8 11#[3,] 3 6 9 12apply(x, 1, mean)#[1] 5.5 6.5 7.5apply(x, 2, mean)#[1] 2 5 8 11apply(x, 1, mean) # 가운데 값이 1이면 함수를 행별로 적용#[1] 5.5 6.5 7.5apply(x, 2, mean) # 가운데 값이 2이면 함수를 열별로 적용#[1] 2 5 8 11dim(x)#[1] 3 4sample(x) # 배열 요소를 임의로 섞어 추출#[1] 7 5 3 11 9 1 6 10 2 12 4 8sample(x, 10) # 배열 요소 중 10개를 골라 추출#[1] 10 2 8 7 6 1 4 3 11 12sample(x, 10, prob=c(1:12)/24) # 각 요소별 추출 확률을 달리할 수 있음#[1] 7 11 4 8 2 10 9 6 12 5sample(10) # 단순히 숫자만 사용하여 샘플을 만들 수 있음#[1] 4 10 1 9 8 3 6 5 7 2데이터프레임데이터프레임은 가장 흔히 쓰이는 표 형태의 데이터 구조를 가집니다. 행렬과 달리 여러 데이터형을 혼합하여 저장할 수 있습니다. 리스트와 달리 행의 수를 일치시켜서 저장해야 합니다.데이터프레임을 생성할 때 data.frame 함수를 이용합니다.name = c(&quot;철수&quot;, &quot;춘향&quot;, &quot;길동&quot;)age = c(22, 20, 25)gender = factor(c(&quot;M&quot;, &quot;F&quot;, &quot;M&quot;))blood.type = factor(c(&quot;A&quot;, &quot;O&quot;, &quot;B&quot;))patients = data.frame(name, age, gender, blood.type)patients# name age gender blood.type#1 철수 22 M A#2 춘향 20 F O#3 길동 25 M B데이터프레임 요소에 접근할 때는 $, [, ], 조건식 등을 이용합니다.patients$name # name 속성 값 출력#[1] &quot;철수&quot; &quot;춘향&quot; &quot;길동&quot;patients[1, ] # 1행 값 출력# name age gender blood.type#1 철수 22 M Apatients[, 2] # 2열 값 출력#[1] 22 20 25patients[3, 1] # 3행 1열 값 출력#[1] &quot;길동&quot;patients[patients$name==&quot;철수&quot;, ] # 환자 중 철수에 대한 정보 추출# name age gender blood.type#1 철수 22 M Apatients[patients$name==&quot;철수&quot;, c(&quot;name&quot;, &quot;age&quot;)] # 철수 이름과 나이 정보만 추출# name age#1 철수 22데이터프레임에 사용할 수 있는 유용한 함수가 있습니다.attach/detach 함수는 데이터프레임의 속성명을 변수명으로 변경합니다.head(cars) # cars 데이터셋 확인. head 함수의 기본 기능은 앞 6개 데이터를 추출함# speed dist#1 4 2#2 4 10#3 7 4#4 7 22#5 8 16#6 9 10speed # speed 변수가 독립적으로 존재하지 않기 때문에 에러 발생#Error: object &#39;speed&#39; not foundattach(cars) # attach 함수를 통해 cars의 각 속성을 변수로 이용하게 함speed # speed라는 변수명을 직접 이용할 수 있음# [1] 4 4 7 7 8 9 10 10 10 11 11 12 12 12 12 13 13 13 13 14 14 14 14 15 15 15 16 16 17 17 17 18 18 18 18 19 19 19 20 20 20 20 20 22 23 24 24 24 24 25detach(cars) # detach 함수를 통해 cars의 각 속성을 변수로 사용하는 것을 해제함speed # detach 실행 후 더이상 cars 속성인 speed를 사용하지 못함#Error: object &#39;speed&#39; not foundwith 함수는 데이터프레임에 다양한 함수를 적용할 수 있습니다.mean(cars$speed) # 데이터 속성을 이용해 함수 적용#[1] 15.4max(cars$speed) # 데이터 속성을 이용해 함수 적용#[1] 25with(cars, mean(speed)) # with 함수를 이용해 함수 적용#[1] 15.4with(cars, max(speed)) # with 함수를 이용해 함수 적용#[1] 25subset 함수는 데이터프레임에서 일부 데이터만 추출할 수 있습니다.subset(cars, speed&amp;gt;20) # 속도가 20 초과인 데이터만 추출# speed dist#44 22 66#45 23 54#46 24 70#47 24 92#48 24 93#49 24 120#50 25 85subset(cars, speed&amp;gt;20, select= -c(dist)) # 속도가 20 초과인 데이터 중 dist를 제외한 데이터만 추출# speed#44 22#45 23#46 24#47 24#48 24#49 24#50 25subset(cars, speed&amp;gt;20, select=c(dist)) # 속도가 20 초과인 dist 데이터만 추출, 여러 열 선택은 c() 안을 ,로 구분# dist#44 66#45 54#46 70#47 92#48 93#49 120#50 85리스트리스트는 서로 다른 데이터형을 갖는 자료 구조를 포함할 수 있습니다. 데이터프레임보다 넓은 의미의 데이터 모임입니다. 데이터프레임과 달리 모든 속성의 크기가 같을 필요는 없습니다.리스트를 생성할 때 list 함수를 이용할 수 있습니다.patients = data.frame(name=c(&quot;철수&quot;, &quot;춘향&quot;, &quot;길동&quot;), age=c(22, 20, 25), gender=factor(c(&quot;M&quot;, &quot;F&quot;, &quot;M&quot;)), blood.type=factor(c(&quot;A&quot;, &quot;O&quot;, &quot;B&quot;)))no.patients = data.frame(day=c(1:6), no=c(50, 60, 55, 52, 65, 58))listPatients = list(patients, no.patients) # 데이터를 단순히 추가listPatients#[[1]]# name age gender blood.type#1 철수 22 M A#2 춘향 20 F O#3 길동 25 M B#[[2]]# day no#1 1 50#2 2 60#3 3 55#4 4 52#5 5 65#6 6 58listPatients = list(patients=patients, no.patients=no.patients) # 각 데이터에 이름을 부여하면서 추가listPatients#$patients# name age gender blood.type#1 철수 22 M A#2 춘향 20 F O#3 길동 25 M B#$no.patients# day no#1 1 50#2 2 60#3 3 55#4 4 52#5 5 65#6 6 58리스트 요소에 접근할 때 $, [[ ]]를 이용합니다.listPatients$patients # 요소명 입력# name age gender blood.type#1 철수 22 M A#2 춘향 20 F O#3 길동 25 M BlistPatients[[1]] # 인덱스 입력# name age gender blood.type#1 철수 22 M A#2 춘향 20 F O#3 길동 25 M BlistPatients[[&quot;patients&quot;]] # 요소명을 &quot;&quot;에 입력# name age gender blood.type#1 철수 22 M A#2 춘향 20 F O#3 길동 25 M B리스트에 사용할 수 있는 유용한 함수가 있습니다.lapply/sapply 함수는 리스트 요소에 다양한 함수를 적용합니다.lapply(listPatients$no.patients, mean) # no.patients 요소의 평균을 구함#$day#[1] 3.5#$no#[1] 56.66667lapply(listPatients$patients, mean) # patients 요소의 평균을 구함. 숫자 형태가 아닌 것은 평균이 구해지지 않음#$name#[1] NA#$age#[1] 22.33333#$gender#[1] NA#$blood.type#[1] NA#Warning messages:#1: In mean.default(X[[i]], ...) :# 인자가 수치형 또는 논리형이 아니므로 NA를 반환합니다#2: In mean.default(X[[i]], ...) :# 인자가 수치형 또는 논리형이 아니므로 NA를 반환합니다#3: In mean.default(X[[i]], ...) :# 인자가 수치형 또는 논리형이 아니므로 NA를 반환합니다sapply(listPatients$no.patients, mean)# day no # 3.50000 56.66667 sapply(listPatients$no.patients, mean, simplify=F) # sapply()의 simplify 옵션을 F로 하면 lapply()와 동일한 결과 반환함#$day#[1] 3.5#$no#[1] 56.66667Take Home Message R에서 사용하는 데이터형과 연산에 대해 알아보았습니다." }, { "title": "생물정보학을 위한 R프로그래밍 II - 데이터형과 연산", "url": "/posts/R_for_Bioinformatics_2/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, R", "date": "2023-07-31 07:58:04 +0900", "snippet": "본 post는 LAIAD에서 제공하는 부산대학교 이해승 교수님의 생물정보학을 위한 R프로그래밍을 정리한 내용입니다.Intro R 프로그래밍의 데이터형과 연산에 대해 알아봅니다.데이터의 저장과 처리구조와 형태에 따라 데이터의 이름도 다릅니다. 변수 벡터(vector): 단일값들의 모임입니다. 데이터 구조의 가장 기본입니다. 배열(array) : 벡터를 행과 열로 구성한 구조입니다. 2차원: 행렬, 3차원: 배열 데이터프레임(dataframe): 서로 다른 데이터 형이 표 형태로 정리된 구조입니다. 각 속성의 크기가 같습니다. 리스트(list): 여러 데이터를 그룹화한 구조입니다. 각 속성의 크기가 달라도 됩니다. 데이터형: 숫자형, 문자형, 범주형, 논리형, 특수 상수 등 연산자: 산술(+, -, *, /), 비교(&amp;gt;, &amp;lt;), 논리 연산자(==, !=, !)데이터 구조 간 관계https://www.laidd.org/local/ubonline/view.php?id=181&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==변수명을 생성할 때 몇 가지 규칙이 있습니다. 첫 글자는 반드시 영문자 또는 마침표만 사용 가능합니다. 두 번째 글자 이후로는 영문자, 숫자, 밑줄 사용 가능합니다. 대문자와 소문자를 구분합니다. 빈 칸은 사용 불가합니다.변수에 값을 할당할 때 세 가지 방법이 있습니다.x = 1y = 2# method1z = x + y# method2z &amp;lt;- x+y# method3x + y -&amp;gt; zR의 기본 데이터형은 다음과 같습니다. 데이터형 종류 숫자형 int: 정수, num: 실수, cplx: 복소수 문자형 chr: 작은따옴표나 큰따옴표로 묶어서 표기 범주형 factor: 레벨에 따라 분류된 형태 논리형 TRUE(T), FALSE(F) 특수 상수 NULL: 정의되지 않은 값, NA: 결측값, -Inf: 음의 무한대, Inf: 양의 무한대, NaN: 0/0, Inf/Inf 등과 같이 연산 불가능한 값 표시 기본 데이터형 실습 예제입니다.x = 5y = 2x/yxi = 1 + 2iyi = 1 - 2ixi + yistr = &quot;Heool, World!&quot;strblood.type = factor(c(&#39;A&#39;, &#39;B&#39;, &#39;O&#39;, &#39;AB&#39;))blood.typeTFxinf = Infyinf = Infxinf/yinf데이터형을 확인하는 함수입니다. 함수 설명 class(x) R 객체지향 관점에서 x의 데이터형 typeof(x) R 언어 자체 관점에서 x의 데이터형 is.integer(x) x가 정수형이면 TRUE, 아니면 FALSE is.numeric(x) x가 실수형이면 TRUE, 아니면 FALSE is.complex(x) x가 복소수형이면 TRUE, 아니면 FALSE is.character(x) x가 문자형이면 TRUE, 아니면 FALSE is.na(x) x가 NA이면 TRUE, 아니면 FALSE 데이터형을 변환하는 함수입니다. 함수 설명 as.factor(x) x를 범주형으로 변환 as.integer(x) x를 정수형으로 변환 as.numeric(x) x를 숫자형으로 변환 as.character(x) x를 문자형으로 변환 as.matrix(x) x를 행렬로 변환 as.array(x) x를 배열로 변환 산술 연산자는 다음과 같습니다. 연산자 설명 예 + 덧셈 5 + 2 - 뺄셈 5 - 2 * 곱셈 5 * 2 / 나눗셈(실수 나눗셈) 5 / 2 ^ 또는 ** 지수승 5 ^ 2 x %% y x를 y로 나눈 나머지 (정수 나눗셈 나머지) 5 %% 2 x %/% y x를 y로 나눈 몫 (정수 나눗셈 몫) 5 %/% 2 비교, 논리 연산자는 다음과 같습니다. 연산자 설명 예 &amp;lt; 좌변이 작은(미만) 5 &amp;lt; 5 &amp;lt;= 좌변이 작거나 같은(이하) 5 &amp;lt;= 5 &amp;gt; 좌변이 큰(초과) 5 &amp;gt; 5 &amp;gt;= 좌번이 크거나 같은(이상) 5 &amp;gt;= 5 == 좌변과 우변이 같은 5 == 5 != 좌변과 우변이 다른 5 != 5 !x 부정(not) !TRUE x | y, x | | y x or y(또는, 합집합) TRUE | FALSE x &amp;amp; y, x &amp;amp; &amp;amp; y x and y(그리고, 교집합) TRUE &amp;amp; FALSE isTRUE(x) x의 TRUE 여부 판단 isTRUE(TRUE) 연산자를 연달아 사용할 때 우선순위를 따릅니다.연산자 우선 순위https://www.laidd.org/local/ubonline/view.php?id=181&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==벡터벡터는 여러 단일값을 하나의 변수명으로 저장할 수 있는 데이터형입니다.벡터를 생성하는 여러 가지 방법이 있습니다. 벡터 생성 연산자: ‘:’ vector 함수 이용: vector(length=n) c 함수 이용: c(1:5) seq 함수 이용: 순열 벡터를 생성합니다. seq(from=n, to=n, by=n) req 함수 이용: 반복 벡터를 생성합니다. rep(c(1:3), times=n), rep(c(1:3), each=n)벡터 생성: seq 함수 이용https://www.laidd.org/local/ubonline/view.php?id=181&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==벡터 생성: rep 함수 이용https://www.laidd.org/local/ubonline/view.php?id=181&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==벡터 연산과 관련된 실습 내용입니다.x = c(2, 4, 6, 8, 10)length(x) # x 벡터의 길이를 구합니다.x[1] # x 벡터의 1번 요소 값을 구합니다.x[1, 2, 3] # x 벡터의 1, 2, 3번 요소 값을 구할 때 이와 같이 입력하면 에러가 발생합니다.x[c(1, 2, 3)] # x 벡터의 1, 2, 3번 요소 값을 구할 때 벡터로 묶어줘야 합니다.x[-c(1, 2, 3)] # x 벡터의 1, 2, 3번 요소를 제외한 값을 구합니다.x[c(1:3)] # x 벡터의 1, 2, 3번 요소 값을 구합니다.벡터 간 연산은 벡터의 길이가 같거나 요소 개수가 배수 관계에 있을 때 가능합니다.x = c(1, 2, 3, 4)y = c(5, 6, 7, 8)z = c(3, 4)w = c(5, 6, 7)x + 2 # x 벡터의 개별 요소에 각각 2를 더합니다.x + y # x 벡터와 y 벡터의 크기가 동일하므로 각 요소별로 더합니다.x + z # x 벡터의 크기가 z 벡터 크기의 정수배(2배)이므로 크기가 작은 z 벡터 요소를 순환하며 x 벡터 각 요소에 더합니다.x + w # x와 w 벡터의 크기가 정수배가 아니므로 연산에 에러가 발생합니다.벡터 연산에 유용한 함수는 다음과 같습니다.x = c(1:10)x &amp;gt; 5 # x 벡터의 요소 값이 5보다 큰지 확인합니다.all(x &amp;gt; 5) # x 벡터의 요소 값이 모두 5보다 큰지 확인합니다.any(x &amp;gt; 5) # x 벡터의 요소 값 중 일부가 5보다 큰지 확인합니다.a = c(1, 2, 3)b = c(3, 4, 5)c = c(3, 1, 2)union(x, y) # 합집합intersect(x, y) # 교집합setdiff(x, y) # 차집합(x에서 y와 동일한 요소 제외하고 출력)setequal(x, y) # x와 y에 동일한 요소가 있는지 비교Take Home Message R에서 사용하는 데이터형과 연산에 대해 알아보았습니다." }, { "title": "Solid Tumors - Hereditary", "url": "/posts/hereditary_cancer/", "categories": "Bioinformatics, Biology", "tags": "BI, bioinformatics, biology", "date": "2023-07-31 07:14:40 +0900", "snippet": "Solid Tumors - Hereditarywww.amp.org" }, { "title": "Solid Tumors - Sporadic", "url": "/posts/sporadic_cancer/", "categories": "Bioinformatics, Biology", "tags": "BI, bioinformatics, biology", "date": "2023-07-31 07:12:04 +0900", "snippet": "Solid Tumors - Sporadicwww.amp.orgSolid Tumors - Sporadicwww.amp.org" }, { "title": "Interpretation Databases", "url": "/posts/Interpretation-Databases/", "categories": "Bioinformatics, Databases", "tags": "BI, bioinformatics, databases", "date": "2023-07-31 07:09:24 +0900", "snippet": "Interpretation Databaseswww.amp.org" }, { "title": "(LAIDD) Cancer Genome Bigdata", "url": "/posts/Certificate_Cancer_Genome_Bigdata/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, bioinformatics, LAIDD", "date": "2023-07-30 15:40:08 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "암 유전체 빅데이터", "url": "/posts/Cancer_genome_bigdata/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, bigdata, TCGA, cancer", "date": "2023-07-30 10:42:04 +0900", "snippet": "본 post는 LAIAD에서 제공하는 가톨릭의과대학 홍동완 교수님의 암 유전체 빅데이터를 정리한 내용입니다.Intro cBioPortal, USCS XenaBrowser, GDC Data Portal 사용법을 학습합니다. 암 정밀 의료 실현을 위한 인간 암 유전체 데이터의 특징과 데이터베이스를 이해합니다. 국제 암 컨소시움 TCGA 프로젝트에서 생산, 구축한 빅 데이터베이스 사용법을 습득하고 통합 분석법을 이해합니다. cBioPortalCentral dogma는 DNA → RNA → Protein으로 이어지는 사람의 유전정보 전달 체계입니다. DNA, RNA, Protein 모두 유전정보를 담고 있으며 각 물질에 대한 연구를 오믹스 연구라고 합니다.Central Dogmahttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=오믹스 분석에 대한 시초는 NGS 기술에 있습니다. NGS로 사람 유전체에 대한 bigdata를 생산하는데 현재 Illumina사의 NovaSeq6000은 WGS 30x 기준 1년에 약 4,500명의 유전체 정보를 생산할 수 있습니다.NGS Sequencerhttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=한 명의 환자에 대한 다양한 시퀀싱 데이터를 생산한다고 가정했을 때 나올 수 있는 데이터 종류와 사이즈 입니다. 암 패널 데이터, WGS, WES, RNA seq 데이터 생산이 가능합니다. 생산된 데이터로부터 암 환자의 유전체 특징을 파악하고 적절한 치료를 시도할 수 있습니다.Sequencing Data Sizehttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=암 환자에게서 나타날 수 있는 다양한 somatic 변이 종류입니다. SNV, CNV, SV, Gene fusion 등 다양한 somatic 변이가 존재합니다.Types of Somatic Variants in Cancerhttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=TCGA(The Cancer Genome Atlas) 프로젝트의 첫 번째 버전 데이터는 20 peta 정도이며 TCGA data portal, cBioPortal, CGHub를 통해 제한적으로 제공하고 있습니다. 이렇게 공개된 데이터는 CEDAR, ClinGen, ClinVar 등의 프로젝트와 연구그룹과 연계되어 연구가 진행되고 있습니다.Toward a Shared Vision for Cancer Genomic Datahttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=cBioPortal은 데이터의 visualization에 특화되어 있습니다. 20가지 cancer type에 대하여 총 292개 study, 107,299개 샘플 데이터를 포함하고 있습니다.cBioPortalhttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=cBioPortalhttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=Prostate cancer 관련 유전자의 발현량 기반으로 검출된 변이를 살펴보는 예시입니다.Prostate Cancer in cBioPortalhttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=Prostate Cancer in cBioPortalhttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=Prostate Cancer in cBioPortalhttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=Prostate Cancer in cBioPortalhttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=Prostate Cancer in cBioPortalhttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=Xena BrowserXena Browser는 TCGA 등에서 나온 데이터를 기반으로 비교적 쉽게 분석을 진행할 수 있는 사이트입니다.Xena Browserhttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=두 개의 study에서 KRAS 유전자의 발현량을 비교한 그래프입니다.Xena Browserhttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=GDC Data PortalGDC Data Portal은 TCGA 등의 대형 프로젝트 데이터를 확인, 다운로드, 분석할 수 있는 사이트입니다.다음과 같이 TCGA, ICGC, PCAWG 등과 같은 국제 project에서 나온 다량의 데이터가 존재합니다.TCGA, ICGC, PCAWGhttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=Cancer research와 관련된 genomic databases와 주요 project에 투입된 인력, 비용입니다.Genomic Databases in Cancer Researchhttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=Projectshttps://www.laidd.org/local/ubonline/view.php?id=195&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSVFQyU5NSU5NCslRUMlOUMlQTAlRUMlQTAlODQlRUMlQjIlQjQmZW5yb2xfc3RhcnQ9JmVucm9sX2VuZD0mc3R1ZHlfc3RhcnQ9JnN0dWR5X2VuZD0=Take Home Message cBioPortal, USCS XenaBrowser, GDC Data Portal과 사용법을 알아보았습니다. 암 유전체 데이터의 특징과 데이터베이스를 학습했습니다. " }, { "title": "(LAIDD) Big Data in Precision Oncology", "url": "/posts/Certificate_Big_Data_in_Precision_Oncology/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, bioinformatics, LAIDD", "date": "2023-07-27 20:04:10 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "생물정보학을 위한 R프로그래밍 I - R 설치 및 환경설정", "url": "/posts/R_for_Bioinformatics_1/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, R", "date": "2023-07-27 07:40:04 +0900", "snippet": "본 post는 LAIAD에서 제공하는 부산대학교 이해승 교수님의 생물정보학을 위한 R프로그래밍을 정리한 내용입니다.Intro R 프로그래밍 기초를 익힙니다. R을 활용한 전사체 정보를 분석합니다. 데이터 분석 과정데이터 분석 과정은 다섯 개의 단계로 구성됩니다. 데이터 준비부터 데이터 분석까지 효율적인 작업이 필요한데, 이 때 R과 같이 다양한 언어와 tool을 사용할 수 있습니다.데이터 분석 과정 다섯 단계https://www.laidd.org/local/ubonline/view.php?id=181&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==SPSS, SAS, STATA는 유료이며 프로그래밍 기능이 약해서 요구사항에 딱 맞는 맞춤처리가 약합니다. 반면 R, python은 무료이며 프로그래밍 기능이 강합니다. 또한 오픈 커뮤니티를 통한 무수한 라이브러리가 존재하고 배우기 쉽습니다. Python이 범용 프로그래밍 언어라면, R은 통계 특화 언어이며 시각화가 뛰어납니다. R은 1993년 뉴질랜드 오클랜드 대학의 Robert Gentleman과 Ross Ihaka가 개발한 프로그래밍 언어입니다.보조자료 및 참고 사이트는 아래와 같습니다. 도구 R 다운로드: https://www.r-project.org R 스튜디오: https://www.rstudio.com/products/rstudio/#Desktop Sublime Text: https://www.sublimetext.com 데이터 저장소 CRAN: http://cran.r-project.org Bioconductor: https://www.bioconductor.org 캐글: https://www.kaggle.com R 다운로드 및 설치 후 기본 명령어를 실행해 봅니다.print(&quot;Hello&quot;) # printdata() # default datasetR cmd: data()https://www.laidd.org/local/ubonline/view.php?id=181&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==‘str’ 함수는 데이터의 내용을 요약해서 보여줍니다. 이 때 색깔을 지정하는 옵션 col, 축의 이름을 지정하는 xlab, ylab, 기호 모양을 지정하는 pch를 사용할 수 있습니다.str(cars)plot(cars, col=&#39;blue&#39;)plot(cars, col=&#39;blue&#39;, xlab=&#39;속도&#39;)plot(cars, col=&#39;blue&#39;, xlab=&#39;속도&#39;, ylab=&#39;거리&#39;)plot(cars, col=&#39;blue&#39;, xlab=&#39;속도&#39;, ylab=&#39;거리&#39;, pch=18)R cmd: plot()https://www.laidd.org/local/ubonline/view.php?id=181&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==Rstudio는 R을 효과적으로 편리하게 사용할 수 있게 도와주는 통합 개발 환경(IDE; Integrated Development Environment)입니다.Rstudio 개발 환경은 콘솔창, 스크립트창, 환경창, 그리고 파일창으로 구성되어 있습니다. 콘솔창 코드 실행 및 결과, 오류 확인 등 스크립트창 코드 작성 창 콘솔창과 달리 긴 코드 작성에 용이 별도의 코드파일(.R)로 저장/불러오기 가능 함수에 대한 자동완성 그낭 제공 환경창 입력된 데이터 세트 확인 실행한 명령어, 결과 등 확인 DB서버와 연결 관리 파일창 파일 탐색기, 그래프 출력, 패키지 관리, 도움말 Rstudiohttps://www.laidd.org/local/ubonline/view.php?id=181&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPSZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==Take Home Message R과 Rstudio를 설치하고 기본 사용법을 익힙니다." }, { "title": "Big Data in Precision Oncology - TCGA 데이터베이스의 이해 및 활용", "url": "/posts/Big_Data_in_Precision_Oncology2/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, bigdata, TCGA, cancer", "date": "2023-07-25 07:02:45 +0900", "snippet": "본 post는 LAIAD에서 제공하는 가톨릭의과대학 김태민 교수님의 Big Data in Precision Oncology를 정리한 내용입니다.Intro TCGA 멀티오믹스 데이터의 형태 및 분석 활용법을 학습합니다. mRNA/miRNA의 형태 및 응용분석 예제를 학습합니다. Mutation, SCNA, methylation의 형태 및 응용분석 예제를 학습합니다. TCGA data 분석: mRNA/miRNA ExpressionTCGA publication data에서 논문 출판에 사용된 RNA, RPPA, methylation 등 분석 data를 다운로드 받을 수 있습니다.mRNA/miRNA expression data는 보통 아래와 같은 형태로 표현합니다. N개의 샘플별로 M개의 genes에 대한 각각 발현율을 숫자로 표시합니다. 이 때 발현율은 normalized intensity(microarray)나 RPKM/RSEM(RNA-seq)으로 표현합니다.Standard Format for mRNA/miRNA Expressionhttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==TCGA에서 mRNA/miRNA expression data를 다운로드 받아 살펴봅니다. 파일 size는 1.8G 정도로 큰 편에 속합니다. Standard format과 마찬가지로 각 샘플에 대해 gene별로 발현량이 표시되어 있습니다.TCGA Format for mRNA/miRNA Expressionhttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==다운로드 받은 파일을 input으로 ‘consensus clustering’을 실습합니다.data = read.table(&quot;unifiedScaledFiltered.txt&quot;, header=T, sep=&quot;\\t&quot;, row.names=1)head(data)boxplot(data)heatmap(as.matrix(data))source(&quot;https://bioconductor.org/biocLite.R&quot;)biocLite(&quot;ConsensusClusteringPlus&quot;) # install an R package!library(&quot;ConsensusClusteringPlus&quot;) # load the installed packageresult = ConsensusClusteringPlus(as.matrix(data), maxK=10, reps=1000, pItem=0.8, title=&quot;TCGA GBM&quot;, plot=&quot;pdf&quot;)Consensus Clustering of GBM Expression Datahttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==Consensus Clustering of GBM Expression Datahttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==Consensus Clustering of GBM Expression Datahttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==TCGA data 분석: DNA Copy Number AlterationsCopy number alterations는 microarray와 NGS 방식으로 모두 검출할 수 있습니다.Copy Number Alterationshttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==CNA data는 genome상의 각 구간별로 normalized ratio로 표현할 수 있습니다. 하지만 각 구간을 target으로 하는 probe 전체를 나열하면 굉장히 많은 양의 row가 필요합니다. 따라서 보통 비슷한 ratio를 가진 영역끼리 모아서 하나의 구간으로 표현하고 이를 seg 파일로 형태로 표현합니다. 아래 예시에서도 10개 구간으로 표현된 level2 data를 2개 구간으로 줄인 level3 data로 표현할 수 있습니다.Seg 파일https://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==seg 파일은 IGV에 load해서 visualization 할 수 있습니다.Seg on IGVhttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==TCGA data 분석: Somatic MutationsMutation 분석 결과는 보통 vcf format으로 표기하며 가장 일반적인 format 입니다. TCGA는 방대한 project이므로 자체적으로 만든 mutation format을 사용했는데 이를 MAF(Mutation Annotation Format)라고 일컫습니다.VCF and MAF Formathttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==Lung adenocarcinoma 환자가 가지고 있는 somatic mutation에 따라 EGFR inhibitor(Gefitinib)가 치료제로서 작동여부가 결정됩니다. Precision medicine의 대표적인 사례입니다.EGFR Inhibitorhttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==Take Home Message TCGA 멀티오믹스 데이터의 형태 및 분석 활용법에 대해 알아보았습니다." }, { "title": "AMP Guideline", "url": "/posts/AMP_guideline/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, AMP, cancer", "date": "2023-07-24 07:10:04 +0900", "snippet": "Intro AMP guideline에 대해 알아봅니다.AMP guidelineAMP Guideline은 2017년 AMP(Association for Molecular Pathology)에서 발표한 NGS 변이 해석 가이드라인으로 ‘Standards and Guidelines for thr Interpretation and Reporting of Sequence Variants in Cancer’ 논문으로 발표했습니다. 논문의 내용을 살펴보며 AMP 가이드라인이 어떤 원리로 동작하고 어떤 규칙을 가지고 있는지 알아봅니다.AbstractAMP 가이드라인은 다양한 그룹의 연구자들이 NGS로 검출된 somatic 변이에 대해 통일된 classification, annotation, interpretation, reporting convention을 정리하고 있습니다. 전문가들의 설문조사와 합의, 문헌 검토를 바탕으로 somatic 변이를 네 단계로 분류하는 4-tiered 시스템이 만들어 졌습니다.- tier I: variants with strong clinical significance- tier II: variants with potential clinical significance- tier III: variants of unknown clinical significance- tier IV: variants deemed benign or likely benignCancer genomics는 급격하게 발전하는 분야이므로, 치료, 진단, 혹은 예방과 관련된 변이의 임상적 중요도는 매번 재평가되어야 합니다. 유전적 변이는 AMP 가이드라인을 준수하여 리포팅 해야합니다. 임상적 권장사항은 간결해야 하며 조직학적 소견과 임상적 소견과 함께 연관되어야 합니다.NGS 기술 발전으로 변이 분석에 들어가는 비용과 시간은 대폭 감소했습니다. 분석 가능한 변이도 SNVs(single-nucleotide variants) 뿐만 아니라 indels, CNVs(copy number variants), fusions까지 범위가 넓어졌습니다.Tumor DNA, RNA에서 얻은 분자생물학적 profile은 암환자의 임상적 관리에 대한 가이드가 될 수 있습니다. 진단이나 예측에 필요한 정보를 제공할 수 있고, 가능한 치료방법이나 타겟 치료를 찾을 수 있도록 도움이 될 수 있습니다.Tumor tissue 대상 실시하는 NGS 검사에 대한 광범위한 접근을 위해서 4주 동안 NGS technical 설문 조사와 NGS reporting 설문 조사를 실시했습니다. 결과는 아래와 같습니다.NGS technical &amp;amp; reporting surveyhttps://doi.org/10.1016%2Fj.jmoldx.2016.10.002본 가이드라인의 목적은 cancer 대상 NGS 검사결과로 검출된 변이의 classification, annotation, interpretation, reporting의 표준방식을 수립하기 위함입니다.Databases  Genomic Databases다양한 tumor 종류 대상 large-scale genome sequencing project가 점점 증가하고 논문으로 발표됨에 따라 풍부한 genomic information을 바탕으로 많은 public database가 생성되고 있습니다. 예를 들어, TCGA(The Cancer Genome Atlas), COSMIC(the Catalog of Somatic Mutations in Cancer)와 같은 somatic 변이 database가 있습니다. Reference sequence information, population databases, germline variant databases 등이 분석에 자주 사용되고 있습니다. 이런 database는 somatic 변이의 정확한 annotation과 prioritization에 필수적인 정보를 제공합니다. 임상실험실은 public database 사용에 대한 아래 주의사항들을 반드시 준주해야 합니다.1. Database content와 어떻게 만들어졌는지 이해해야 합니다. 관련 논문을 리뷰하고 database의 source, type, 목적을 이해해야 합니다.2. Database의 한계를 이해하고 annotation 결과에 대한 과해석을 방지해야 합니다.3. Human genome assembly 버전과 mRNA transcript reference를 확인해야 합니다. 모든 정보는 HGVS(Human Genome Variation Society) annotation 규칙을 따라야 합니다.4. Database에 대한 불분명한 query 요청을 막기 위해서 가능하다면 HGVS nomenclature 대신 genomic coordinates를 사용합니다.5. Database가 제공하는 genomic data의 quality를 확인합니다. the number of a specific entry, single or multiple, the depth of the study, the use of appropriate controls, confirmation of a variant&#39;s somatic origin, functional and potential drug studies 등을 확인합니다.6. Pathological diagnosis에 대한 data quality를 확인합니다. (eg, site, diagnosis, and subtype) &amp;lt;br&amp;gt;&amp;lt;br&amp;gt; Utility/function Database Location (web address) Population database to &amp;lt;/br&amp;gt;exclude polymorphisms 1000 Genome Project http://browser.1000genomes.org   Exome Variant Server http://evs.gs.washington.edu/EVS   dbSNP http://www.ncbi.nlm.nih.gov/snp   dbVar http://www.ncbi.nlm.nih.gov/dbvar   ExAC http://exac.broadinstitute.org Cancer-specific &amp;lt;/br&amp;gt;variant databases Catalog of Somatic Mutations in Cancer http://cancer.sanger.ac.uk/cosmic   My Cancer Genome http://www.mycancergenome.org   Personalized cancer therapy, MD Anderson Cancer Center https://pct.mdanderson.org   cBioPortal, Memorial Sloan Kettering Cancer Center http://www.cbioportal.org   Intogen https://www.intogen.org/search   ClinicalTrials.gov https://clinicaltrials.gov   IARC(WHO) TP53 mutation database http://p53.iarc.fr   Pediatri Cancer Genome Project(St. Jude Children’s Research Hospital-Washington University) http://explorepcgp.org   International Cancer Genome Consortium https://dcc.icgc.org Sequence repositores &amp;lt;/br&amp;gt;and data hosts NCBI Genome http://www.ncbi.nlm.nih.gov/genome   RefSeqGene http://www.ncbi.nlm.nih.gov/refseq/rsg   Locus Reference Genomic http://www.lrg-sequence.org   UCSC table browser https://genome.ucsc.edu/cgi-bin/hgTables   Ensemble BioMart http://useast.ensembl.org/biomart/martview Other disease/mutation databases &amp;lt;/br&amp;gt;useful in the context of variant interpretation &amp;lt;/br&amp;gt;for cancer genomics ClinVar http://www.ncbi.nlm.nih.gov/clinvar   Human Gene Mutation Database http://www.hgmd.org   Leiden Open Variation Database http://www.lovd.nl   dbNSFP(compiled database of precomputed in silico prediction scores for nonsynonymous SNVs) https://sites.google.com/site/jpopgen/dbNSFP   Ensemble Variant Effect Predictor http://www.ensembl.org/info/docs/tools/vep/index.html   Reference Sequence DatabasesReference sequence database는 human genome assembly에 대한 version과 genomic coordinates와 같은 관련 정보를 제공합니다. 유전자에 대한 variant location mapping(coding, noncoding, untranslated region, and splice site)과 strand representation(positive versus negative)도 database로부터 계산할 수 있습니다. RefSeq, Ensembl, Locus Reference Genomic database를 사용할 수 있습니다.  Population Databases지리학적으로 분리된 population을 대표하는 개인들의 유전자 분석결과에서 특정 locus의 alternative(minor) alleles의 빈도를 제공하는 database입니다. 주로 유전자 분석결과 polymorphic/benign으로 보이는 변이를 filter out 할 때 사용합니다. 이 때 기준점을 MAF(minor allele frequency)로 사용하는데, 수치는 1%(0.01)로 잡는 것을 권장하며 규정된 값은 아닙니다. 해당 database를 사용할 때 주의해야 할 사항 중 하나는 study 참여 당시 대상자는 모두 건강하고 질병이 없는 상태로 간주했다는 점입니다. 게다가 몇몇 전통적으로 cancer-associated로 알려진 targetable somatic 변이가 일부 population database 에서는 germline 변이로 포함되어 있습니다.예를 들어, NM_004972.3(JAK2):c.1849G&amp;gt;T(c.V617F)는 myeloproliferative neoplasms에서 somatic 변이로 잘 알려져 있으며, FDA 승인 약물인 JAK(Janus kinase) inhibitor의 target으로 알려져 있습니다. 이처럼 hematological malignancies에서 검출된 변이를 평가할 때는 특별히 많은 주의를 기울어야 하는데, leukemia와 myeloodysplastic syndromes에서 발견되는 일반적인 유전자 변이가 blood 내에서 somatically mutated 되었을 가능성이 있기 때문입니다.  Cancer-Specific Databases여러 가지 cancer 종류와 subtypes에 걸쳐 sequence variants의 발병률과 유병률에 대한 정보를 제공하는 database입니다.  Internal(Laboratory-Generated) Databases임상검사실은 검사실 내 변이를 추적하고 일관적으로 변이 annotation 정보를 제공하기 위해 well-annotated in-house database를 구축하는 것이 중요합니다. Cancer type별로 변이의 빈도를 확인하면, sequencing alignment artifacts나 false-positive 의심 변이를 확인할 수 있습니다.In Silico(Computational) Prediction AlgorithmsIn silico 예측 알고리즘은 유전자에서 발생한 nucleotide change가 단백질의 구조와 기능에 변화를 일으킬 수 있는지 예측하는데 주로 사용합니다. 분석 tool은 크게 두 가지 종류로 나뉘는데, 단백질 기능에 있어서 missense 변이가 미치는 영향력 예측, 그리고 splicing site에서 sequence variant가 미치는 영향력 예측입니다. Utility/function Algorithm/software Location (web address) Missense SNV PolyPhen2 http://genetics.bwh.harvard.edu/pph2   SIFT http://sift.jcvi.org   MutationAssessor http://mutationassessor.org   MutationTaster http://www.mutationtaster.org   PROVEAN http://provean.jcvi.org/index.php   Condel http://bg.upf.edu/blog/2012/12/condel-for-prioritization-of-variants-involved-in-hereditary-diseases-and-transfic-for-cancer   CoVEC https://sourceforge.net/projects/covec/files   CADD http://cadd.gs.washington.edu   GERP++ http://mendel.stanford.edu/sidowlab/downloads/gerp/index.html   PhyloP and PhastCons http://compgen.bscb.cornell.edu/phast Splice site prediction Human Splicing Finder http://www.umd.be/HSF3   MaxEntScan http://genes.mit.edu/burgelab/maxent/Xmaxentscan_scoreseq.html   NetGene2 http://www.cbs.dtu.dk/services/NetGene2   NNSplice http://www.fruitfly.org/seq_tools/splice.html   GeneSplicer http://www.cbcb.umd.edu/software/GeneSplicer/gene_spl.shtml Variant Identification and Annotation변이 확인은 변이 해석 과정에 있어서 중요한 시작점입니다. Variant calling 결과는 전형적인 결과 포맷 중 하나로 표현합니다; VCF(variant call format), gVCF(genomic VCF), GFF(generic feature format)Variant annotation 또한 somatic sequence 변이를 정확하게 해석하기 위해 필요한 중요한 과정입니다. 난제 중 하나는 변이의 genomic coordinates(chromosome and position)를 이에 상응하는 cDNA/amino acid coordinate system(c. and p. syntax, respectively)로 변환하는 것입니다. 특히 alignment에 있어서 난해함이 있는 indel 변이에서 문제가 되는데, HGVS system에서는 right-aligned(더 이상 옮기지 못할 때까지 변이의 시작점을 오른쪽으로 이동시키는 것) 표현을 권장하지만 VCF는 left-aligned 표기를 필요로 합니다.TCGA Sample Annotationttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==Standard quality metric을 제시한 논문 중 하나로, Earth BioGenome Project의 Supplementary Figure S1에 자세히 기술되어 있습니다. x score: \\(10^{x}\\) = N50 contig length in kb. 만약 x가 3이라면 contig의 N50이 1,000kb임을 의미합니다. y score: \\(10^{y}\\) = N50 scaffold length in kb. 만약 y가 1이라면 scaffold의 N50이 10kb임을 의미합니다. z score: contig, scaffold 제작 과정에 문제가 없었는지 얼마나 자세히 확인했는가 나타내는 지표입니다. 3단계(0, 1, 2)로 표현합니다. 해당 논문에서 high-quality reference assembly standard를 ‘2.3.2.QV40’으로 제시하고 있습니다. 이는, contig N50 100kb 이상 scaffold N50 1,000kb 이상 길이로 따졌을 때 90% 이상의 contig가 scaffold에 포함되고 fusion/fission/translocation 등이 다른 실험 방법으로 확인됐는지 검증한 것 을 의미합니다.Contig LengthN50은 quality metric 중 하나로 read/contig/scaffold에 모두 적용됩니다.우선 read/contig/scaffold를 길이가 긴 것부터 정렬합니다. 그 길이를 순차적으로 하나씩 더했을 때, 전체 길이의 절반이 넘는 순간 그에 해당하는 read/contig/scaffold의 길이를 N50으로 정의합니다. 그림에서 전체 길이는 135bp이며 50%는 약 68bp입니다. 길이가 긴 것부터 정렬한 뒤 68bp를 넘는 시점의 read/contig/scaffold는 30bp입니다. 즉, N50은 30bp입니다.N50https://www.edwith.org/longread-seq-2023/lecture/1475113NGx plot은 각 contig의 길이(=y축: contig나 scaffold length)와 누적 합을 전체 genome length로 나눈 비율(=x측: cumulative coverage)로 표현한 plot입니다.)NGx Plothttps://www.edwith.org/longread-seq-2023/lecture/1475113BUSCOBUSCO(Benchmarking Universal Single-Copy Orthologs)는 기존에 알려진 lineage-specific single-copy ortholog 유전자들이 제대로 assembly 됐는지 확인하는 tool입니다. BUSCO Plothttps://www.edwith.org/longread-seq-2023/lecture/1475113Take Home Message Contig length 기반으로 assembly quality를 비교할 수 있습니다. BUSCO를 활용할 수 있습니다. " }, { "title": "Big Data in Precision Oncology - TCGA 및 암유전체 빅데이터 개요", "url": "/posts/Big_Data_in_Precision_Oncology1/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, bigdata, TCGA, cancer", "date": "2023-07-21 07:34:10 +0900", "snippet": "본 post는 LAIAD에서 제공하는 가톨릭의과대학 김태민 교수님의 Big Data in Precision Oncology를 정리한 내용입니다.Intro TCGA 및 ICGC 등의 데이터베이스 개요 및 구조를 학습합니다.TCGA (The Cancer Genome Atlas Program)TCGA는 NIH에서 2005년부터 2015년까지 진행된 프로젝트 입니다. 20,000개 이상의 primary cancer에 대한 분자생물학적 특징과 33개 이상의 cancer type에 대해 확인했습니다. Pan-America 프로젝트로 NHGRI(The National Human Genome Research Institute), NCI(The National Cancer Institute), NIH(The National Institute of Health)에서 funding을 받았으며 미국 주도로 진행되었습니다. Human genome project의 계보를 이어 TCGA 프로젝트가 진행되었고 그 결과 오바마 행정부의 Precision medicine initiatives로 이어졌습니다.before and after TCGAhttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==TCGA Pilot Phase(2008~2012)TCGA Pilot 프로젝트는 GBM(Glioblastoma multiforme)과 OV(Srous ovarian cacners)에 대해 진행됐습니다.The first project에서는 GBM과 연관된 gene과 핵심 pathways를 확인했습니다. Gene sequencing, DNA copy number, DNA methylation, Transcrpitome, MicroRNA 등 다섯 가지 목적에 각각 알맞은 플랫폼을 사용하여 분석을 진행했습니다. 당시에는 NGS 기술이 출시되기 이전이므로 microarray, sanger sequencing 기반 플랫폼이 사용되었습니다.The second project에서는 OV와 연관된 분석이 진행됐습니다.TCGA Sample AnnotationTCGA 샘플은 아래와 같은 annotation 체계를 따릅니다.처음 열 두 자리는 환자의 unique id입니다. 마지막 두 자리는 tumor(01)인지, matched normal(10 or 11)인지 나타내는 id입니다.TCGA Sample Annotationhttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==TCGA data는 다음과 같이 네 개 단계의 level로 구분되어 있습니다. 원하는 data를 다운로드 받아 연구에 사용할 수 있습니다.Levels of TCGA Datahttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==TCGA project가 종료된 후 2018년 4월 Cell에 논문으로 publish 되었습니다.Pan-Cancer Atlashttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==TCGA 사용TCGA 데이터는 NCI GDC에서 다운로드 받을 수 있습니다. TCGA 사이트에서 BRCA mutation 정보를 찾는 예시입니다.BRCA in TCGAhttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==실제 data는 ‘open’과 ‘controlled’로 구분되는데, 개인정보가 담긴 data이므로 ‘controlled’는 TCGA에서 승인된 연구자만 다운로드 받을 수 있습니다.TCGA Datahttps://www.laidd.org/local/ubonline/view.php?id=141&amp;amp;group=1&amp;amp;returnurl=aHR0cHM6Ly93d3cubGFpZGQub3JnL2xvY2FsL3Vib25saW5lL2luZGV4LnBocD9vcmRlcnR5cGU9cmNfZCZrZXl3b3JkPUJJRyZwcm9ncmVzcyU1QiU1RD0xMyZlbnJvbF9zdGFydD0mZW5yb2xfZW5kPSZzdHVkeV9zdGFydD0mc3R1ZHlfZW5kPQ==TCGA data는 그 외에도 ‘Brooad Firehose’, ‘cBioPorta’, ‘UCSC Xena browser’, 연구논문의 supplementary 등에서 다운로드 받을 수 있습니다.ICGC-PCAWG ProjectTCGA에 이어서 진행된 대규모 project 입니다. ICGC는 처음에 WES와 WGS 두 가지 플랫폼을 모두 모으는 25k Initiative project를 진행 했습니다. 이후 WGS 중 high quality 샘플만 모아서 PCAWG(Pan-Cancer Analysis of Whole Genome)이 진행되었습니다.ICGC data는 ICGC Data Portal에서 확인 및 다운로드 받을 수 있습니다.Summaries &amp;amp; Other Public Resources| Database | Size | Drugs | Genome Data | Open || —– | —– | —– | —– | —– || GDSC ver1 | 987 cell lines | 320 | SNV(exome), CNV(exome), methylation, gene expression | open(EGA, GEO, ArrayExpress 경유) || GDSV ver2 | 809 cell lines | 185 | SNV(exome), CNV(exome), methylation, gene expression | open(EGA, GEO, ArrayExpress 경유) || CCLE | 1,500 cell lines | 24 (for 500 cell lines) | SNV(exome), CNV(exome), methylation, gene expression, RPPA | open || TCGA | 10,000 cancer patient | 기본 임상 정보 | SNV, CNV, methylation, mRNA/miRNA expression | open || ICGC(1st) | 3,000 cancer patient | 기본 임상 정보 | WGS | processed data만 open || ICGC(2nd) | over 100,000 cancer patient (예정) | 약물정보 포함한 표준화된 임상정보 | WGS | 예정 |Take Home Message TCGA 및 ICGC 등의 데이터베이스 개요 및 구조에 대해 알아보았습니다." }, { "title": "PRS(Polygenic Risk Score)", "url": "/posts/Polygenic_Score/", "categories": "Bioinformatics, Biology", "tags": "BI, bioinformatics, PRS", "date": "2023-07-17 07:10:20 +0900", "snippet": "본 post는 BROAD INSTITUTE의 Polygenic Scores 사이트를 정리한 내용입니다.PRS(Polygenic Risk Score)PRS는 한 사람의 유전정보에 근거하여 특정 질환의 위험도를 예측하는데 사용하는 score 입니다.특정 질환 발병위험에 대한 유전적 배경지식을 아는 것은 당신의 건강과 관련된 중요한 결정을 하는데 도움을 줄 수 있습니다.Genetic Variation모든 사람은 부모에게서 유전된 유전정보를 가지고 있습니다. 유전정보는 units of information으로 구성되어 있는데, 신체가 기능하는데 필요한 정보를 담고 있습니다.Unit of informationhttp://polygenicscores.org/explained/개인 간 비교했을 때 대부분 유전정보는 동일하고 일부에서만 차이가 나는데, 이를 genetic variants라고 일컫습니다.Genetic variantshttp://polygenicscores.org/explained/Genetic variants는 eye color, height, taste preferences와 같이 개인을 unique하게 만드는 trait 형성에 기여합니다.Genetic variantshttp://polygenicscores.org/explained/Genetic variants는 또한 특정 질병의 발병 위험도에 영향을 줄 수도 있는데, 이를 risk variants라고 일컫습니다.Risk variantshttp://polygenicscores.org/explained/Risk Variants특정 질병의 위험도를 높히는 risk variants를 찾기 위해서, 연구자들은 해당 질병을 가진 사람들과 정상 사람들의 유전정보를 비교합니다.Discovering risk variantshttp://polygenicscores.org/explained/만약 해당 질병을 가진 사람들에게서 더 빈번하게 나타나는 genetic variants는 해당 질병의 발병 위험도 증가와 연관되어 있다고 추정할 수 있습니다.Discovering risk variantshttp://polygenicscores.org/explained/만약 해당 질병을 가지지 않은 정상 사람들에게서 더 빈번하게 나타나는 genetic variants는 해당 질병의 발병 위험도 감소와 연관되어 있다고 추정할 수 있습니다.Discovering risk variantshttp://polygenicscores.org/explained/이처럼 risk variants는 한 사람에게서 특정 질병의 발병 위험도를 증가시키거나 감소시킬 수 있습니다.그리고 각각 risk variant는 서로 다른 크기의 영향력을 가지고 있습니다. 일부는 위험도에 큰 영향력을 가지고, 일부는 작은 영향력을 가집니다.또한 하나의 risk variant는 상대적으로 작은 영향력을 가지지만, 그 숫자가 늘어날수록 상대적으로 더 큰 영향력을 가집니다.Different Impact of Risk Variantshttp://polygenicscores.org/explained/Polygenic score는 모든 risk variants가 지니는 영향력을 한 번에 계산하고 특정 질병에 대한 개인의 발병 위험도를 예측하는데 사용하는 지표입니다.Polygenic Score Calculation특정 질병에 대한 개인의 polygenic score를 계산하기 위해서 연구자들은 risk-increasing variants와 risk-decresing variants의 전체 숫자와 영향력 정도를 합산합니다.Polygenic Score Calculationhttp://polygenicscores.org/explained/Polygenic score는 특정 질병에 대해 다른 사람들과 비교해서 대상자의 위험도가 어느 정도인지 알려줍니다.Polygenic Score Calculationhttp://polygenicscores.org/explained/연구자들은 전체 population에 대해서 polygenic score를 확인할 수 있습니다.Polygenic Score Calculationhttp://polygenicscores.org/explained/개인이 가지고 있는 risk-increasing variants와 risk-decreasing variants의 숫자, 그리고 각 varinat가 지니는 영향력에 따라 상대적으로 높거나 혹은 낮은 polygenic score를 나타냅니다.Polygenic Score Calculationhttp://polygenicscores.org/explained/거의 같은 개수의 risk-increasing variants와 risk-decreasing variants를 가지는 사람은 해당 질병의 발병 위험도가 평균 수준이라고 볼 수 있습니다.Polygenic Score Calculationhttp://polygenicscores.org/explained/더 많은 개수의 risk-increasing variants를 가지는 사람은 해당 질병의 발병 위험도가 상대적으로 더 높은 수준이라고 볼 수 있습니다.Polygenic Score Calculationhttp://polygenicscores.org/explained/더 많은 개수의 risk-decreasing variants를 가지는 사람은 해당 질병의 발병 위험도가 상대적으로 더 낮은 수준이라고 볼 수 있습니다.Polygenic Score Calculationhttp://polygenicscores.org/explained/Polygenic Score Interpretation대부분 사람들은 질병의 발병 위험도가 평균 수준입니다.Polygenic Score Interpretationhttp://polygenicscores.org/explained/Polygenic score가 평균보다 높다는 것은 대부분 사람들과 비교해서 해당 질병의 발병 위험도가 증가 되었음을 의미합니다.만약 polygenic score가 95th percentile이라면, 질병의 발병 위험도가 95%라는 의미가 아닙니다.100명 중 95명보다 더 높은 polygenic score라는 의미인 동시에 5명과 같거나 더 낮은 polygenic score라는 의미입니다.Polygenic Score Interpretationhttp://polygenicscores.org/explained/Polygenic score가 평균보다 낮다는 것은 대부분 사람들과 비교해서 해당 질병의 발병 위험도가 감소 되었음을 의미합니다.만약 polygenic score가 5th percentile이라면, 질병의 발병 위험도가 5%라는 의미가 아닙니다.100명 중 5명보다 더 높은 polygenic score라는 의미인 동시에 95명과 같거나 더 낮은 polygenic score라는 의미입니다.Polygenic Score Interpretationhttp://polygenicscores.org/explained/DNA is not destinu - additional factors influence your riskPolygenic score는 개인이 가지고 태어난 유전정보만을 바탕으로 계산된 지표입니다.아무리 열심히 노력해도 polygenic score를 바꿀 수 없지만, 건강한 식습관과 생활습관, 금연 등의 노력으로 발병 위험도를 줄일 수는 있습니다." }, { "title": "Advanced Sort Algorithm - Quick Sort", "url": "/posts/Algorithm_Advanced_Sort_Quick/", "categories": "Programming, Algorithm", "tags": "algorithm, sort, python", "date": "2023-07-16 13:02:04 +0900", "snippet": "퀵 정렬퀵 정렬은 병합 정렬과 마찬가지로 분할 정복(Devide and Conquer) 기법과 재귀 알고리즘을 이용한 정렬 알고리즘 입니다.임의의 값을 한 개 정한 뒤, 그보다 작은 값은 왼쪽으로 위치시키고 큰 값은 오른쪽으로 위치시킵니다. 이후에는 분리된 왼쪽, 오른쪽 배열들 내에서만 위 과정을 반복해서 정렬하면 되는 알고리즘 입니다.파이썬의 list.sort() 함수도 퀵 정렬을 사용하는데 프로그래밍 언어 내장 정렬 함수는 대부분 퀵 정렬을 기본으로 사용할만큼 많이 사용됩니다.[5, 3, 7, 1, 4, 2, 6, 8]# 배열에서 임의의 값을 정합니다. s[5, 3, 7, 1, 4, 2, 6, 8]# s를 중심으로 그보다 작은 값은 왼쪽# 큰 값은 오른쪽으로 위치시킵니다.[3, 1, 2] &amp;lt; [4] &amp;lt; [5, 7, 6, 8]# 왼쪽 배열에서 다시 임의의 값을 정한 뒤 위 과정을 반복합니다. s[3, 1, 2] s[1] &amp;lt; [3, 2][2] &amp;lt; [3]# 오른쪽 배열도 마찬가지로 반복합니다. s[5, 7, 6, 8][5] &amp;lt; [6] &amp;lt; [7, 8] s[7] &amp;lt; [8]# 지금까지 왼쪽, 오른쪽으로 분할했던 값을 모두 합칩니다.[1, 2, 3, 4, 5, 6, 7, 8]구현# 정렬 대상 배열array = [5, 3, 7, 1, 4, 2, 6, 8]def quick_sort(array): if len(array) &amp;lt;= 1: return array array_length = len(array) middle_num = array[array_length // 2] left_array = [] equal_array = [] right_array = [] for num in array: if num &amp;lt; middle_num: left_array.append(num) elif num &amp;gt; middle_num: right_array.append(num) else: equal_array.append(num) return quick_sort(left_array) + equal_array + quick_sort(right_array)print(quick_sort(array))시간 복잡도퀵 정렬의 시간 복잡도는 어떤 기준값을 잡느냐에 따라 크게 달라질 수 있습니다. 가장 이상적인 경우에는 기준값을 중심으로 left, right 배열이 동일한 개수로 분할되고, 병합 정렬과 마찬가지로 \\(\\theta(nlogn)\\) 의 시간 복잡도를 가집니다.하지만 기준값을 따라 분할했을 때 left나 right 배열 한 쪽으로 모든 값이 몰리면 \\(\\theta(n^{2})\\) 시간 복잡도를 가집니다." }, { "title": "Advanced Sort Algorithm - Merge Sort", "url": "/posts/Algorithm_Advanced_Sort_Merge/", "categories": "Programming, Algorithm", "tags": "algorithm, sort, python", "date": "2023-07-16 09:42:10 +0900", "snippet": "병합 정렬병합 정렬은 입력 배열을 절반으로 나눈 뒤 각각 독립적으로 정렬합니다. 그리고 마지막에 정렬된 두 배열을 병합하여 최종 정렬된 배열을 얻는 알고리즘 입니다. 즉, 분할 정복(Devide and Conquer) 기법과 재귀 알고리즘을 이용하여 정렬하는 알고리즘 입니다.[5, 3, 7, 1, 4, 2, 6, 8]# 배열을 둘로 나눕니다.[5, 3, 7, 1] [4, 2, 6, 8]# 다시 배열을 둘로 나눕니다.# 위 과정을 반복합니다.[5, 3] [7, 1] [4, 2] [6, 8][5] [3] [7] [1] [4] [2] [6] [8]# 나뉜 배열을 정렬하면서 합칩니다.[3, 5] [1, 7] [2, 4] [6, 8][1, 3, 5, 7] [2, 4, 6, 8][1, 2, 3, 4, 5, 6, 7, 8]구현# 정렬 대상 배열array = [5, 3, 7, 1, 4, 2, 6, 8]def merge_sort(array): if len(array) &amp;lt; 2: return array middle = len(array) // 2 left_array = merge_sort(array[:middle]) right_array = merge_sort(array[middle:]) merged_array = [] l = r = 0 while l &amp;lt; len(left_array) and r &amp;lt; len(right_array): if left_array[l] &amp;lt; right_array[r]: merged_array.append(left_array[l]) l += 1 else: merged_array.append(right_array[r]) r += 1 merged_array += left_array[l:] merged_array += right_array[r:] return merged_arrayprint(merge_sort(array))시간 복잡도병합 정렬의 시간 복잡도는 \\(\\theta(nlogn)\\) 입니다. 예제에서 배열을 절반으로 나누는 것은 8 → 4 → 2 → 1과 같이 반복 수가 줄어들기 때문에 \\(\\theta(logn)\\) 시간이 필요합니다. 또한 정렬한 뒤 다시 병합할 때 모든 값을 비교해야 하므로 \\(\\theta(n)\\) 시간이 필요합니다. 따라서 총 시간 복잡도는 \\(\\theta(nlogn)\\) 입니다." }, { "title": "Sort Algorithm - Insertion Sort", "url": "/posts/Algorithm_Sort_Insertion/", "categories": "Programming, Algorithm", "tags": "algorithm, sort, python", "date": "2023-07-15 20:10:04 +0900", "snippet": "삽입 정렬삽입 정렬은 이미 정렬되어 있는 i개짜리 배열에 하나의 원소를 더해서 i+1개까지 배열을 만드는 과정을 반복합니다. 선택 정렬, 버블 정렬은 n개까지 배열에서 시작하여 loop 크기를 1씩 줄여나가는 데 반해서, 삽입 정렬은 반대로 1개짜리 배열에서 1씩 늘려나가는 데 차이가 있습니다. i i+1[5, 3, 15, 34, 22, 45]# idx[i], idx[i+1]만 비교: idx[i] &amp;gt; idx[i+1]# 따라서 둘 자리를 변경하여 배열 생성 end[3, 5]# idx[i+2]와 idx[end] 비교: idx[i+2] &amp;lt; idx[end]# 따라서 둘 자리를 변경하지 않고 끝자리에 삽입[3, 5, 15]# 위 과정 반복 [3, 5, 15, 34][3, 5, 15, 22, 34][3, 5, 15, 22, 34, 45]구현# 정렬 대상 배열array = [5, 3, 15, 34, 22, 45]array_len = len(array)for end in range(1, array_len): i = end while i &amp;gt; 0 and array[i-1] &amp;gt; array[i]: # i, i-1 값 서로 변경 array[i-1], array[i] = array[i], array[i-1] i -= 1 print(array)시간 복잡도삽입 정렬의 수행 시간은 최대 \\(\\theta(n^{2})\\) 입니다. 하지만 버블 정렬과 같이 최적화 여지를 가진 알고리즘 입니다. 만약 전체 정렬된 배열이 들어온다면 시간 복잡도는 \\(\\theta(n)\\)까지 향상시킬 수 있습니다.선택 정렬, 삽입 정렬이 n개짜리 배열에서 시작하여 아직 정렬되지 않은 배열의 크기를 하나씩 줄이는 데 반하여, 삽입 정렬은 1개짜리 배열에서 시작하여 이미 정렬된 배열의 크기를 하나씩 늘리는 알고리즘 입니다." }, { "title": "Sort Algorithm - Bubble Sort", "url": "/posts/Algorithm_Sort_Bubble/", "categories": "Programming, Algorithm", "tags": "algorithm, sort, python", "date": "2023-07-15 17:22:51 +0900", "snippet": "버블 정렬버블 정렬은 제일 큰 원소를 끝자리로 옮기는 작업을 한다는 점에서 선택 정렬과 유사합니다. 다만 제일 큰 원소를 끝자리로 옮기는 방법이 상이합니다.배열 A[1, …, n]에서 \\(A[1]\\) 원소부터 순서대로 이웃한 오른쪽 원소와 비교합니다. 만약 올바르게 정렬되어 있지 않으면 둘의 자리를 바꿉니다. 올바르게 정렬되어 있다면 그대로 놓아둡니다. 다음 원소로 넘어가서 같은 작업을 반복합니다. j j+1[5, 3, 15, 34, 22, 45]# idx[j] &amp;gt; idx[j+1]# 따라서 둘 자리를 변경 j+1 j+2[3, 5, 15, 34, 22, 45]# idx[j+1] &amp;lt;&amp;gt; idx[j+2]# 따라서 둘 자리를 변경하지 않고 다음 원소 확인 j+2 j+3[3, 5, 15, 34, 22, 45]# idx[j+2] &amp;lt;&amp;gt; idx[j+3]# 따라서 둘 자리를 변경하지 않고 다음 원소 확인# 위 과정 반복 [3, 5, 15, 22, 34, 45]구현# 정렬 대상 배열array = [5, 3, 15, 34, 22, 45]array_len = len(array)for i in range(array_len-1, 0, -1): for j in range(i): # 배열의 sorting 여부 확인 변수 check_sorted = True if (array[j] &amp;gt; array[j+1]): # j, j+1 값 서로 변경 array[j], array[j+1] = array[j+1], array[j] check_sorted = False if check_sorted == True: break print(array)시간 복잡도버블 정렬의 수행 시간은 일반적으로 \\(\\theta(n^{2})\\) 입니다. 하지만 최적화 여지를 가진 알고리즘이라는 점에서 선택 정렬과 차이가 있습니다. 만약 어느 단계에서 j, j+1 원소간 자리 이동이 단 한 번도 일어나지 않았다면, 배열이 모두 정렬되었음을 의미하며 바로 정렬작업을 종료할 수 있습니다.우선 첫 번째 for loop에서 모든 index에 접근해야 하므로 (n)번 수행합니다. 가장 오른쪽 제일 큰 원소를 제외한 나머지 (n-1)개 원소와 비교하므로 (n-1)번 수행합니다. 따라서 총 횟수는 \\((n-1)+(n-2)+...+2+1 = \\frac{n(n-1)}{2}\\) 입니다. 시간 복잡도는 \\(\\theta(n^{2})\\) 입니다.다만 앞서 언급한 내용과 같이, 부분적으로 정렬되어 있는 배열, 즉, 특정 index 이후 정렬되어 있는 배열이 들어온다면 더 이상 loop를 돌지 않고 종료할 수 있습니다. 예를 들어 완벽히 정렬된 배열이 들어온다면, 시간 복잡도는 \\(\\theta(n)\\)까지 향상시킬 수 있습니다." }, { "title": "Sort Algorithm - Selection Sort", "url": "/posts/Algorithm_Sort_Selection/", "categories": "Programming, Algorithm", "tags": "algorithm, sort, python", "date": "2023-07-15 10:40:02 +0900", "snippet": "선택 정렬선택 정렬은 원리가 간단한 정렬 알고리즘 중 하나입니다.배열 A[1, …, n]에서 가장 작은(or 큰) 원소를 찾아 배열의 첫(or 끝)자리에 있는 \\(A[1](or A[n])\\)과 자리를 바꿉니다. \\(A[1](or A[n])\\) 원소에 대한 배열은 끝났으므로 나머지 원소를 대상으로 같은 작업을 반복합니다.# 초기 min_idx = i = 0# 새로운 min_idx = j = 1 i[5, 3, 15, 34, 22, 45] m# min_idx[i] = 5 &amp;gt; min_idx[j] = 3# 따라서 두 개 값 위치를 변경함[3, 5, 15, 34, 22, 45]# idx = 0 위치는 정렬되었으므로, 다음 idx부터 위 과정 반복 i[3, 5, 15, 34, 22, 45] m i[3, 5, 15, 34, 22, 45] m i[3, 5, 15, 34, 22, 45] m i[3, 5, 15, 22, 34, 45] m i[3, 5, 15, 22, 34, 45] m구현# 정렬 대상 배열array = [5, 3, 15, 34, 22, 45]array_len = len(array)# 배열 길이만큼 for loop 실행for i in range(len(array)): # min value index min_idx = i for j in range(i+1, array_len): # 만약 새로운 min value 발견하면 if (array[min_idx] &amp;gt; array[j]): # min value index 변경 min_idx = j # min value 자리 변경 array[i], array[min_idx] = array[min_idx], array[i]print(array)시간 복잡도선택 정렬의 수행 시간은 모든 경우에 \\(\\theta(n^{2})\\) 입니다.우선 첫 번째 for loop에서 모든 index에 접근해야 하므로 (n)번 수행합니다. 이제 min_idx를 제외한 나머지 (n-1)개 index를 탐색하므로 (n-1)번 수행합니다. 따라서 min_idx를 비교하는 총 횟수는 \\((n-1)+(n-2)+...+2+1 = \\frac{n(n-1)}{2}\\) 입니다. 시간 복잡도는 \\(\\theta(n^{2})\\) 입니다." }, { "title": "(EDWITH-KOBIC) Data Analysis of Longread Sequencing", "url": "/posts/Certificate_Data_analysis_of_longread_sequencing/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, bioinformatics, KOBIC", "date": "2023-07-12 08:45:01 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "Long Read Sequencing VII - Visualization", "url": "/posts/Longread_sequencing7/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, pacbio, longread", "date": "2023-07-12 08:12:50 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 박사 후 연구원 김준님의 Visualization를 정리한 내용입니다.Intro Visualization에 가장 널리 쓰이는 circos plot에 대해 알아봅니다.Circos PlotCircos Plot은 chromosome, alignment, SNP/SV density를 plotting하는데 유용한 tool입니다.Human chromosome 별로 색상을 구분하여 그린 ideogram입니다.Human Ideogramhttps://www.edwith.org/longread-seq-2023/lecture/1475115Human chromosome 별로 gene density를 표현한 plot입니다.Gene Densityhttps://www.edwith.org/longread-seq-2023/lecture/1475115위 plot에 alignment까지 추가한 plot입니다.Gene Density with alignmentshttps://www.edwith.org/longread-seq-2023/lecture/1475115Take Home Message Circos를 이용하여 plot을 그릴 수 있습니다. Gene density 외에도 SNP, SV, read depth 등을 포함할 수 있습니다. Alignment를 이용해 다양한 관계를 표현할 수 있습니다. " }, { "title": "Long Read Sequencing VI - SV Calling", "url": "/posts/Longread_sequencing6/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, pacbio, longread", "date": "2023-07-12 07:38:04 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 박사 후 연구원 김준님의 SV Calling를 정리한 내용입니다.Intro Structural variant에 대해 배웁니다. SV calling pipeline을 실습합니다. SV(Structural Variant)5V는 50bp 이상의 variant를 의미합니다. Size 기준은 short-read sequencing으로 확인하기 어려운 variant를 SV로 정의했습니다. Translocation과 같이 size 측정이 어려운 variant도 포함합니다.SV calling은 크게 두 가지 방식이 존재합니다. Read-based SV calling pros: 적은 read depth로도 가능합니다. 즉, 비용이 저렴합니다. cons: False positive, false negative가 많습니다. 분석 시간이 좀 더 걸립니다. Assembly-based SV calling pros: 가장 정확합니다. 그리고 assembly만 되어있으면 분석 시간은 좀 더 짧습니다. cons: 20x 이상의 read depth가 필요합니다. 즉, 비용이 많이 듭니다. SV Callinghttps://www.edwith.org/longread-seq-2023/lecture/1475114Take Home Message SV는 50bp 이상의 거대한 variant이며 희귀질환의 원인이 되는 경우가 있습니다. SV calling은 read 또는 assembly 수준에서 할 수 있습니다. " }, { "title": "Long Read Sequencing V - Assembly Quality 확인", "url": "/posts/Longread_sequencing5/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, pacbio, longread", "date": "2023-07-11 07:52:52 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 박사 후 연구원 김준님의 Assembly Quality 확인를 정리한 내용입니다.Intro Assembly quality 확인하는 기본적인 방법들을 알아봅니다. 간단한 visualization 스크립트를 익힙니다. Assembly Quality란?유전체 지도의 품질을 반영하는 지표들이 몇 가지 존재합니다. Contiguity: 얼마나 잘 이어졌는지 반영하는 지표입니다. contig-level: contig가 길면 길수록 좋습니다. gene-level: known gene이 많이 잡히면 잡힐수록 좋습니다. chromosome: chromosome 수준으로 잘 조립되었는지 가늠하는 지표입니다. Assembly error: 각 수준에서의 error가 적으면 적을수록 좋습니다. base-level contig-level(mis-assembly) scaffold-level(mis-joining) Standard quality metric을 제시한 논문 중 하나로, Earth BioGenome Project의 Supplementary Figure S1에 자세히 기술되어 있습니다. x score: \\(10^{x}\\) = N50 contig length in kb. 만약 x가 3이라면 contig의 N50이 1,000kb임을 의미합니다. y score: \\(10^{y}\\) = N50 scaffold length in kb. 만약 y가 1이라면 scaffold의 N50이 10kb임을 의미합니다. z score: contig, scaffold 제작 과정에 문제가 없었는지 얼마나 자세히 확인했는가 나타내는 지표입니다. 3단계(0, 1, 2)로 표현합니다. 해당 논문에서 high-quality reference assembly standard를 ‘2.3.2.QV40’으로 제시하고 있습니다. 이는, contig N50 100kb 이상 scaffold N50 1,000kb 이상 길이로 따졌을 때 90% 이상의 contig가 scaffold에 포함되고 fusion/fission/translocation 등이 다른 실험 방법으로 확인됐는지 검증한 것 을 의미합니다.Contig LengthN50은 quality metric 중 하나로 read/contig/scaffold에 모두 적용됩니다.우선 read/contig/scaffold를 길이가 긴 것부터 정렬합니다. 그 길이를 순차적으로 하나씩 더했을 때, 전체 길이의 절반이 넘는 순간 그에 해당하는 read/contig/scaffold의 길이를 N50으로 정의합니다. 그림에서 전체 길이는 135bp이며 50%는 약 68bp입니다. 길이가 긴 것부터 정렬한 뒤 68bp를 넘는 시점의 read/contig/scaffold는 30bp입니다. 즉, N50은 30bp입니다.N50https://www.edwith.org/longread-seq-2023/lecture/1475113NGx plot은 각 contig의 길이(=y축: contig나 scaffold length)와 누적 합을 전체 genome length로 나눈 비율(=x측: cumulative coverage)로 표현한 plot입니다.)NGx Plothttps://www.edwith.org/longread-seq-2023/lecture/1475113BUSCOBUSCO(Benchmarking Universal Single-Copy Orthologs)는 기존에 알려진 lineage-specific single-copy ortholog 유전자들이 제대로 assembly 됐는지 확인하는 tool입니다. BUSCO Plothttps://www.edwith.org/longread-seq-2023/lecture/1475113Take Home Message Contig length 기반으로 assembly quality를 비교할 수 있습니다. BUSCO를 활용할 수 있습니다. " }, { "title": "Long Read Sequencing IV - Repeat/Gene Annotation", "url": "/posts/Longread_sequencing4/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, pacbio, longread", "date": "2023-07-10 07:42:11 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 박사 후 연구원 김준님의 Repeat/Gene Annotation를 정리한 내용입니다.Intro 유전자 정보를 확보하는 방법에 대해 알아봅니다. 반복서열을 masking하는 방법에 대해 알아봅니다. Repeat MaskingRepeat masking을 하는 이유는 gene annotation을 좀 더 정확하고 선명하게 처리하기 위함입니다.Gene annotation 과정을 살펴보면, 먼저 genome reference를 준비한 뒤 RNA-seq reads를 mapping합니다. 이후 gene annotation을 진행합니다. 이 때 repeat masking이 되어있으면 좀 더 정확하고 선명한 gene annotation 결과를 얻을 수 있습니다.Gene Annotation Processhttps://www.edwith.org/longread-seq-2023/lecture/1475112다음은 Repeat 영역에 대해 알아보겠습니다.많은 진핵생물의 유전체는 repeat으로 가득 차있습니다. HiFi를 비롯한 long-read sequencing 기법을 동원하면 repeat까지 정확하게 assemble 할 수 있습니다. 이런 repeat을 제거하거나 확인함으로써 유전체 활용을 더 효과적으로 할 수 있습니다.Repeat masking은 두 가지 종류가 존재합니다. Hard masking: repeat을 모두 N으로 masking하는 방법입니다. Soft masking: repeat을 모두 소문자로 masking하는 방법입니다. Repeat Maskinghttps://www.edwith.org/longread-seq-2023/lecture/1475112Gene Annotationhisat2를 사용하여 masked genome에 RNA-seq data를 mapping합니다.이후 braker, GeneMark를 다운로드 받아 설치한 뒤 실행합니다.Take Home MessageRepeat masking -&amp;gt; RNA-seq read mapping -&amp;gt; gene annotation 순서로 진행합니다." }, { "title": "(coursera) Machine Learning Applied", "url": "/posts/Machine_Learning_Applied/", "categories": "Study, L-Certificate", "tags": "certificate, ML, coursera", "date": "2023-07-08 00:14:33 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "Long Read Sequencing III - 유전체 크기 추정하기", "url": "/posts/Longread_sequencing3/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, pacbio, longread", "date": "2023-07-07 11:35:10 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 박사 후 연구원 김준님의 유전체 크기 추정하기를 정리한 내용입니다.Intro 유전체 크기를 추정하는 다양한 방법에 대해 알아봅니다. 시퀀싱 데이터로부터 직접 유전체 크기를 추정해봅니다. 앞으로 강의에서 다루는 분석내용은 STAR Protocols에 상세히 정리되어 있습니다. 유전체 크기 추정 - Wet 실험유전체 크기를 추정해야 하는 이유는 다음과 같습니다. 생산해야 할 총 시퀀싱 양 &amp;amp; 시퀀싱 비용 계산에 필요합니다. 몇몇 genome assembler 작동시킬 때 option으로 넣어줘야 합니다. 사람 같이 이미 알려진 종에서는 생략 가능합니다. 유전체 크기 단위는 C-value를 사용합니다.haploid DNA 질량 1pg은 대략 haploid genome size 1Gb와 유사하다고 볼 수 있습니다.1pg(haploid DNA 질량) ~= 1Gb(haploid genome size)실험적인 방법으로 genome size를 추정하는 방법은 다음과 같습니다. 형광 + flow cytometer 알려진 nucleus를 control로 삼고, 모르는 종의 nucleus 등을 뽑아 함께 염색합니다. 이후 형광 세기를 비교하여 genome size를 추정합니다. Single-copy gene + qPCR gDNA 추출 후 전체 질량 및 single-copy gene의 copy number를 측정합니다. 두 값을 활용하여 haploid genome size를 추정합니다. 유전체 크기 추정 - 알려진 DB유전체 크기를 모아놓은 다양한 DB가 존재합니다. Animal Genome Size Database 약 6,222개 동물종에 대한 genome size data를 확인할 수 있습니다. Plant Genome Size Database 약 12,273개 식물종에 대한 genome size data를 확인할 수 있습니다. 유전체 크기 추정 - 시퀀싱 데이터DNA 시퀀싱 기반 유전체 크기를 추정할 수 있습니다.가상의 유전체 지도를 가정하고 생산한 DNA read응 유전체 지도에 mapping 합니다. 전체 생산 DNA 시퀀싱 총량을 depth로 나누어 유전체 크기를 추정할 수 있습니다.예를들어, 5Gb의 시퀀싱 데이터를 생산하여 mapping 했을 때 약 5x depth로 mapping 되었다면, genome size는 약 1Gb라고 추정할 수 있습니다.DNA 시퀀싱 활용한 유전체 크기 추정https://www.edwith.org/longread-seq-2023/lecture/1475110DNA와 RNA 시퀀싱을 활용해서 유전체 크기를 추정할 수 있습니다.Genome 대신 transcript 정보를 확보하고, 여기에 DNA read를 mapping해서 genome size를 추정합니다.장점으로는 DNA data가 적어도 된다는 점입니다. 단점은 transcript quality가 좋지 않으면 genome size 추정이 부정확합니다.DNA+RNA 시퀀싱 활용한 유전체 크기 추정https://www.edwith.org/longread-seq-2023/lecture/1475110Take Home Message새로운 종의 genome assembly를 해야할 때는 유전체 크기 추정을 해야합니다.다양한 방법이 있으며 시퀀싱 데이터만 가지고도 유전체 크기 추정이 가능합니다." }, { "title": "Long Read Sequencing II - 유전체 지도 작성 개괄", "url": "/posts/Longread_sequencing2/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, pacbio, longread", "date": "2023-07-07 07:15:42 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 박사 후 연구원 김준님의 유전체 지도 작성 개괄를 정리한 내용입니다.Intro 유전체 지도 작성법에 대해 간략히 이해해 봅니다. 현존하는 세 가지 롱리드 시퀀싱 방식의 특징에 대해 알아봅니다. 2022년에 공개된 인간 유전체 지도 완성에 대해 알아봅니다. 유전체 지도와 유전체 정보롱리드 시퀀싱은 한 번에 더 긴 길이의 리드를 생산해내며, 이들을 이어붙이는 과정(assembly)을 매우 쉽게 해줍니다.유전체 지도는 이와 같이 리드들을 모아 이어붙여서 완성하게 됩니다.유전체 지도 작성 관련 시퀀싱 플랫폼 특징유전체 지도 작성 과정은 다음과 같습니다.유전체 지도 작성 과정https://www.edwith.org/longread-seq-2023/lecture/1475109Genome assembly 관점에서 각 시퀀싱 데이터의 특징과 용도를 알아봅니다.Arima Hi-C, Bionano optical map은 longread까지는 아니고 long range sequencing으로 분류됩니다.PacBio HiFi가 가장 정확도가 높고 고품질의 시퀀싱 데이터를 얻을 수 있습니다. Size selection을 거치므로 10kb~20kb의 길이로 데이터를 생산합니다.ONT ultra-long은 정확도가 떨어지지만 가장 긴 길이의 데이터를 생산합니다.각 시퀀싱 데이터의 특징과 용도https://www.edwith.org/longread-seq-2023/lecture/1475109유전체 지도를 생산하는 보편적인 과정은 다음과 같습니다.Longread를 이어붙여 contig를 생산한 뒤, 이러한 contig들을 이어붙여 scaffold를 생성합니다. 이 때, physical map/optical map/genetic map 등을 활용하여 contig의 순서 및 방향을 결정합니다. 이후 RAN-seq을 수행하여 exon 정보 등을 확인합니다.유전체 지도 생산 과정https://www.edwith.org/longread-seq-2023/lecture/1475109유전체 지도를 작성할 때 assembly가 잘 안되는 지역이 존재합니다. 짧은 반복서열이 매우 많은 지역(repeat) 엄청 거대한 서열이 2회 이상 반복되는 지역(segmental duplication) Heterozygosity가 문제될 정도로 큰 지역 centromere: 작은 subunit이 수 Mb까지 반복되기도 합니다. Telomere &amp;amp; subtelomere: segmental duplication이 흔하게 관찰되는 지역입니다. 실제 사례 CHM13 사용한 human genome‘The complete sequence of a human genome’는 2022년 publish된, 현재 가장 완성에 가까운 human genome reference입니다. 해당 논문은 CHM13 cell line을 활용하여 유전체 지도의 완성도를 높혔습니다.CHM은 완전포상기태(Complete Hydatidiform Mole, CHM) 세포주를 의미하며, 효과적으로 haploid cell line을 제작하는데 사용되고 있습니다. DNA가 없는 난자에 DNA가 있는 정자를 투입하면 정자 DNA만 2배로 불어난 세포가 되고 이것이 곧 homozygous cell line을 의미합니다. CHM13 cell line의 경우 세포 안에 존재하는 한 쌍의 염색체가 거의 동일하며, 이와 관련된 내용이 논문 내에 기재되어 있습니다.CHM13 Cell Linehttps://www.edwith.org/longread-seq-2023/lecture/1475109해당 논문에서 기본 contig는 PacBio HiFi 리드를 사용하여 생산했습니다. 이를 사용하여 scaffold를 생산할 때 gap 영역은 N base로 채우는 것이 아니라 ONT ultra longread를 사용하여 시퀀스를 확인 했습니다.고품질 유전체 지도 생산 과정https://www.edwith.org/longread-seq-2023/lecture/1475109 Human Pangenome ProjectCHM cell line을 사용하여 유전체 지도를 만드는 과정에서 보다 scale up을 잘 할 수 있도록, 그리고 phasing을 잘되게 하는 것을 목적으로 하는 project입니다. Phasing은 모계에서 받은 DNA 정보, 부계에서 받은 DNA 정보를 나누는 과정입니다. PacBio HiFi + HiC + Strand-seq 등만 활용해도 diploid 개체의 유전체 정보 두 벌을 정확히 확인 가능합니다.‘The Human Pangenome Project: a global resource to map genomic diversity’‘A draft human pangenome reference’Take Home Message유전체 지도는 가장 고품질의 DNA 정보를 확보하는 과정입니다.롱리드 사이에서 겹치는 부분을 활용해 contig를 만듭니다.Physical/optical/henetic map 정보를 활용해 scaffold를 만듭니다.RNA-seq 정보를 활용해 유전자 정보를 확보합니다." }, { "title": "Long Read Sequencing I - Introduction", "url": "/posts/Longread_sequencing1/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, pacbio, longread", "date": "2023-07-06 07:23:33 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 박사 후 연구원 김준님의 롱리드 시퀀싱 개요를 정리한 내용입니다.Intro 시권싱 기법과 이를 활용한 생물학 연구 방법론에 대해 알아봅니다. 롱리드 시퀀싱과 기존 숏리드 시퀀싱 기법의 차이를 알아봅니다. 롱리드 시퀀싱 기법을 활용한 생물학 연구 방법론 개요를 이해합니다. 시퀀싱 기법생물학은 그 어떤 과학 분야보다 많은 양의 데이터를 생산하는 거대 과학으로 자리 잡고 있습니다. 시퀀싱을 통해서 매년 다른 분야를 능가하는 양의 데이터를 생산하고 있습니다.Data Size of Genomicshttps://www.edwith.org/longread-seq-2023/lecture/1475107시퀀싱을 하는 궁극적인 목적은 변이(variation)를 찾아내기 위함입니다. 변이는 특정 개체의 DNA를 시퀀싱하여 서열정보를 확인한 뒤 해당 개체의 reference 대비 변화된 서열정보 입니다.생체 내 분자들 중 DNA와 RNA는 다량으로 복제하여 시퀀싱하고 서열정보를 알아낼 수 잇는 방법론이 잘 갖춰져 있기때문에 오늘날 시퀀싱이 보편화 되었습니다.시퀀싱 데이터 살펴보기시퀀싱은 DNA 등의 생체 분자 정보를 사람이 읽을 수 있는 형태로 변환하는 과정입니다. 환자 집단과 비환자 집단 등을 비교함으로써 변이를 확보할 수 있습니다.시퀀싱 데이터는 문자로 표현한 FASTA/Q 포맷으로 나타냅니다. FASTA ’&amp;gt;’: read/contig/chromosome 등의 정보 그 외: A/T/C/G로 이루어진 실제 시퀀스 정보 FASTQ line1(‘@’): read/contig/chromosome 등의 정보 line2: A/T/C/G로 이루어진 실제 시퀀스 정보 line3(‘+’): 추가 정보 line4: 각 base의 quality 정보(Q-score0) FASTA, FASTQhttps://www.edwith.org/longread-seq-2023/lecture/1475107시퀀싱 방법에 따라, DNA/RNA 분자의 한쪽 끝(Single-end) 또는 양쪽 끝(Paired-end)에서 진행할 수 있습니다. Single-end: DNA/RNA 분자의 시퀀싱 정보가 한 개의 파일에 저장됩니다. Paired-end: DNA/RNA 분자의 시퀀싱 정보가 두 개의 파일에 저장됩니다. 그 외 다양한 생물학 데이터 포맷이 존재합니다. SAM/BAM: read alignment 정보를 담은 파일 VCF: variant 정보를 담은 파일 BED: 특정 구간의 정보를 담은 파일 GTF/GFF: genome annotation 정보를 담은 파일 (repeat, gene, variant, etc) GFA: 여러 fragment의 sequence와 overlap 정보 등을 담은 파일. genome assembly 등에 많이 사용됨 시퀀싱 데이터 사용 변이 확인(variant calling) 기존에 확보되어 있는 유전체 지도(genome assembly)에 유전체 정보를 담고 잇는 짧은 리드를 검색하는 방식으로 변이를 확인할 수 있습니다. Variant Callinghttps://www.edwith.org/longread-seq-2023/lecture/1475107롱리드 시퀀싱롱리드 시퀀싱을 사용하는 이유 중 하나는, 리드 길이가 짧으면 복잡한 구조 변이(SV)를 찾아내는 것이 매우 어렵기 때문입니다.롱리드 시퀀싱은 한 번에 더 긴 길이의 리드를 생산하며, 이들을 이어붙임(assembly)으로써 보다 정교한 SV 분석이 가능해집니다.Longread Sequencing for SV analysishttps://www.edwith.org/longread-seq-2023/lecture/1475107롱리드 시퀀싱을 활용하면 full-length transcript 정보를 확보할 수 있고 기존에 밝혀지지 않은 유전자 동형 분석은 물론 정량적 비교도 가능합니다.Longread Sequencing for isoform analysishttps://www.edwith.org/longread-seq-2023/lecture/1475107롱리드 시퀀싱은 PCR 없이 가능하기 때문에 분자에 존재하는 화학적 변형(DNA/RNA modification)도 분석할 수 있습니다.Take Home Message시퀀싱 기법을 활용한 데이터 생산 덕분에 생물학은 가장 거대한 데이터 과학 중 하나로 자리매김 하고 있습니다.DNA/RNA에 담긴 변이 정보는 물론 해당 분자의 정량적 정보를 확보할 수 있게 되면서 다양한 생물학 연구가 가능해졌습니다.롱리드 시퀀싱은 PCR 없이도 단분자에서 한 번에 더 긴 DNA/RNA 정보를 확보할 수 있게 해줍니다.이는 high-quality genome assembly, novel isoform detection, DNA/RNA modification 정보 등을 확보할 수 있게 합니다." }, { "title": "파이썬을 활용한 데이터 분석 (중급) - 11. Summary", "url": "/posts/Python_Data_Analysis_11/", "categories": "Bioinformatics, Statistics", "tags": "BI, bioinformatics, python, statistics", "date": "2023-07-05 20:15:05 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 인사이트마이닝 이부일 CEO의 전체 강의를 정리한 내용입니다.일표본 검정일표본 검정https://www.edwith.org/python-data-analysis-2023/lecture/1475052독립2표본 검정독립2표본 검정https://www.edwith.org/python-data-analysis-2023/lecture/1475052대응2표본 검정대응2표본 검정https://www.edwith.org/python-data-analysis-2023/lecture/1475052ANOVAANOVAhttps://www.edwith.org/python-data-analysis-2023/lecture/1475052Take Home MessagePython을 활용하여 데이터에 알맞은 통계분석 방법을 학습했습니다." }, { "title": "(EDWITH-KOBIC) Data Analysis with Python", "url": "/posts/Certificate_Data_analysis_with_python/", "categories": "Study, L-Certificate", "tags": "certificate, python, statistics, KOBIC", "date": "2023-07-05 19:24:04 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "파이썬을 활용한 데이터 분석 (중급) - 10. Non-Parametric Multiple Comparison with python", "url": "/posts/Python_Data_Analysis_10/", "categories": "Bioinformatics, Statistics", "tags": "BI, bioinformatics, python, statistics", "date": "2023-07-05 19:02:40 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 인사이트마이닝 이부일 CEO의 Non-Parametric Multiple Comparison with python을 정리한 내용입니다.IntroPython을 이용하여 Non-Parametric Multiple Comparison with python 수행과정을 알아봅니다.언제 사용하는가?비모수적 방법인 Kruskal-Wallis rank sum test에서 집단에 따라 통계적으로 유의한 차이가 있다고 결론이 나왔을 때, 어느 집단 간 유의한 차이가 있는지 확인할 때 사용하는 방법입니다. 3개 이상 범주와 수치형 자료를 가질 때 사용합니다.비모수적 다중비교 bonferroni sidak holm-sidak simes-Hochberg hommel fdf_bh fdr_by fdr_tsbh fdr_tsbky코드# 비모수적 사후분석: Dunn Test# 귀무가설: 두 집단 간에는 차이가 없습니다.# 대립가설: 두 집단 간에는 차이가 있습니다.import pandas as pdimport scikit_posthocs as spInsectSprays = pd.read_excel( io = &#39;09InsectSprays.xlsx&#39;, sheet_name = 0)print(InsectSprays)sp.posthoc_dunn( InsectSprays, val_col = &#39;count&#39;, group_col = &#39;spray&#39;, p_adjust = &#39;holm&#39;)Take Home MessageNon-Parametric Multiple Comparison 이론을 학습하고 Google colab에서 실습해 보았습니다." }, { "title": "(Error) CommandNotFoundError - Your shell has not been properly configured to use &#39;conda activate&#39;", "url": "/posts/conda_error_CommandNotFoundError/", "categories": "Programming, Python", "tags": "python, anaconda, conda, activate", "date": "2023-07-05 08:05:15 +0900", "snippet": "Error 내용conda environment를 생성한 뒤 activate 시도했을 때 아래와 같은 error message를 출력합니다.CommandNotFoundErrorhttps://hubert-bioinformatics.github.io/내용에 따라 conda init &amp;lt;SHELL_NAME&amp;gt; 실행한 뒤 shell을 재실행해도 마찬가지 error message를 출력하고 conda environment를 실행할 수 없습니다.Error 원인 및 해결Error 원인은 새로 생성한 environment가 현재 접속 중인 shell에서 기본적으로 사용할 수 있는 상태가 아니기 때문입니다.따라서 아래와 같이 conda 설정 파일(conda.sh) 변경사항을 source 명령어를 사용하여 반영하면 해결됩니다.CommandNotFoundErrorhttps://hubert-bioinformatics.github.io/source /(conda_path)/etc/profile.d/conda.shconda activate (env name)출처https://github.com/conda/conda/issues/7980" }, { "title": "파이썬을 활용한 데이터 분석 (중급) - 9. Kruskal-Wallis Rank Sum Test with python", "url": "/posts/Python_Data_Analysis_9/", "categories": "Bioinformatics, Statistics", "tags": "BI, bioinformatics, python, statistics", "date": "2023-07-05 07:01:02 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 인사이트마이닝 이부일 CEO의 Kruskal-Wallis Rank Sum Test with python을 정리한 내용입니다.IntroPython을 이용하여 Kruskal-Wallis Rank Sum Test with python 수행과정을 알아봅니다.언제 사용하는가?세 개 이상의 독립적인 집단의 양적 자료의 평균에 차이가 있는지를 분석할 때 사용하는 방법입니다. 하나의 집단에서라도 정규성 가정을 만족하지 않을 때, 즉 ANOVA를 사용할 수 없을 때 사용합니다. 3개 이상 범주와 수치형 자료를 가질 때 사용합니다.가설 세우기 귀무가설 (Null Hypothesis, H0) 살충제의 종류(spray)에 따라 살충효과가 없습니다. 대립가설 (Alternative Hypothesis, H1 or HA) 살충제의 종류(spray)에 따라 살충효과가 있습니다. Kruskal-Wallis Rank Sum Test 1단계: 세 군의 측정치를 모두 풀어 크기 순으로 정렬합니다. 2단계: 크기 순으로 순위를 부여합니다. 이 때 동률은 순위의 평균값을 부여합니다. Kruskal-Wallis Rank Sum Test1https://www.edwith.org/python-data-analysis-2023/lecture/1475051 3단계: 집단별로 순위합을 구합니다. 4단계: 집단별로 평균순위합을 구합니다. Kruskal-Wallis Rank Sum Test2https://www.edwith.org/python-data-analysis-2023/lecture/1475051 5단계: 기대값을 구합니다. 관찰값 합계를 구한 뒤 집단 간 차이가 없다면 동일하게 나눠 가질 것이라는 가정하에 기대값을 구하고 관찷값과 비교하는 것입니다.Kruskal-Wallis Rank Sum Test3https://www.edwith.org/python-data-analysis-2023/lecture/1475051 6단계: 편차의 제곱합을 구합니다.Kruskal-Wallis Rank Sum Test4https://www.edwith.org/python-data-analysis-2023/lecture/1475051 7단계: 카이제곱을 구합니다.Kruskal-Wallis Rank Sum Test5https://www.edwith.org/python-data-analysis-2023/lecture/1475051코드import pandas as pdimport scipy.stats as statsInsectSprays = pd.read_excel( io = &#39;09InsectSprays.xlsx&#39;, sheet_name = 0)print(InsectSprays)# Analysis I: Normality Test# n &amp;lt; 5,000 -&amp;gt; Shapiro-Wilk Normality Testprint(stats.shapiro(InsectSprays.loc[InsectSprays[&#39;spray&#39;] == &#39;A&#39;, &#39;count&#39;]))print(stats.shapiro(InsectSprays.loc[InsectSprays[&#39;spray&#39;] == &#39;B&#39;, &#39;count&#39;]))print(stats.shapiro(InsectSprays.loc[InsectSprays[&#39;spray&#39;] == &#39;C&#39;, &#39;count&#39;]))print(stats.shapiro(InsectSprays.loc[InsectSprays[&#39;spray&#39;] == &#39;D&#39;, &#39;count&#39;]))print(stats.shapiro(InsectSprays.loc[InsectSprays[&#39;spray&#39;] == &#39;E&#39;, &#39;count&#39;]))print(stats.shapiro(InsectSprays.loc[InsectSprays[&#39;spray&#39;] == &#39;F&#39;, &#39;count&#39;]))# 정규성 검정 결과, C, D는 각각 유의확률(p-value)이 0.048, 0.003으로 유의확률(0.05)보다 작으므로 정규성 가정을 만족하지 않습니다.# 따라서, ANOVA를 사용할 수 없고 Kruskal-Wallis Rank Sum Test를 사용해야 합니다.# Analysis II: Kruskal-Wallis Rank Sum Test# 귀무가설: 살충제의 종류(spray)에 따라 살충효과가 없습니다.# 대립가설: 살충제의 종류(spray)에 따라 살충효과가 있습니다.stats.kruskal( InsectSprays.loc[InsectSprays[&#39;spray&#39;] == &#39;A&#39;, &#39;count&#39;], InsectSprays.loc[InsectSprays[&#39;spray&#39;] == &#39;B&#39;, &#39;count&#39;], InsectSprays.loc[InsectSprays[&#39;spray&#39;] == &#39;C&#39;, &#39;count&#39;], InsectSprays.loc[InsectSprays[&#39;spray&#39;] == &#39;D&#39;, &#39;count&#39;], InsectSprays.loc[InsectSprays[&#39;spray&#39;] == &#39;E&#39;, &#39;count&#39;], InsectSprays.loc[InsectSprays[&#39;spray&#39;] == &#39;F&#39;, &#39;count&#39;],)# Kruskal-Wallis Rank Sum Test 결과 유의확률(p-value) 0.000으로 유의수준(0.05)보다 작으므로 귀무가설을 기각합니다. 즉, 살충제의 종류에 따라 통계적으로 유의한 살충효과가 있습니다.Take Home MessageKruskal-Wallis Rank Sum Test 이론을 학습하고 Google colab에서 실습해 보았습니다." }, { "title": "파이썬을 활용한 데이터 분석 (중급) - 8. Parametric Multiple Comparison with python", "url": "/posts/Python_Data_Analysis_8/", "categories": "Bioinformatics, Statistics", "tags": "BI, bioinformatics, python, statistics", "date": "2023-07-04 20:14:42 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 인사이트마이닝 이부일 CEO의 Parametric Multiple Comparison with python을 정리한 내용입니다.IntroPython을 이용하여 Parametric Multiple Comparison with python 수행과정을 알아봅니다.언제 사용하는가?모수적 방법인 분산분석(ANOVA)에서 집단에 따라 통계적으로 차이가 있다고 나왔을 때 사용하는 다중비교 방법입니다. 범주가 3개 이상인 범주형 자료와 수치형 자료가 필요합니다.Family-wise error rate세 개의 집단에 대해 일반적인 다중비교를 실행하면, 각 비교시 유의수준을 \\(\\alpha\\)로 잡았다고 하더라도 최종 유의수준은 \\(1 - (1 - \\alpha)^(n)\\)이 되는 error가 발생합니다. 예를 들어 세 개의 집단을 두고 각 집단간 비교시 유의수준을 0.05로 잡았다면, 집단A vs. 집단B, 집단A vs. 집단C, 집단B vs. 집단C를 비교 후 최종 유의수준은 0.143이 됩니다.Family-wise error ratehttps://www.edwith.org/python-data-analysis-2023/lecture/1475050Tukey HSD다중비교(Multiple comparison) = 사후분석(Post-Hoc) 방법 중 하나로 Tukey HSD(Honest Significant Difference)가 있습니다. 특징: 비교 대상 표본수가 동일한 경우에만 사용 가능합니다. 모든 집단 조합에 대해서 분석합니다. 장점: 표본수가 동일한 경우 가장 많이 사용되는 사후 검정 기법입니다. 단점: 비교 대상 표본수가 동일하여야 합니다. 표본수가 적을수록 정확도가 낮아집니다. Tukeyhttps://www.edwith.org/python-data-analysis-2023/lecture/1475050Dunnett다중비교(Multiple comparison) = 사후분석(Post-Hoc) 방법 중 하나로 Dunnett이 있습니다. 특징: 하나의 집단을 기준으로 다른 집단들과 차이에 대하여 분석합니다. 양측 검정이 가능합니다. 장점: 1개의 대조군과 여러 실험군과의 비교를 하는 연구에 사용 가능합니다. Tukey보다 검정력이 높습니다. 단점: 모든 집단 조합에 대한 검정을 하지 않습니다. Duncan다중비교(Multiple comparison) = 사후분석(Post-Hoc) 방법 중 하나로 Duncan이 있습니다. 특징: 오차비율을 통제하지 않아 상대적으로 엄격하지 않은 기준을 가집니다. 인접하는 평균값들을 단계적으로 비교하는 방법입니다. 장점: 엄격하지 않은 기준으로 통계적 유의성을 도출하기 쉽습니다. 단점: 비교대상이 많아질수록 검정력이 약해집니다. Bonferroni다중비교(Multiple comparison) = 사후분석(Post-Hoc) 방법 중 하나로 Bonferroni가 있습니다. 특징: 응용 범위가 넓습니다.(모수, 비모수 적용 가능) Tukey보다 엄격하지만 Scheffe보다는 관대합니다. 장점: ANOVA, 다중 t-test, 비모수 검정 등에 적용 가능합니다. 단점: 비교대상이 많아질수록 검정력이 약해집니다. Scheffe다중비교(Multiple comparison) = 사후분석(Post-Hoc) 방법 중 하나로 Scheffe가 있습니다. 특징: 가장 보수적이고 엄격한 사후검정 방식입니다. 장점: 엄격한 기준으로 사후 검정을 실시합니다. 단점: 통계적으로 유의한 차이를 도출하기가 쉽지 않습니다. Tukeyhttps://www.edwith.org/python-data-analysis-2023/lecture/1475050가설 세우기 귀무가설 (Null Hypothesis, H0) 재배방법(group)에 따라 풀의 생산량(weight)이 두 집단 간에는 차이가 없습니다. 대립가설 (Alternative Hypothesis, H1 or HA) 재배방법(group)에 따라 풀의 생산량(weight)이 두 집단 간에는 차이가 있습니다. 실습 가설 설정 귀무가설: 재배방법(group)에 따라 풀의 생산량(weight)이 두 집단 간에는 차이가 없습니다. 대립가설: 재배방법(group)에 따라 풀의 생산량(weight)이 두 집단 간에는 차이가 있습니다. 데이터 로딩https://www.edwith.org/python-data-analysis-2023/lecture/1475050 분석 1단계: Tukey HSD 귀무가설: 재배방법(group)에 따라 풀의 생산량(weight)이 두 집단 간에는 차이가 없습니다. 대립가설: 재배방법(group)에 따라 풀의 생산량(weight)이 두 집단 간에는 차이가 있습니다. Tukey HSD 결과, ctrl vs. trt1: adjusted p-value가 0.391로 귀무가설을 기각하지 못합니다. 즉, 두 집단 간 차이가 없습니다. ctrl vs. trt2: adjusted p-value가 0.198로 귀무가설을 기각하지 못합니다. 즉, 두 집단 간 차이가 없습니다. trtl vs. trt2: adjusted p-value가 0.012로 귀무가설을 기각합니다. 즉, 두 집단 간 차이가 있습니다. 코드import pandas as pdfrom statsmodels.stats.multicomp import pairwise_tukeyhsdPlantGrowth = pd.read_excel( io = &#39;07PlantGrowth.xlsx&#39;, sheet_name = 0)print(PlantGrowth)# Analysis I: Tukey HSDtukey = pairwise_tukeyhsd( endog = PlantGrowth.weight, groups = PlantGrowth.group, alpha = 0.05)print(tukey)Take Home MessageParametric Multiple Comparison 이론을 학습하고 Google colab에서 실습해 보았습니다." }, { "title": "파이썬을 활용한 데이터 분석 (중급) - 7. Analysis of Variance with python", "url": "/posts/Python_Data_Analysis_7/", "categories": "Bioinformatics, Statistics", "tags": "BI, bioinformatics, python, statistics", "date": "2023-07-04 07:30:02 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 인사이트마이닝 이부일 CEO의 Analysis of variance with python을 정리한 내용입니다.IntroPython을 이용하여 Analysis of variance with python 수행과정을 알아봅니다.언제 사용하는가?Analysis of variance with python은 세 개 이상의 독립적인 모집단의 수치형 자료의 평균에 차이가 있는지 분석할 때 사용하는 방법입니다. 모든 모집단의 수치형 자료가 정규분포를 따를 때 사용할 수 있습니다.가설 세우기 귀무가설 (Null Hypothesis, H0) 재배방법(group)에 따라 풀의 생산량(weight)에 차이가 없습니다. 대립가설 (Alternative Hypothesis, H1 or HA) 재배방법(group)에 따라 풀의 생산량(weight)에 차이가 있습니다. SST(Sum of Square Total)https://www.edwith.org/python-data-analysis-2023/lecture/1475049 SST(Sum of Squuare Total)는 총제곱합으로 Y에 있는 모든 다름의 양을 의미합니다. SST = SSE + SSB SSE: 집단 내 제곱합을 의미합니다. 집단 내부적인 이유때문에 생긴 Y의 다름의 양입니다. 즉, SSE가 클수록 \\(H_{0}\\)(집단 간 차이가 없음)을 지지합니다. SSB: 집단 간 제곱합을 의미합니다. 집단이 달라서 생긴 Y의 다름의 양입니다. 즉, SSB가 클수록 \\(H_{1}\\)(집단 간 차이가 있음)을 지지합니다.F분포https://www.edwith.org/python-data-analysis-2023/lecture/1475049Analysis of variance 1단계: 정규성 검정(Normality Test) 귀무가설: 정규분포를 따릅니다. 대립가설: 정규분포를 따르지 않습니다. n &amp;lt; 5,000: Shapiro-Wilk Normality Test n &amp;gt;= 5,000: Anderson-Darling Normality Test 정규성 검정은 control group에서 한 번, treat1 group에서 한 번, treat2 group에서 한 번, 총 세 번 시행합니다. 2단계: Levene의 등분산 검정 귀무가설: 등분산입니다. 대립가설: 이분산입니다. 3단계: 등분산이 가정된 ANOVA 또는 이분산이 가정된 ANOVA ANOVA를 시행합니다. 실습 가설 설정 귀무가설: 재배방법(group)에 따라 풀의 생산량(weight)에 차이가 없습니다. 대립가설: 재배방법(group)에 따라 풀의 생산량(weight)에 차이가 있습니다. 데이터 로딩https://www.edwith.org/python-data-analysis-2023/lecture/1475049 분석 1단계: 정규성 검정(Normality Test) 귀무가설: 정규분포를 따릅니다. 대립가설: 정규분포를 따르지 않습니다. n &amp;lt; 5,000 : Shapito-Wilk Normality Test (shapiro(data.variable)) n &amp;gt;= 5,000 : Anderson-Darling Normality Test (anderson(data.variable)) shapiro normality test 결과, ctrl group: 유의확률(p-value)가 0.747로 정규성 가정을 만족합니다. trt1 group: 유의확률(p-value)가 0.452로 정규성 가정을 만족합니다. trt2 group: 유의확률(p-value)가 0.564로 정규성 가정을 만족합니다. 정규성 검정https://www.edwith.org/python-data-analysis-2023/lecture/1475049 분석 2단계: Levene의 등분산 검정 귀무가설: 등분산입니다. 대립가설: 이분산입니다. levene 등분산 검정 결과 유의확률(p-value) 0.341로 유의수준(0.05)보다 크므로 귀무가설을 기각하지 못합니다. 즉, 등분산입니다. Levene의 등분산 검정https://www.edwith.org/python-data-analysis-2023/lecture/1475049 분석 3단계: Analysis of variance 귀무가설: 재배방법(group)에 따라 풀의 생산량(weight)에 차이가 없습니다. 대립가설: 재배방법(group)에 따라 풀의 생산량(weight)에 차이가 있습니다. 유의확률(p-value) 0.016으로 유의수준(0.05)보다 작으므로 귀무가설을 기각합니다. 즉, 재배방법(group)에 따라 풀의 생산량(weight)에 차이가 있습니다. ANOVAhttps://www.edwith.org/python-data-analysis-2023/lecture/1475049코드import pandas as pdimport scipy.stats as statsPlantGrowth = pd.read_excel( io = &#39;07PlantGrowth.xlsx&#39;, sheet_name = 0)print(PlantGrowth)# Analysis I: Normality Test# n &amp;lt; 5,000 -&amp;gt; Shapiro-Wilk Normality Testprint(stats.shapiro(PlantGrowth.loc[PlantGrowth[&#39;group&#39;] == &#39;ctrl&#39;, &#39;weight&#39;]))print(stats.shapiro(PlantGrowth.loc[PlantGrowth[&#39;group&#39;] == &#39;trt1&#39;, &#39;weight&#39;]))print(stats.shapiro(PlantGrowth.loc[PlantGrowth[&#39;group&#39;] == &#39;trt2&#39;, &#39;weight&#39;]))# Analysis II: Levene의 등분산 검정# 귀무가설: 등분산입니다.# 대립가설: 이분산입니다.stats.levene( PlantGrowth.loc[PlantGrowth[&#39;group&#39;] == &#39;ctrl&#39;, &#39;weight&#39;], PlantGrowth.loc[PlantGrowth[&#39;group&#39;] == &#39;trt1&#39;, &#39;weight&#39;], PlantGrowth.loc[PlantGrowth[&#39;group&#39;] == &#39;trt2&#39;, &#39;weight&#39;],)# Analysis III: ANOVAstats.f_oneway( PlantGrowth.loc[PlantGrowth[&#39;group&#39;] == &#39;ctrl&#39;, &#39;weight&#39;], PlantGrowth.loc[PlantGrowth[&#39;group&#39;] == &#39;trt1&#39;, &#39;weight&#39;], PlantGrowth.loc[PlantGrowth[&#39;group&#39;] == &#39;trt2&#39;, &#39;weight&#39;],)Take Home MessageAnalysis of variance 이론을 학습하고 Google colab에서 실습해 보았습니다." }, { "title": "파이썬을 활용한 데이터 분석 (중급) - 6. Wilcoxon&#39;s matched pairs signed rank test with python", "url": "/posts/Python_Data_Analysis_6/", "categories": "Bioinformatics, Statistics", "tags": "BI, bioinformatics, python, statistics", "date": "2023-07-03 11:55:05 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 인사이트마이닝 이부일 CEO의 Wilcoxon’s matched pairs signed rank test with python을 정리한 내용입니다.IntroPython을 이용하여 Wilcoxon’s matched pairs signed rank test with python 수행과정을 알아봅니다.언제 사용하는가?Wilcoxon’s matched pairs signed rank test with python은 동일한 모집단의 사전자료(수치형 자료)와 사후자료(수치형 자료) 간에 통계적으로 의미 있는 차이가 있는지를 분석할 때 사용하는 방법입니다. 사전자료, 사후자료의 값이 정규분포를 따르지 않을 때 사용할 수 있습니다.가설 세우기 귀무가설 (Null Hypothesis, H0) 경호원의 경호효과는 없습니다. 대립가설 (Alternative Hypothesis, H1 or HA) 경호원의 경호효과는 있습니다. Paired t-test 1단계: 정규성 검정(Normality Test) 귀무가설: (사전-사후) 값이 정규분포를 따릅니다. 대립가설: (사전-사후) 값이 정규분포를 따르지 않습니다. n &amp;lt; 5,000: Shapiro-Wilk Normality Test n &amp;gt;= 5,000: Anderson-Darling Normality Test 2단계: Wilcoxon’s matched pairs signed rank test difference = before - after 값을 구합니다. difference에 절대값을 취합니다. 순위를 구합니다. 동점(tie)이 발생할 경우에는 평균 순위를 줍니다. W+, W-를 구합니다. 실습 가설 설정 귀무가설: 경호원의 경호효과는 없습니다. 대립가설: 경호원의 경호효과는 있습니다. 데이터 로딩https://www.edwith.org/python-data-analysis-2023/lecture/1475048 분석 1단계: 정규성 검정(Normality Test) 귀무가설: 정규분포를 따릅니다. 대립가설: 정규분포를 따르지 않습니다. n &amp;lt; 5,000 : Shapito-Wilk Normality Test (shapiro(data.variable)) n &amp;gt;= 5,000 : Anderson-Darling Normality Test (anderson(data.variable)) shapiro normality test 결과 difference의 유의확률(p-value)가 0.016으로 정규성 가정을 만족하지 않습니다. 정규성 검정https://www.edwith.org/python-data-analysis-2023/lecture/1475048 분석 2단계: Wilcoxon’s matched pairs signed rank test 귀무가설: 경호원의 경호효과는 없습니다. 대립가설: 경호원의 경호효과는 있습니다. 유의확률(p-value) 0.289로 유의수준(0.05)보다 크므로 귀무가설을 기각하지 못합니다. 즉, 경호원에 대한 통계적으로 유의한 경호효과는 없습니다. Paired t-testhttps://www.edwith.org/python-data-analysis-2023/lecture/1475048코드import pandas as pdimport scipy.stats as statssecurity = pd.read_excel( io = &#39;06security.xlsx&#39;, sheet_name = 0)print(security)# Analysis I: Normality Test# n &amp;lt; 5,000 -&amp;gt; Shapiro-Wilk Normality Testsecurity[&#39;difference&#39;] = security.before - security.afterstats.shapiro(security.difference)# Analysis II: Wilcoxon&#39;s matched pairs signed rank teststats.wilcoxon( security.difference, alternative = &#39;greater&#39;)Take Home MessageWilcoxon’s matched pairs signed rank test 이론을 학습하고 Google colab에서 실습해 보았습니다." }, { "title": "파이썬을 활용한 데이터 분석 (중급) - 5. Paired t-test with python", "url": "/posts/Python_Data_Analysis_5/", "categories": "Bioinformatics, Statistics", "tags": "BI, bioinformatics, python, statistics", "date": "2023-07-03 07:42:52 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 인사이트마이닝 이부일 CEO의 Paired t-test with python을 정리한 내용입니다.IntroPython을 이용하여 Paired t-test with python 수행과정을 알아봅니다.언제 사용하는가?Paired t-test with python은 동일한 모집단의 사전자료(수치형 자료)와 사후자료(수치형 자료) 간에 통계적으로 의미 있는 차이가 있는지를 분석할 때 사용하는 방법입니다. 사전자료, 사후자료의 값이 정규분포를 따를 때 사용할 수 있습니다.가설 세우기 귀무가설 (Null Hypothesis, H0) 우울증 치료제는 우울증에 효과가 없습니다. 대립가설 (Alternative Hypothesis, H1 or HA) 우울증 치료제는 우울증에 효과가 있습니다. Paired t-test 1단계: 정규성 검정(Normality Test) 귀무가설: (사전-사후) 값이 정규분포를 따릅니다. 대립가설: (사전-사후) 값이 정규분포를 따르지 않습니다. n &amp;lt; 5,000: Shapiro-Wilk Normality Test n &amp;gt;= 5,000: Anderson-Darling Normality Test 2단계: Paired t-test Paired t-test를 수행합니다. 실습 가설 설정 귀무가설: 우울증 치료제는 우울증에 효과가 없습니다. 대립가설: 우울증 치료제는 우울증에 효과가 있습니다. 데이터 로딩https://www.edwith.org/python-data-analysis-2023/lecture/1475047 분석 1단계: 정규성 검정(Normality Test) 귀무가설: 정규분포를 따릅니다. 대립가설: 정규분포를 따르지 않습니다. n &amp;lt; 5,000 : Shapito-Wilk Normality Test (shapiro(data.variable)) n &amp;gt;= 5,000 : Anderson-Darling Normality Test (anderson(data.variable)) shapiro normality test 결과 difference의 유의확률(p-value)가 0.828로 정규성 가정을 만족합니다. 정규성 검정https://www.edwith.org/python-data-analysis-2023/lecture/1475047 분석 2단계: Paired t-test 귀무가설: 우울증 치료제는 우울증에 효과가 없습니다. 대립가설: 우울증 치료제는 우울증에 효과가 있습니다. 유의확률(p-value) 0.000으로 유의수준(0.05)보다 작으므로 귀무가설을 기각합니다. 즉, 우울증 치료제는 우울증에 통계적으로 유의한 효과가 있습니다. Paired t-testhttps://www.edwith.org/python-data-analysis-2023/lecture/1475047코드import pandas as pdimport scipy.stats as statsdepression = pd.read_excel( io = &#39;05depression.xlsx&#39;, sheet_name = 0)print(depression)# Analysis I: Normality Test# n &amp;lt; 5,000 -&amp;gt; Shapiro-Wilk Normality Testdepression[&#39;difference&#39;] = depression.pre - depression.poststats.shapiro(depression.difference)# Analysis II: Paired t-teststats.ttest_rel( depression.pre, depression.post, alternative = &#39;greater&#39;)Take Home MessagePaired t-test 이론을 학습하고 Google colab에서 실습해 보았습니다." }, { "title": "파이썬을 활용한 데이터 분석 (중급) - 4. Wilcoxons Rank Sum Test with python", "url": "/posts/Python_Data_Analysis_4/", "categories": "Bioinformatics, Statistics", "tags": "BI, bioinformatics, python, statistics", "date": "2023-07-01 15:32:10 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 인사이트마이닝 이부일 CEO의 Wilcoxons Rank Sum Test with python을 정리한 내용입니다.IntroPython을 이용하여 Wilcoxons Rank Sum Test with python 수행과정을 알아봅니다.언제 사용하는가?Wilcoxons Rank Sum Test with python은 두 개의 독립적인 모집단의 평균이 같은지, 다른지, 같지 않은지를 분석하는 방법입니다. 두 개이 모집단 중에서 하나의 모집단이라도 정규성 가정이 깨졌을 때, 또는 모집단의 분포에 대한 가정을 할 수 없을 때 사용합니다.가설 세우기 귀무가설 (Null Hypothesis, H0) 성별(F, M)에 따라 혈압에 차이가 없습니다. 대립가설 (Alternative Hypothesis, H1 or HA) 성별(F, M)에 따라 혈압에 차이가 있습니다. Wilcoxons Rank Sum Test 1단계: 정규성 검정(Normality Test) 귀무가설: 정규분포를 따릅니다. 대립가설: 정규분포를 따르지 않습니다. n &amp;lt; 5,000: Shapiro-Wilk Normality Test n &amp;gt;= 5,000: Anderson-Darling Normality Test 2단계: Wilcoxons Rank Sum Test 혈압을 기준으로 오름차순으로 정렬합니다. 정렬된 혈압에 순위(rank)를 매깁니다. 참고로 동점이 있는 경우에는 평균 순위를 사용합니다. 성별로 순위의 합계를 구한 뒤 차이가 있는지 비교합니다. 실습 가설 설정 귀무가설: 성별(F, M)에 따라 혈압에 차이가 없습니다. 대립가설: 성별(F, M)에 따라 혈압에 차이가 있습니다. 데이터 로딩https://www.edwith.org/python-data-analysis-2023/lecture/1475046 분석 1단계: 정규성 검정(Normality Test) 귀무가설: 정규분포를 따릅니다. 대립가설: 정규분포를 따르지 않습니다. n &amp;lt; 5,000 : Shapito-Wilk Normality Test (shapiro(data.variable)) n &amp;gt;= 5,000 : Anderson-Darling Normality Test (anderson(data.variable)) shapiro normality test 결과 female의 유의확률(p-value)가 0.337로 정규성 가정을 만족하고, male의 유의확률(p-value)가 0.003으로 정규성 가정을 만족하지 못합니다. 정규성 검정https://www.edwith.org/python-data-analysis-2023/lecture/1475046 분석 2단계: Wilcoxon’s rank sum test 귀무가설: 성별(F, M)에 따라 혈압에 차이가 없습니다. 대립가설: 성별(F, M)에 따라 혈압에 차이가 있습니다. Wilcoxon’s rank sum testhttps://www.edwith.org/python-data-analysis-2023/lecture/1475046코드import pandas as pdimport scipy.stats as statshealth = pd.read_excel( io = &#39;04health.xlsx&#39;, sheet_name = 0)print(health)# Analysis I: Normality Test# n &amp;lt; 5,000 -&amp;gt; Shapiro-Wilk Normality Test# femalefemale_normality = stats.shapiro(health.loc[health[&#39;gender&#39;] == &#39;F&#39;, &#39;hypertension&#39;])print(female_normality)# malemale_normality = stats.shapiro(health.loc[health[&#39;gender&#39;] == &#39;M&#39;, &#39;hypertension&#39;])print(male_normality)# Analysis II: Wilcoxon&#39;s rank sum teststats.wilcoxon( health.loc[health[&#39;gender&#39;] == &#39;F&#39;, &#39;hypertension&#39;], health.loc[health[&#39;gender&#39;] == &#39;M&#39;, &#39;hypertension&#39;], alternative = &#39;two-sided&#39;)# 유의확률(0.212) &amp;gt; 유의수준(0.05)이므로 귀무가설을 기각하지 못합니다. 즉, 성별(F, M)에 따라 혈압에 통계적으로 유의한 차이가 없습니다.Take Home MessageWilcoxon’s rank sum test 이론을 학습하고 Google colab에서 실습해 보았습니다." }, { "title": "파이썬을 활용한 데이터 분석 (중급) - 3. Two Sample t-Test with python", "url": "/posts/Python_Data_Analysis_3/", "categories": "Bioinformatics, Statistics", "tags": "BI, bioinformatics, python, statistics", "date": "2023-06-29 07:42:50 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 인사이트마이닝 이부일 CEO의 Two Sample t-Test with python을 정리한 내용입니다.IntroPython을 이용하여 Two Sample t-Test with python 수행과정을 알아봅니다.언제 사용하는가?Two Sample t-Test는 두 개의 독립적인 모집단의 평균이 같은지, 다른지, 같지 않은지를 분석하는 방법입니다. 두 개이 모집단이 모두 정규성 가정을 만족할 때 사용합니다.가설 세우기 귀무가설 (Null Hypothesis, H0) 수면제품(A, B)에 따라 수면시간에 차이가 없습니다. 대립가설 (Alternative Hypothesis, H1 or HA) 수면제품(A, B)에 따라 수면시간에 차이가 있습니다. Two Sample t-Test 1단계: 정규성 검정(Normality Test) 귀무가설: 정규분포를 따릅니다. 대립가설: 정규분포를 따르지 않습니다. n &amp;lt; 5,000: Shapiro-Wilk Normality Test n &amp;gt;= 5,000: Anderson-Darling Normality Test 2단계: 등분산 검정(F-test of Equality of Variances) 귀무가설: 등분산입니다. 대립가설: 이분산입니다. 3단계-1: Two Sample t-Test (등분산) 등분산이 가정된 Two Sample t-Test를 계산합니다. \\(t = frac{(\\bar x_{1} - \\bar x_{2}) - (\\mu_{1} - \\mu_{2})}{S_{p}\\sqrt(\\frac{1}{n_{1}}-\\frac{1}{n_{2}})}\\) t분포https://www.edwith.org/python-data-analysis-2023/lecture/1475045 3단계-2: Two sample t-test (이분산) 이분산이 가정된 Two Sample t-Test를 계산합니다. \\[t = frac{(\\bar x_{1} - \\bar x_{2}) - (\\mu_{1} - \\mu_{2})}{\\sqrt(\\frac{S_{1}^{2}}{n_{1}}+\\frac{S_{2}^{2}}{n_{2}})}\\] 등분산과 마찬가지로 t분포를 따릅니다. 실습 가설 설정 귀무가설: 수면제품(A, B)에 따라 수면시간에 차이가 없습니다. 대립가설: 수면제품(A, B)에 따라 수면시간에 차이가 있습니다. 데이터 로딩https://www.edwith.org/python-data-analysis-2023/lecture/1475045 분석 1단계: 정규성 검정(Normality Test) 귀무가설: 정규분포를 따릅니다. 대립가설: 정규분포를 따르지 않습니다. n &amp;lt; 5,000 : Shapito-Wilk Normality Test (shapiro(data.variable)) n &amp;gt;= 5,000 : Anderson-Darling Normality Test (anderson(data.variable)) shapiro normality test 결과 A 그룹의 유의확률(p-value)가 0.408, B 그룹의 유의확률(p-value)가 0.351로 귀무가설(정규분포 따름)을 만족합니다. 정규성 검정https://www.edwith.org/python-data-analysis-2023/lecture/1475045 분석 2단계: 등분산 검정(F-test of Equality of Variances) 귀무가설: 등분산입니다. 대립가설: 이분산입니다. 등분산 검정https://www.edwith.org/python-data-analysis-2023/lecture/1475045 분석 3단계: 등분산이 가정된 Two Sample t-Test 등분산이 가정된 Two Sample t-Test 분석결과 유의확률(p-value)가 0.079로 귀무가설을 만족합니다. 즉, 수면제품(A, B)에 따라 수면시간에 차이가 없습니다. 등분산이 가정된 Two Sample t-Testhttps://www.edwith.org/python-data-analysis-2023/lecture/1475045코드import pandas as pdimport seaborn as snsimport scipy.stats as statsfrom scipy.stats import shapiro# load datasleep = pd.read_excel( io = &#39;03sleep.xlsx&#39;, sheet_name = 0)print(sleep)# Analysis I: Normality Test# n &amp;lt; 5,000 -&amp;gt; Shapito-Wilk Normality Test# group Ashapiro_test_A = shapiro(sleep.loc[sleep[&quot;product&quot;] == &quot;A&quot;, &quot;time&quot;])print(shapiro_test_A)# 유의확률(0.408) &amp;gt; 유의수준(0.05)) : 귀무가설 -&amp;gt; 정규성 가정을 만족합니다.# group Bshapiro_test_B = shapiro(sleep.loc[sleep[&quot;product&quot;] == &quot;B&quot;, &quot;time&quot;])print(shapiro_test_B)# 유의확률(0.351) &amp;gt; 유의수준(0.05)) : 귀무가설 -&amp;gt; 정규성 가정을 만족합니다.# Analysis II: 등분산(성) 검정stats.levene( sleep.loc[sleep[&quot;product&quot;] == &quot;A&quot;, &quot;time&quot;], sleep.loc[sleep[&quot;product&quot;] == &quot;B&quot;, &quot;time&quot;])# 유의확률(0.624) &amp;gt; 유의수준(0.05) : 귀무가설 -&amp;gt; 등분산을 만족합니다.# Analysis III: 등분산이 가정된 Two sample t-teststats.ttest_ind( sleep.loc[sleep[&quot;product&quot;] == &quot;A&quot;, &quot;time&quot;], sleep.loc[sleep[&quot;product&quot;] == &quot;B&quot;, &quot;time&quot;], equal_var = True, alternative = &#39;two-sided&#39;)# 유의확률(0.079) &amp;gt; 유의수준(0.05) : 귀무가설 -&amp;gt; 수면제(A, B)에 따라 수면시간에 통계적으로 유의한 차이는 없습니다.Take Home MessageTwo Sample t-Test 이론을 학습하고 Google colab에서 실습해 보았습니다." }, { "title": "파이썬을 활용한 데이터 분석 (중급) - 2. Wilcoxon&#39;s Signed Rank Test with python", "url": "/posts/Python_Data_Analysis_2/", "categories": "Bioinformatics, Statistics", "tags": "BI, bioinformatics, python, statistics", "date": "2023-06-28 07:29:14 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 인사이트마이닝 이부일 CEO의 Wilcoxon’s Signed Rank Test with python을 정리한 내용입니다.IntroPython을 이용하여 Wilcoxon’s Signed Rank Test 수행과정을 알아봅니다.언제 사용하는가?Wilcoxon’s Signed Rank Test는 하나의 모집단의 평균이 기존보다 커졌는지, 작아졌는지, 같지 않은지를 분석할 때 사용합니다. One sample t-test와 다른점은 정규성 가정이 깨졌을 때 사용하는 분석 방법입니다.가설 세우기 귀무가설 (Null Hypothesis, H0) 퀴즈 시험성적의 평균은 3.7점 입니다. 대립가설 (Alternative Hypothesis, H1 or HA) 퀴즈 시험성적의 평균은 3.7점이 아닙니다. Wilcoxon’s Signed Rank Test 1단계 데이터에서 평균 3.7점을 빼줍니다. 2단계 1단계의 결과를 절대값으로 변경합니다. 3단계 절대값이 0인 값은 삭제합니다. 절대값이 가장 작은 값이 순위 1이 됩니다. 동일한 값이 있을 때에는 순위의 평균으로 지정합니다. 4단계 평균 3.7점보다 작은 값의 순위에 -를 붙입니다. 5단계 W+ (평균보다 큰 값의 순위의 합) W- (평균보다 작은 값의 순위의 합) 두 가지 값을 구합니다. 6단계 Wilcoxon의 표에서 유의확률(p-value)를 구합니다. 실습 가설 설정 귀무가설: iris 꽃잎의 평균 길이는 3 입니다. 대립가설: iris 꽃잎의 평균 길이는 3이 아닙니다. 데이터 로딩https://www.edwith.org/python-data-analysis-2023/lecture/1475044 분석 1단계: 정규성 검정(Normality Test) 귀무가설: 정규분포를 따릅니다. (정규분포를 따라야만 One sample t-test를 수행할 수 있습니다.) 대립가설: 정규분포를 따르지 않습니다. n &amp;lt; 5,000 : Shapito-Wilk Normality Test (shapiro(data.variable)) n &amp;gt;= 5,000 : Anderson-Darling Normality Test (anderson(data.variable)) shapiro normality test의 유의확률(p-value)가 0.79로 귀무가설(정규분포 따름)을 만족합니다. 정규성 검정https://www.edwith.org/python-data-analysis-2023/lecture/1475044 분석 2단계: Wilcoxon’s signed rank testWilcoxon’s Signed Rank Testhttps://www.edwith.org/python-data-analysis-2023/lecture/1475044코드import pandas as pdimport seaborn as snsimport scipy.stats as statsfrom scipy.stats import shapiro# load datairis = sns.load_dataset(&#39;iris&#39;)print(iris)# Analysis I: Normality Test# n &amp;lt; 5,000 -&amp;gt; Shapito-Wilk Normality Testshapiro_test = shapiro(iris.petal_length)print(shapiro_test)# 유의확률 (7.413 * 10^(-10)) &amp;lt; 유의수준 (0.05) -&amp;gt; 대립가설 지지 -&amp;gt; 정규성 가정을 만족하지 않습니다.# Analysis II: Wilcoxon&#39;s Signed Rank Teststats.wilcoxon( iris.petal_length - 3, alternative = &#39;two-sided&#39; )# 유의확률 (6.942 * 10^(-7)) &amp;lt; 유의수준 (0.05) -&amp;gt; 대립가설 지지 -&amp;gt; iris의 꽃잎 길이는 통계적으로 유의한 차이가 있는 것으로 나타났습니다.Take Home MessageWilcoxon’s Signed Rank Test 이론을 학습하고 Google colab에서 실습해 보았습니다." }, { "title": "파이썬을 활용한 데이터 분석 (중급) - 1. One Sample t-Test with python", "url": "/posts/Python_Data_Analysis_1/", "categories": "Bioinformatics, Statistics", "tags": "BI, bioinformatics, python, statistics", "date": "2023-06-27 07:31:05 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 인사이트마이닝 이부일 CEO의 One Sample t-Test with Python을 정리한 내용입니다.IntroPython을 이용하여 One sample t-test 수행과정을 알아봅니다.언제 사용하는가?One sample t-test는 하나의 모집단의 평균이 기존보다 커졌는지, 작아졌는지, 같지 않은지를 분석할 때 사용합니다. 데이터는 수치형 자료를 사용합니다.가설 세우기 귀무가설 (Null Hypothesis, H0) 모집단의 평균은 \\(\\mu\\)0입니다. (\\(\\mu\\) = \\(\\mu\\)0) 대립가설 (Alternative Hypothesis, H1 or HA) 연구자가 지지하는 가설입니다. (채택되길 바라는 가설) 모집단의 평균은 \\(\\mu\\)0보다 큽니다. (\\(\\mu &amp;gt; \\mu\\)0) 모집단의 평균은 \\(\\mu\\)0보다 작습니다. (\\(\\mu &amp;lt; \\mu\\)0) 모집단의 평균은 \\(\\mu\\)0와 같지 않습니다. (\\(\\mu \\neq \\mu\\)0) 유의수준 (Significant Level, \\(\\alpha\\))표본에서 관찰된 검정통계량이 어떤 값이 나오는지에 따라 귀무가설로 결론을 내릴지, 아니면 대립가설로 결론을 내릴지 결정하는 기준입니다. 보통 0.05로 설정합니다.유의확률 (Significanct Probability)표본에서 관찰된 검정통계량이 귀무가설이 맞다는 가정 하에서 얼마나 일어날까 알려주는 값입니다. 유의확률 &amp;lt; 유의수준 : 대립가설 표본에서 관찰된 값이 귀무가설이 맞다는 가정 하에서 일어나기 어려운 사건인데 일어난 상태입니다. 대립가설을 지지합니다. 유의확률 &amp;gt;= 유의수준 : 귀무가설 표본에서 관찰된 값이 귀무가설이 맞다는 가정 하에서 일어나기 쉬운 사건인데 일어난 상태입니다. 귀무가설을 지지합니다. 검정통계량 (Test Statistics) \\[t = \\frac{\\bar y - \\mu_{0}}{s/\\sqrt n}\\] t(n-1) 분포를 따릅니다. (n-1)은 자유도(df, degree of freedom) 입니다.t-Testhttps://www.edwith.org/python-data-analysis-2023/lecture/1475043실습 가설 설정 귀무가설: 환자들의 평균 키는 15인치 입니다. 대립가설: 환자들의 평균 키는 15인치와 같지 않습니다. 가설 설정https://www.edwith.org/python-data-analysis-2023/lecture/1475043 분석 1단계: 정규성 검정(Normality Test) 귀무가설: 정규분포를 따릅니다. (정규분포를 따라야만 One sample t-test를 수행할 수 있습니다.) 대립가설: 정규분포를 따르지 않습니다. n &amp;lt; 5,000 : Shapito-Wilk Normality Test (shapiro(data.variable)) n &amp;gt;= 5,000 : Anderson-Darling Normality Test (anderson(data.variable)) shapiro normality test의 유의확률(p-value)가 0.79로 귀무가설(정규분포 따름)을 만족합니다. 정규성 검정https://www.edwith.org/python-data-analysis-2023/lecture/1475043 분석 2단계: One sample t-test정규성 검정https://www.edwith.org/python-data-analysis-2023/lecture/1475043* patient.height: 검정변수* popmean: 귀무가설이 참일 때 모평균* alternative: 대립가설 -&amp;gt; &#39;greater&#39; or &#39;less&#39; or &#39;two-sided&#39;* One sample t-test의 유의확률(p-value)가 0.120으로 유의수준인 0.05보다 큽니다. 즉, 환자들의 평균 키는 15인치라는 귀무가설을 지지합니다. &amp;lt;br&amp;gt;&amp;lt;br&amp;gt;코드import pandas as pdimport scipy.stats as statsfrom scipy.stats import shapiro, anderson# load datapatient = pd.read_excel( io=&#39;01patient.xlsx&#39;, sheet_name=0 )print(patient)# Analysis I: Normality Test# n &amp;lt; 5,000 -&amp;gt; Shapito-Wilk Normality Testshapiro_test = shapiro(patient.height)print(shapiro_test)# Analysis II: One sample t-teststats.ttest_1samp( patient.height, popmean = 15, alternative = &#39;two-sided&#39;)Take Home MessageOne sample t-Test 이론을 학습하고 Google colab에서 실습해 보았습니다." }, { "title": "(EDWITH-KOBIC) Basic of ML and DL for Cancer Genomics", "url": "/posts/Certificate_ML_and_DL_for_Cacner_Genomics/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, ML, DL, Cancer, KOBIC", "date": "2023-06-26 07:16:32 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "ML and DL for Cancer Genomics VI - 딥러닝 구동 환경 구축 1", "url": "/posts/ML_and_DL_for_Cancer_Genomics_V/", "categories": "Bioinformatics, ML", "tags": "BI, bioinformatics, cancer, ML, DL", "date": "2023-06-22 07:42:50 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 경희대학교 이과대학 김권일 교수님의 딥러닝 구동 환경 구축 1를 정리한 내용입니다.IntroMachine learning 관련 기초 개념을 확인하고, 공개된 논문내용 및 데이터를 바탕으로 직접 실습하고 학습하는 과정입니다.데이터를 표현하는 방식: 텐서텐서는 핵심 속성 세 가지를 지니고 있습니다. rank: 축의 개수. rank-3 텐서에는 3개의 축이 있습니다. 행렬에는 2개의 축이 있습니다. numpy, tensorflow 같은 python library에서 ndim 속성에 저장되어 있습니다. shape: 텐서의 각 축을 따라 얼마나 많은 차원이 있는지 나타내는 정보입니다. dtype: 텐서에 포함된 데이터 타입입니다. 텐서플로와 케라스 텐서플로(TensorFlow) 구글에서 만든 python 기반의 무료 오픈 소스 machine learning 플랫폼입니다. NumPy와 매우 비슷하며 간단한 텐서 연산 뿐만 아니라 학습 과정에 필요한 연산들을 제공합니다. 케라스(Keras) TensorFlow 위에 구축된 python용 deep learning API로 deep learning model을 쉽게 만들고 훈련할 수 있는 방법을 제공합니다. NumPy와 매우 비슷하며, 간단한 텐서 연산 뿐만 아니라 학습 과정에 필요한 연산들을 제공합니다. https://www.edwith.org/deep-learning-2023/lecture/1475088DeepDEP이러한 배경에서 DeepDEP은 unsupervised pretraining을 수행하는데 다음과 같은 특징을 가집니다. Genomic representations(대표값) of tumors를 얻기 위해서 수많은 unlabeled tumor samples로 pretrain을 진행합니다. (with genomics data but no screening results) Gene dependency 예측을 최적화하기 위하여 limited ‘labeled’ CCL samples로 fine-tune을 진행합니다. (with genomics and screens) 결국 DeepDEP는 high-dimensional genomic profiles of both tumor and cell line samples로부터 representations를 pretraining으로 추출한 후 이에 기반하여 gene dependency와의 상관관계를 학습합니다.AutoencoderAutoencoder란 단순히 입력을 출력으로 복사하는 신경망입니다. Hidden layer의 neuron 수를 input layer보다 작게 해서 data를 압축할 수 있는데, 이를 통하여 data를 효율적으로 표현하는 방법을 학습하도록 합니다. Autoencoder는 항상 encoder와 decoder 두 부분으로 구성되어 있습니다. encoder: 인지 네트워크(recognition network)라고도 하며, 입력을 내부 표현으로 변환합니다. decoder: 생성 네트워크(generative network)라고도 하며, 내부 표현을 출력으로 변환합니다. 이러한 학습을 통해 입력 data에서 가장 중요한 특성을 학습하도록 합니다. 또한 여러 개의 hidden layer를 추가하여 deep autoencoder도 만들 수 있습니다.Take Home MessageGoogle colab에서 딥러닝 구동 환경을 구축하고 분석을 실습해 보았습니다." }, { "title": "ML and DL for Cancer Genomics IV - DL Algorithm II", "url": "/posts/ML_and_DL_for_Cancer_Genomics_IV/", "categories": "Bioinformatics, ML", "tags": "BI, bioinformatics, cancer, ML, DL", "date": "2023-06-20 12:29:30 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 경희대학교 이과대학 김권일 교수님의 딥러닝 알고리즘 2를 정리한 내용입니다.IntroMachine learning 관련 기초 개념을 확인하고, 공개된 논문내용 및 데이터를 바탕으로 직접 실습하고 학습하는 과정입니다.오차 역전파 알고리즘최적의 학습 결과를 갖는 neural network를 설계하려면 근본적으로 입력이나 특정 neuron의 weight를 약간 변경시키면 출력에 작은 변화가 일어난다는 점에 근거하고 있습니다. 여기서 activation function으로 쓰이는 sigmoid function은 0에서 1까지 연속적으로 변하는 출력을 갖기 때문에 weight나 bias를 조금 변화시켰을 때 출력이 조금씩 변하도록 만들 수 있습니다.Neural network는 backpropagation(역전파)를 통해 “역방향으로 error를 전파”시키면서 최적의 학습 결과를 찾아가는 것이 가능합니다. Backpropagation을 수행하기 위해 사용되는 cost function(loss function)은 다음과 같이 정의됩니다.\\[C(w, b) \\equiv \\frac{1}{2n} \\sum_{x}^{} ||y(x) - a||^2\\]n은 training에 사용되는 input node의 수y(x)는 입력 x를 넣었을 때 기대 출력a는 실제 출력을 의미합니다. 이를 mean square error (MSE; 평균제곱 오차)라고 부르며, 학습의 최종 목표는 MSE를 최소화하는 것입니다. Cost function에서 예측 값과 label의 오차를 절대값이 아닌 제곱으로 처리하는 이유는 다음과 같습니다. 오차가 큰 경우에 더 큰 가중치를 주어 학습을 빠르게 처리합니다. MSE를 볼록함수(convex function)로 만들어 최적의 weight를 효과적으로 찾기 위함입니다. 절대값은 미분불가능 수식이기 때문입니다. Gradient descent(경사 하강법)을 기반으로 backpropagation을 진행하며 학습을 수행합니다.MSE와 Gradient DescentMSE를 최소로 만드는 w와 b의 해를 찾는 방법입니다. 우선 b를 무시하고 w에 집중해보면, MSE는 w를 중심으로 한 convex function(볼록 함수)입니다. 아래로 볼록한 convex function이며 이 함수의 최소값을 찾는 것, 즉 error를 최소화하는 값을 찾는 과정입니다. 일단 w를 1로 설정합니다. w=1에서의 접선의 기울기를 계산하면, 최소값으로 가기 위한 방향과 크기를 찾을 수 있습니다. 접선의 방향이 양수가 나온다는 것은 MSE가 양의 방향으로 증가하는 경향을 보인다는 의미합니다. 증가하면 안되니 반대방향으로 가야합니다. 접선 만큼의 크기를 원래 w에서 빼주면 최소값으로 갈 수 있습니다. Gradient Descenthttps://www.edwith.org/deep-learning-2023/lecture/1475086Gradient Descent를 위한 편미분Neural network 크기가 커지고 입력이나 출력의 개수가 많아지면 parameter의 수가 너무 많기 때문에 weight와 bias를 조절하여 cost function을 최소화하는 작업이 매우 어렵게 됩니다.입력이나 출력의 개수가 많아진 상태에서 weight나 bias 값을 작게 변화시키면, 출력 쪽에서 생기는 변화 역시 매우 작게 생기며, 작은 구간만 놓고 보았을 때 선형적인 관계가 있습니다. 작은 변화의 관점에서는 선형적인 관계이기 때문에, 출력에서 생긴 오차를 반대의 입력 쪽으로 전파시키면서 weight와 bias 등을 갱신합니다.Cost function이 weight와 bias의 함수로 이루어졌기 때문에 출력 부분부터 시작해서 입력 쪽으로(역방향으로) 순차적으로 cost function에 대한 편미분을 구하고 여기에서 얻은 편미분 값을 이용하여 weight와 bias 값을 갱신합니다.모든 training data에 대해 이 작업을 반복적으로 수행하다 보면, training data에 최적화된 weight와 bias 값들을 얻을 수 있습니다. Backpropagation은 출력부터 반대 방향으로 순차적으로 편미분을 수행해 나가면서 weight와 bias 값들을 갱신시킨다는 의미입니다.Neural Network에서의 편미분https://www.edwith.org/deep-learning-2023/lecture/1475086Backpropagation 상세: Chain RuleChain rule을 이용하면 backpropagation 식을 좀 더 쉽게 풀어낼 수 있습니다. 여기서 chain rule이란, 합성함수 y=f(g(x))가 t=g(x), y=f(t)로 분해될 때 다음이 성립함을 나타내는 법칙입니다.\\(\\frac{dy}{dx} = \\frac{dy}{dt} \\frac{dt}{dx}\\)Backpropagationhttps://www.edwith.org/deep-learning-2023/lecture/1475086Backpropagation 장단점Hornik et al, 1989의 연구에서 hidden node가 충분히 많다면 activation function으로 무엇을 사용하든 multi-layer feedforward neural network는 어떤 함수라도 원하는 정확도만큼 슨사화할 수 있음을 증명했습니다. 그러나 hidden layer의 neuron 개수를 어떻게 설정하느냐는 아직도 해결되지 않은 문제이며, 시행착오 방법에만 의존해서 조정할 수 밖에 없습니다.Backpropagation neural network는 강력한 능력으로 인해 overfitting 현상을 자주 겪게 됩니다. 두 가지 전략을 통해 overfitting을 완화시킬 수 있습니다. Early stopping(조기 종료): Data를 training set과 validation set으로 분리합니다. Training set은 gradient descent를 계산하고 weight와 bias를 갱신하는데 사용합니다. Validation set는 error를 예측하는데 사용되고 만약 training set의 error가 줄어들 때 validation set의 error가 높아진다면 즉시 훈련을 종료하는 방법입니다. Regularization(정규화): Cost function에 weight와 bias의 제곱합과 같은 network 복잡도를 표현하는 부분을 추가하는 방법입니다. Deep Learning이론상으로 parameter 수가 많으면 많을수록 model의 복잡성이 높아지고 예측 및 분류 능력이 커집니다. 이는 아무리 복잡한 학습 문제라도 parameter를 증가시키면 해결이 가능하다는 것을 의미합니다. 그러나 동시에 복잡한 model의 훈련 효과가 좋지 않고 쉽게 overfitting에 빠집니다.최근 클라우드 컴퓨터와 빅데이터 시대가 도래하면서 컴퓨터의 능력은 대대적으로 높아졌고 훈련 성능 저하 문제를 완화시켰습니다. 그리고 training data가 많아짐에 따라 overfitting 위험은 대폭 낮아졌습니다. 이에 따라 deep learning을 대표로 하는 복잡한 model들이 사람들의 관심을 받기 시작했습니다. 전형적인 deep learning model은 깊은 층을 쌓은 neural network입니다. Neural network model의 능력을 향상시킬 수 있는 가장 간단한 방법은 hidden layer 개수를 늘리는 것입니다.Hidden layer가 많으면 상응하는 neuron 연결 weight, 임계값 등의 parameter 수가 늘어납니다. Model의 복잡성도 단순히 hidden layer neuron 수를 증가시키는 것만으로 늘릴 수 있습니다. 하지만 model의 복잡성을 증가시키는 관점에서 바라보면 hidden layer의 개수를 증가시키는 것이 hidden layer neuron의 수를 증가시키는 것보다 효율적입니다. Hidden layer의 수를 증가시키면 activation function을 가진 neuron의 개수를 늘리게 될 뿐 아니라 activation function이 내장된 층 수도 증가하기 때문입니다.그러나 여러 hidden layer를 가진 neural network는 전통적인 algorithm(backpropagation)을 사용하여 훈련시키기 힘든 점이 있습니다. 오차가 hidden layer에서 backpropagation 될 때 vanishing(소실)되어 update 하기 어려운 점이 있기 때문입니다. 이러한 현상을 vanishing gradient라고 합니다.Global Minimum and Local Minimum만약 E로 neural network의 training set에 대한 error를 나타낸다면, 이는 weight와 bias(threshold)에 관한 함수일 것입니다. 이 때 neural network의 훈련 과정은 하나의 parameter 탐색 과정이라고 볼 수 있습니다. 즉, parameter 공간에서 최적의 parameter를 찾아 E를 최소화 하는 것입니다. 여기에는 두 가지 종류의 ‘최적’이 있습니다. 바로 local minimum과 global minimum입니다.Local minimum은 parameter 공간의 어떤 점이 되고 주변 점들의 cost function(loss function, error 함수값)이 해당 점의 함수값보다 작으면 안됩니다. 이와 비슷하게 global minimum의 해는 parameter 공간 내의 모든 점들이 error 함수값보다 작지 않다는 것을 의미합니다.Gradient descent 방법은 임의의 시작점에서 출발해 반복적으로 최적의 parameter 값을 찾아 나갑니다. 매번 반복할 때마다 우리는 먼저 cost function이 해당 점에서 갖는 기울기를 계산하고 그 기울기에 따라 탐색 방향을 정합니다. 만약 해당 점에서 cost function의 기울기가 0이라면 이미 local minimum에 도달한 것입니다. 이는 parameter 반복 갱신이 그 점에서 멈출 것이라는 의미입니다. 또한 cost function이 하나의 local minimum만을 갖는다면 해당 값이 바로 global minimum이 됩니다.Local Minimum 함정 탈출 전략https://www.edwith.org/deep-learning-2023/lecture/1475086Take Home MessageSummary 1https://www.edwith.org/deep-learning-2023/lecture/1475086Summary 2https://www.edwith.org/deep-learning-2023/lecture/1475086" }, { "title": "ML and DL for Cancer Genomics III - DL Algorithm I", "url": "/posts/ML_and_DL_for_Cancer_Genomics_III/", "categories": "Bioinformatics, ML", "tags": "BI, bioinformatics, cancer, ML, DL", "date": "2023-06-20 11:49:55 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 경희대학교 이과대학 김권일 교수님의 딥러닝 알고리즘 1을 정리한 내용입니다.IntroMachine learning 관련 기초 개념을 확인하고, 공개된 논문내용 및 데이터를 바탕으로 직접 실습하고 학습하는 과정입니다.인공신경망 개념 - Neural network 구조생물의 neural network에서 각 neuron은 기타 neuron과 서로 연결되어 있습니다. 만약 neuron이 흥분한다면 연결된 neuron으로 화학물질을 전하여 neuron 내의 전압을 바굽니다. 이후 neuron의 전압이 threshold(임계값)을 넘으면 해당 neuron이 활성화 됩니다. 즉, neuron이 흥분해서 다른 neuron을 향해 화학물질을 전달하는 방식으로 신호를 전달합니다.생물 neural network를 machine learning model로 구현 가능합니다. (Artificial Neural Network, 인공신경망) 이 model에서 neuron은 n개의 기타 neuron에서 전송하는 입력 신호를 받습니다. 이러한 입력 신호는 weight(가중치)를 가진 connection(연결)을 거쳐 전달됩니다. Neuron이 받은 총 입력값은 neuron이 threshold와 비교하고 activation function(활성화 함수)를 통해 neuron의 출력을 처리합니다.Neural Network 구조https://www.edwith.org/deep-learning-2023/lecture/1475085가장 직관적인 activation function은 단위 계단 함수입니다. 이 함수는 입력값을 출력값 ‘0’(억제)이나 ‘1’(흥분)에 투영시킯니다. 그러나 단위 계단 함수는 매끄럽지 못하고 불연속성이라는 좋지 않은 특성이 있습니다. 따라서 activation function으로 sigmoid function을 자주 사용합니다. Sigmoid function은 비교적 넓은 범위 내에서 변화하는 입력값을 (0, 1) 사이의 출력값 범위 내로 밀어넣을 수 있습니다. 이런 다수의 neuron을 일정한 겹층 구조로 연결하면 neural network를 얻게 됩니다.Activation Functionhttps://www.edwith.org/deep-learning-2023/lecture/1475085Neuron 기본 구조Neuron의 기본 구조는 McCulloch and Pitts(M-P) neuron으로 불립니다. 해당 neuron은 연결된 이전 neuron들의 입력값에 연결 weight(가중치)의 총합을 받은 뒤 임계값(threshold)과 비교하여 activation function을 통해 출력값을 생성합니다. 입력층 neuron들의 입력신호(x1, x2, …)에 각각 고유한 weight(w1, w2, …)를 부여하는데, weight는 각 신호가 다음 연결 neuron에 주는 영향력을 조절하는 요소입니다. Weight가 클수록 해당 신호가 그만큼 더 중요함을 의미합니다. w는 입력값이 출력값에 주는 영향력을 조절하는 parameter라면, threshold(실제 계산에서는 bias로 처리됨)는 neuron이 얼마나 쉽게 활성화 되느냐를 조절하는 parameter입니다.McCulloch and Pitts(M-P) Neuronhttps://www.edwith.org/deep-learning-2023/lecture/1475085Multi-layer Neural NetworkNeuron의 아름다움은 ‘층을 쌓아’ multi-layer neural network를 만들 수 있다는 데 있습니다. 그림에서 출력층과 입력층 사이에 한 층의 neuron이 있는데 이를 hidden layer(은닉층)이라고 부릅니다. Hidden layer와 출력층 neuron은 모두 activation function의 기능을 가집니다.Neural network 각 층의 neuron은 다음 층 neuron과 완전 연결되어 있고, 같은 층의 neuron이나 층을 뛰어넘는 neuron끼리는 연결되지 않습니다. 이러한 neural network 결합 구조를 일반적으로 multi-layer feedforward neural networks (다층 순방향 신경망)이라고 부릅니다. 여기서 입력층 neuron은 외부 입력을 받고, hidden layer와 출력층 neuron은 신호를 가공합니다. 그리고 최종 결과는 출력층 neuron에 의해 출력되고, 입력층 neuron은 입력만 받고 함수 처리는 하지 않습니다. 반면 hidden layer와 출력층은 기능성 neuron을 포함합니다.Multi-layer Neural Networkhttps://www.edwith.org/deep-learning-2023/lecture/1475085Neural network 학습 과정에서는 training data를 통해 neuron 간의 connection weight(연결 가중치)와 각 기능성 neuron의 threshold만 조절하면 됩니다. 즉, neural network가 학습하는 것은 모두 connection weight와 threshold에 내재되어 있습니다.Take Home MessageSummaryhttps://www.edwith.org/deep-learning-2023/lecture/1475084" }, { "title": "ML and DL for Cancer Genomics II - ML Basic Concpts and Evaluation Methods", "url": "/posts/ML_and_DL_for_Cancer_Genomics_II/", "categories": "Bioinformatics, ML", "tags": "BI, bioinformatics, cancer, ML, DL", "date": "2023-06-20 07:57:12 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 경희대학교 이과대학 김권일 교수님의 기계학습 기초 개념 및 평가 방법을 정리한 내용입니다.IntroMachine learning 관련 기초 개념을 확인하고, 공개된 논문내용 및 데이터를 바탕으로 직접 실습하고 학습하는 과정입니다.기계학습(Machine Learning)이란?기계학습(Machine Learning)이란 컴퓨터로 경험을 활용해 시스템을 개선해 나가는 방법론입니다. 컴퓨터 시스템에서 일반적으로 경험은 data 형식으로 존재합니다. 컴퓨터를 활용해 data에서 하나의 model을 만들어내는 learning algorithm입니다. 즉, model이란 data를 대상으로 learning algorithm이 학습한 결과물 입니다. 이러한 model은 새로운 상황에 대면했을 때 이에 상응하는 판단을 제공합니다.예를 들어 다음과 같이 수박에 관한 데이터가 존재합니다. 수박1: (색깔=청록; 꼭지모양=말림; 소리=혼탁함) 수박2: (색깔=진녹색 꼭지모양=약간 말림; 소리=둔탁함) 수박3: (색깔=연녹색; 꼭지모양=곧음; 소리=맑음)수박에 관한 데이터의 집합을 data set,각 기록은 하나의 대상에 대한 묘사이고 이 대상을 instance(사례) 혹은 sample,색깔, 소리 등 대상의 성질을 반영하는 것을 attribute(속성) 혹은 feature(특성),청록색, 진녹색, 연녹색 등 feature에 대해 취할 수 있는 값을 attribute value 혹은 feature value,이러한 feature value가 sample별로 투영되어 잇는 공간을 sample space라고 지칭합니다.Sample Spacehttps://www.edwith.org/deep-learning-2023/lecture/1475084Data set의 feature 수는 차원수(dimensionality)를 결정합니다.TrainingTraining 혹은 learning은 data를 통해 model을 만들어가는 과정을 의미합니다. Model training 과정은 data를 통해 hypothesis를 세우고 잠재되어 있는 규칙을 찾아내는 과정입니다. (data-driven hypothesis)하지만 data의 feature만으로는 유용한 결과를 얻어낼 수 없습니다. Label이라는 결과를 나타내는 정보가 필요합니다.만약 우리가 예측하려는 값이 ‘잘 익은 수박’, ‘덜 익은 수박’과 같은 discrete value(이산값; 비연속적인 값)일 경우, 이러한 학습 문제를 classification이라고 합니다.반대로 예측하려는 값이 수박의 당도를 나타내는 수치 ‘0.95’, ‘0.37’과 같은 continuous value(연속값)일 경우, 이러한 학습 문제를 regression이라고 합니다.TestingModel training 후, 해당 model을 활용하여 예측하는 과정을 testing이라고 합니다. 기계학습의 목표는 training set에서 좋은 성능을 나타내는 것이 아니라, 새로운 sample과 data에 적용되고 좋은 퍼포먼스를 내는 것입니다. 이런 경우를 generalization(일반화)가 잘 되었다고 이야기 합니다.ErrorModel의 예측 값과 sample의 실제 값 사이의 차이를 error라고 합니다. Error rate(오차율): 전체 sample 수와 잘못 분류한 샘플 수의 비율 Accuracy(정밀도): 1 - 오차율 Machine learning으로 하고 싶은 궁극적인 목표는 testing error가 가장 작은 model을 만들어 내는 것입니다. 하지만 보통 대부분 model이 training erorr가 매우 작고 training sample에서 좋은 성능을 보여주지만 testing error는 그렇지 못한 경우가 많습니다.Overfitting and Underfitting새로운 sample data를 대상으로 좋은 퍼포먼스를 발휘하기 위해서는 model이 training data에서 보편규칙을 찾아야 합니다. 그러나 model이 training data에서 학습을 과도하게 잘하면 training data에만 내재된 특정 특성을 모든 data에 내재된 일반적인 성질로 오해하게 됩니다. 즉, generalization 성능이 떨어지고 이러한 현상을 overfitting(과적합)이라고 합니다. 이와 반대되는 개념은 underfitting(과소적합)이라고 하며 model이 training data의 일반 성질을 제대로 학습하지 못했다는 것을 의미합니다.Underfitting은 algorithm을 더욱 견고하게 잘 만들면 해결될 수 있습니다.하지만 Overfitting은 다루기가 매우 까다롭습니다. ML이 넘어야 할 핵심 장애물 입니다. 모든 learning algorithm은 overfitting을 방지하기 위한 장치를 갖고 있음에도 불구하고 overfitting을 피할 수 없으며, 단지 이를 완화하고 위험을 최소화하는 것에 만족해야 합니다.기계학습 평가 방법대부분 learning algorithm은 조율해야하는 parameter가 있으며, 두 종류가 존재합니다. Hyper-parameter: algorithm의 parameter이며 일반적으로 10개 이내 입니다. Model의 구조 전반에 대한 parameter입니다. (산) Model-parameter: model의 parameter이며 개수가 매우 많을 수 있습니다. (나무) Parameter를 어떻게 설정하는가에 따라 model의 성능은 큰 차이를 보입니다. 따라서 model testing 및 model selection 시 learning algorithm의 선택 뿐만 아니라 algorithm parameter에 대한 설정도 고려해야 합니다. 이러한 과정을 parameter tuning이라고 합니다.최적의 model을 얻기 위해서 어떤 learning algorithm을 사용해야 하고, 어떤 parameter를 선택해야 하는지 결정해야 하는데, 이를 model selection이라고 합니다.이상적인 해답은 testing error를 기준으로 평가하여 가장 작은 model를 선택하는 것입니다. 이를 위하여 training set에서 일부를 testing에 사용합니다. 이 때 주의애햐 할 점은 training set에서의 testing set과 training set의 중복을 최대한 피해야 합니다.Validation Setm개의 sample을 가진 data set D가 있을 때, 적절히 처리하여 training set S와 testing set T로 나눠야 합니다. 새로운 sample에 대한 testing set과 구분하여 위 testing set을 validation set으로 부릅니다. 많은 연구에서 이 용어를 혼용하여 사용하는데 확실하게 구분하여 사용해야 합니다.Cross ValidationCross validation(교차 검증)은 data set D를 k개의 disjoing set(서로소 조합; mutually exclusive)으로 나누는 것으로 시작합니다. 개별 부분집합 D는 되도록 전체 data의 lebel 분포를 반영하도록 나눕니다. 그리고 k-1개의 부분집합들을 training set으로 사용하고, 나머지 한 개의 부분집합을 testing set으로 사용합니다. 이렇게 하면 k개의 training/testing set이 만들어지고, k번의 training과 testing을 거쳐 k개의 testing 결과값 평균을 얻을 수 있습니다. Cross validation을 통한 testing 결과의 안정성과 정확도는 k값에 따라 달라집니다. 이러한 점을 강조하기 위해 k-fild cross validation이라 부르며, 일반적으로 k=10으로 두고 10-fold cross validation을 많이 사용합니다.5-fold Cross Validationhttps://www.edwith.org/deep-learning-2023/lecture/1475084Model Performance MeasureModel으 generalization 성능을 평가하는 기준을 performance measure(성능 측정)이라고 합니다. 이는 프로젝트 목적을 반영해야 하는데, 서로 다른 model의 성능을 비교할 때 일관되지 않은 성능 측도를 사용한다면 판단이 힘들 것입니다. 즉, 어떤 model이 좋은 model인지 결정하는 것은 algorithm과 data가 아닌 data 분석 목적에 달려 있습니다.Recall, Precision and F1 Scroe Error rate(ERR) = (FN+FP) / (전체 data 수=P+N) : 전체 수박 중 잘못 분류한 비율 Precision(PREC) = TP / (TP+FP) : 잘 익었다고 판단한 수박 중에 실제 잘 익은 수박의 비율 Recall(Sensitivity) = TP / (TP+FN) : 모든 잘 익은 수박 중에 잘 선택된 비율 Error rate와 accuracy는 자주 사용되지만 모든 문제에 활용되지는 못합니다. 우리가 알고 싶은 것은 ‘골라낸 수박 중에 잘 익은 수박의 비율’, 혹은 ‘모든 잘 익은 수박 중에 잘 선택된 비율’일 수 있기 때문입니다. 이러한 판단에 대해서 error rate는 도움을 줄 수 없으며, Precision(정밀도)와 recall(재현율)이 이러한 요구에 맞는 성능 측도입니다.Confusion Matrixhttps://www.edwith.org/deep-learning-2023/lecture/1475084Precision과 rcall 사이에는 trade-off가 존재합니다. 일반적으로 precision이 높으면 recall이 낮고(녹색 점선), recall이 높으면 precision이 낮은 경우(파란색 점선)가 많습니다. Precision vs. Recall Trade-offhttps://www.edwith.org/deep-learning-2023/lecture/1475084ROC and AUCModel은 test set에 대하여 실수값 혹은 확률 예측값을 계산합니다. 그 후 해당 에측값과 cut point(분류 임계치)를 비교합니다. Cut off보다 크면 positive value, 작으면 negative value로 분류합니다. 다양한 문제에서 각 문제의 목적과 필요에 따라 서로 다른 cut point를 사용합니다. 만약 precision을 더 중요하게 생각한다면 예측값 배열에서 큰 값을 cut point로 설정하고, recall을 더 중요하게 생각한다면 작은 값을 cut point로 설정합니다. 따라서 cut point에 따라 다른 문제에서 각 model의 성능이 결정됩니다.ROC는 receiver operating characteristic(수신기 조작 특성)의 약자로, 세계 2차대전 당시 적군의 레이더 신호를 분석하는 기술로 활용되었고 1960~70년대부터 심리학, 의학용 test 연구에 응용되기 시작했습니다. 그 후 본격적으로 machine learning 영역에도 응용되고 있습니다.Model의 에측 결과를 기반으로 sample에 대해 예측값 순서를 매기고, 다양한 cut point에 따라 true positive rate(TPR, 참 양성률)과 false positive rate(FPR, 거짓 양성률) 값을 계산하여 x축과 y축에 그려넣으면 ROC curve가 완성됩니다.ROC and AUChttps://www.edwith.org/deep-learning-2023/lecture/1475084Fig (a)에서 대각선은 ‘random prediction model’을 나타낸 것으로 무작위로 답을 선택했을 때 맞출 확률로 이해하면 되겠습니다. 좌표 위의 점 (0, 1)은 모든 positive value를 분류해 낸 ‘가장 이상적인 model’을 의미합니다. 현실에서는 test sample 개수가 많지 않을 때가 많으며, 제한된 data를 이용해 ROC graph를 그리면 유한한 개수의 좌표값을 얻게 됩니다. 이 때는 fig (a)와 같이 매끄러운 ROC curve는 그릴 수 없고 fig (b)와 같은 근사값을 얻을 수 있습니다.만약 어떤 model의 ROC curve가 다른 ROC curve에 완전히 ‘포함’되는 경우, 후자가 전자보다 우수한 성능을 가진 model이라 할 수 있습니다. 하지만 두 model의 ROC curve에 교차가 발생한다면 한 눈에 우열을 가리기 어렵습니다. 이런 상황에서 비교적 합리적인 비교 방법은 ROC curve 아래의 면적을 비교하는 것이며, 이를 AUC(Area Under ROC Curve)라고 합니다.Take Home MessageML은 다양한 parameter로 구성되어 있고, testing error를 최소화하는 쪽으로 parameter를 최적화하여 model selection을 해야합니다. Testing은 training에 포함되면 안되므로, training set에서 일부를 testing에 사용하는데 이를 validation set라고 합니다. Validation set를 만드는데 사용하는 대표적인 방법은 cross validation입니다. Validation set에서 model의 성능을 측정하는 방법에는 단순한 accuracy 측정 뿐만 아니라 precision, recall, ACUT 등의 방법이 있습니다.Summaryhttps://www.edwith.org/deep-learning-2023/lecture/1475084" }, { "title": "Genetic Testing Agency Training 6 - 검사대상자의 권리", "url": "/posts/Genetic_Testing_Agency_Training_VI/", "categories": "Study, L-Genetic Testing Agency Training", "tags": "bioinformatics, genetics", "date": "2023-06-20 07:41:05 +0900", "snippet": "본 post는 질병관리청 유전자검사기관 종사자 교육(2023)의 ‘6차시 - 검사대상자의 권리’를 정리한 내용입니다.인간으로서의 존엄과 가치를 보호받을 권리헌법 제10조와 생명윤리법 제1조에서는 모든 국민은 인간으로서의 존엄과 가치를 가진다고 규정하고 있습니다.정보 주체로서의 권리생명윤리법상 유전정보 주체의 권리를 가집니다. 연구대상자등의 자율성은 존중되어야 하며, 자발적인 동의는 충분한 정보에 근거하여야 합니다. 사생활 보호, 개인정보는 비밀로서 보호되어야 합니다. 연구대상자등의 안전이 충분히 고려되어야 합니다.개인정보보호법상 정보 주체의 권리를 가집니다. 개인정보 처리, 열람에 관한 정보를 제공받을 권리, 삭제 및 파기를 요구할 권리를 가집니다.차별받지 않을 권리생명윤리법 제46조에 따라 누구든지 유전정보를 이유로 교육, 고용, 승진, 보험 등 사회활동에서 다른 사람을 차별하여서는 아니 됩니다.소비자로서의 권리소비자기본법상 소비자의 기본적 권리를 가집니다.소비자로서의 권리https://nih.kohi.or.kr/Take Home Message유전자검사 관련하여 검사대상자의 권리를 알고 보장하는 것은 중요합니다." }, { "title": "(KDCA) 유전자검사기관 종사자 교육(2023)", "url": "/posts/Certificate_Genetics_Testing_Agency_Training/", "categories": "Study, L-Certificate", "tags": "certificate, Genetics, KDCA", "date": "2023-06-20 07:21:35 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "Genetic Testing Agency Training 5 - 유전자검사기관의 숙련도 평가", "url": "/posts/Genetic_Testing_Agency_Training_V/", "categories": "Study, L-Genetic Testing Agency Training", "tags": "bioinformatics, genetics", "date": "2023-06-19 16:51:20 +0900", "snippet": "본 post는 질병관리청 유전자검사기관 종사자 교육(2023)의 ‘5차시 - 유전자검사기관의 숙련도 평가’를 정리한 내용입니다.숙련도 평가 개요평가범위는 유전자검사에 대한 설명 및 동의의 적절성, 검사대상물 처리의 적절성, 유전자검사 결과의 정확성, 유전자검사 분석 및 처리 등 관리의 적절성 등입니다.생명윤리법 제49조의2제1항에 따라 모든 유전자검사기관의 장은 숙련도 평가를 받아야 하며, 보건복지부고시 유전자검사의 숙련도 평가에 필요한 사항의 지정에 고시되어 있습니다.유전자검사기관 신고 확인증 발급일로부터 차기 연도 12월 31일 내 시행 중인 유전자검사 항목에 대해 지정된 평가기관(한국 유전자검사 평가원)에서 숙련도 평가를 받아야 합니다.휴업기관은 당해년도 평가 대상에서 제외됩니다.숙련도 평가 방법숙련도 평가의 구성https://nih.kohi.or.kr/서면평가 이후 외부정도관리 평가, 현장평가가 면제될 수 있는 경우가 있습니다. 의료기관에서 시행하는 질병의 진단 및 치료를 위한 유전자검사에 대해서, 대한병리학회, 진단검사의학재단, 대한임상검사정도관리협회에서 시행하는 인증을 받은 경우가 그 예 입니다.숙련도 평가 범주숙련도 평가 범주https://nih.kohi.or.kr/Take Home Message유전자검사기관의 숙련도 평가는 꼭 받아야 하는 중요한 내용이므로 숙지하고 기한을 준수하여 평가를 수행합니다." }, { "title": "Genetic Testing Agency Training 4 - 유전자검사기관의 의무 및 책임", "url": "/posts/Genetic_Testing_Agency_Training_IV/", "categories": "Study, L-Genetic Testing Agency Training", "tags": "bioinformatics, genetics", "date": "2023-06-19 11:52:02 +0900", "snippet": "본 post는 질병관리청 유전자검사기관 종사자 교육(2023)의 ‘4차시 - 유전자검사기관의 의무 및 책임’을 정리한 내용입니다.서면동의서면동의를 받아야 하는 경우는 두 가지 기준이 있습니다. 먼저 유전자검사기관이 검사대상물을 직접 채취하거나 채취를 의뢰할 경우입니다. 다음은 유전자검사기관이 검사대상물을 인체유래물연구자나 인체유래물은행에 제공하고자 할 경우입니다.서면동의의 주체는 검사대상자입니다. 그러나 검사대상자가 동의 능력이 없거나 불완전한 경우 법정대리인으로부터 동의를 받아야 합니다.서면동의 전 미리 검사대상자 또는 법정대리인에게 유전자검사의 목적과 방법, 예측되는 유전자검사의 결과와 의미 등에 대하여 충분히 설명해야 합니다. 특히 DTC 유전자검사의 경우 검사결과의 한계나 과학적 근거를 충분히 설명해야 합니다.기록 및 보관검사대상물은 유전자검사결과 획득 후 즉시 폐기해야 합니다. 또한 폐기에 대한 사항을 기록하고 보관해야 합니다. 폐기원칙에도 예외사항이 있는데 인체유래물연구자나 인체유래물은행에 제공할 경우입니다.검사대상자의 유전자검사 동의서와 인체유래물연구 동의서는 10년간 보관해야 합니다.유전자검사 결과 역시 10년간 보관해야 할 의무가 있습니다.정보의 공개생명윤리법 제52조제2항 - 정보의 공개https://nih.kohi.or.kr/종사자 교육생명윤리법 시행규칙 제49조의6제1항 - 교육 내용https://nih.kohi.or.kr/거짓표시 또는 과대광고의 금지거짓표시 또는 과대광고의 판정기준은 다섯 가지가 존재합니다. 유전자검사가 과학적으로 완전하게 증명되었다는 표시, 광고 유전자검사가 과학적으로 불확실함에도 불구하고 확실한 것으로 오인, 혼동할 우려가 있는 내용의 표시, 광고 숙련도 평가를 받지 않은 자가 평가를 받았다고 하거나 받은 것으로 오인, 혼동할 우려가 있는 내용의 표시, 광고 금지된 유전자검사 항목을 검사할 수 있는 것으로 오인, 혼동할 우려가 있는 내용의 표시, 광고 의료기관이 아닌 유전자검사기관이 질병의 예방, 진단 및 치료와 관련한 유전자검사를 할 수 있는 것으로 오인, 혼동할 수려가 있는 내용의 표시, 광고 Take Home Message서면동의, 기록 및 보관, 정보의 공개, 종사자 교육, 거짓표시 또는 과대광고의 금지에 대해 확인 했습니다." }, { "title": "(coursera) Artificial Intelligence Algorithms Models and Limitations", "url": "/posts/Artificial_Intelligence_Algorithms_Models_and_Limitations/", "categories": "Study, L-Certificate", "tags": "certificate, AI, coursera", "date": "2023-06-18 12:30:12 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "Genetic Testing Agency Training 3 - 유전자검사항목의 신고", "url": "/posts/Genetic_Testing_Agency_Training_III/", "categories": "Study, L-Genetic Testing Agency Training", "tags": "bioinformatics, genetics", "date": "2023-06-14 07:45:18 +0900", "snippet": "본 post는 질병관리청 유전자검사기관 종사자 교육(2023)의 ‘3차시 - 유전자검사항목의 신고’를 정리한 내용입니다.검사 목적별 유전자검사 항목의 분류생명윤리법 제49조부터 제59조가 유전자검사기관 관련 조항에 해당합니다.유전자검사기관의 시설 및 인력 등에 관한 기준https://nih.kohi.or.kr/금지 또는 제한되는 유전자검사생명윤리법 제50조에 따라 ‘과학적 증명이 불확실하여 검사대상자를 오도할 우려가 있는 신체 외관이나 성격에 관한 유전자검사’는 원칙적으로 금지됩니다.또한 생명윤리법 시행령 제20조 관련 다음 각 목의 어느 하나에 해당하는 유전자검사는 금지됩니다. VDR 유전자에 의한 골다공증 관련 유전자검사 Mt16189 유전자에 의한 당뇨병 관련 유전자검사 UCP-1/PPAR-gamma/ADRB3(B3AR) 유전자에 의한 비만 관련 유전자검사 5-HTT 유전자에 의한 우울증 관련 유전자검사 Mt5178A 유전자에 의한 장수 관련 유전자검사 IGF2R 또는 CALL 유전자에 의한 지능 관련 유전자검사 ACE 유전자에 의한 체력 관련 유전자검사 CYP1A1 유전자에 의한 폐암 관련 유전자검사 DRD2 또는 DRD4 유전자에 의한 호기심 관련 유전자검사제한되는 유전자검사는 건강인을 대상으로 검사하는 것이 금지된 항목이지만, 진료 담당 의사가 해당 질환의 의심된다고 판단하거나 그 질환의 고위험군에 속한다고 판단하는 경우(환자 및 가족력이 있는 환자 가족 대상) 허용되는 항목입니다. HLA-B27(강직성척추염) 관련 유전자검사 BRCA1/2(유방암) 관련 유전자검사 Apolipoprotein E(치매) 관련 유전자검사배아 또는 태아 대상 유전자검사유전자검사기관에서 시행할 수 있는 배아 또는 태아 대상의 유전자검사 항목은 지정된 유전질환에 대해서만 가능합니다. 근이영양증, 수적 이상 염색체이상질환을 비롯한 62개의 유전질환(생명윤리법 시행령 별표3), 시투룰린혈증을 비롯한 137개의 유전질환(보건복지부 고시 ‘배아 또는 태아를 대상으로 유전자검사를 할 수 있는 유전질환의 지정’)이 대상 항목입니다.급여/비급여 관련 정보급여항목은 건강보험 혜택이 적용되는 항목, 비급여항목은 적용되지 않는 항목입니다. 건강보험심사평가원 사이트에서 급여/비급여 항목 조회가 가능합니다.Take Home Message검사 목적별 유전자검사 항목의 분류는 ‘유전자검사 목적’과 ‘유전자검사 목적별 유전자검사 항목’을 신고해야 합니다. 목적1(질병 진단, 치료), 목적2(질병 예측), 목적3(영양, 생활습관 및 신체적 특징에 따른 질병 에방), 목적4(유전적 혈통 찾기), 목적5(개인식별 및 친자확인)로 구분됩니다.생명윤리법에는 금지되는 유전자검사, 제한되는 유전자검사가 존재합니다. 건강인 대상으로 검사가 금지되어 있으나 진료 담당 의사가 해당 질환이 의심된다고 판단하거나 그 질환의 고위험군에 속한다고 판단하는 경우 예외적으로 허용됩니다.배아 또는 태아 대상 유전자검사는 지정된 유전질환을 진단하기 위한 목적에 해당하는 경우에만 시행이 가능합니다." }, { "title": "Genetic Testing Agency Training 2 - 유전자검사 제도의 이해", "url": "/posts/Genetic_Testing_Agency_Training_II/", "categories": "Study, L-Genetic Testing Agency Training", "tags": "bioinformatics, genetics", "date": "2023-06-09 11:56:02 +0900", "snippet": "본 post는 질병관리청 유전자검사기관 종사자 교육(2023)의 ‘2차시 - 유전자검사 제도의 이해’를 정리한 내용입니다.유전자검사와 생명윤리법생명윤리법 제49조부터 제59조가 유전자검사기관 관련 조항에 해당합니다.생명윤리법 제49조 ~ 제50조https://nih.kohi.or.kr/생명윤리법 제51조 ~ 제53조https://nih.kohi.or.kr/생명윤리법 제54조 ~ 제59조https://nih.kohi.or.kr/2021년 12월 30일 기준으로 개정 시행된 생명윤리법에 따라 변경된 사항을 알아보겠습니다.먼저 유전자검사 목적에 따른 신고 방식으로 변경 되었습니다. 기존에는 시행하던 검사 항목별 신고제에서 현재는 검사 목적에 따라 시설, 장비, 인력을 신고하는 검사 목적별 신고제로 변경 되었습니다. 검사 목적별 신고제는 다섯 개의 검사 목적으로 분류하고 있으며 그에 따른 시설, 장비, 인력을 구분하여 신고해야 합니다.유전자검사 목적별 신고제1https://nih.kohi.or.kr/유전자검사 목적별 신고제2https://nih.kohi.or.kr/두 번째는 유전자검사기관 종사자 교육이 의무화 되었습니다. 유전자검사기관 종사자 교육에 관한 규정으로 보건복지부고시에 포함되어 있습니다.세 번째는 숙련도 평가가 도입 되었습니다. 기존에 시행하던 정확도 평가에서 현재 숙련도 평가로 변경 되었습니다. 이것 또한 유전자검사의 숙련도 평가에 필요한 사항의 저정으로 보건복지부고시에 포함되어 있습니다.네 번째는 DTC 유전자검사기관의 검사역량 인증이 도입 되었습니다. 소비자 대상 직접 시행 유전자검사기관의 검사역량 인증에 관한 규정으로 보건복지부고시에 포함되어 있습니다.유전자검사기관의 신고생명윤리법 제49조 제1항에 따르면, 유전자검사를 하려는 자는 ‘유전자검사목적’에 따라 보건복지부령으로 정하는 ‘시설 및 인력 등을 갖추고’ 보건복지부장관에게 신고하여야 합니다. 따라서 유전자검사기관으로서 최초 신고의 요건은 ‘검사목적’과 ‘해당 목적에 따른 시설, 장비, 인력’을 갖추는 것입니다.유전자검사기관의 시설 및 인력 등에 관한 기준https://nih.kohi.or.kr/생명윤리법 제49조 제2항에 따르면, 유전자검사기관의 신고는 제출서류를 갖추고 온라인(질병보건통합관리시스템, http://is.kdca.go.kr)으로 제출합니다.유전자검사기관 신고 제출서류https://nih.kohi.or.kr/또한 제1항에 따라 신고한 사항 중 대통령령으로 정하는 ‘중요한 사항’을 변경하는 경우에도 신고하여야 합니다. 여기서 중요한 사항이란 기관의 소재지, 기관장, 기관의 명칭, 유전자검사 목적, 유전자검사 목적별 유전자검사 항목, 기관의 시설 및 인력이 해당합니다. 변경신고 또한 제출서류를 갖추고 온라인(질병보건통합관리시스템, http://is.kdca.go.kr)으로 제출하는데 이 때 중요한 것은 변경사항이 발생한 날부터 30일 이내 변경신고가 이루어져야 한다는 점입니다.유전자검사기관 변경신고 해당 사항https://nih.kohi.or.kr/유전자검사기관 변경신고 제출서류https://nih.kohi.or.kr/만약 신고를 하지 않고 유전자검사를 하는 경우 검사대상물 폐기 명령, 시설 폐쇄 명령, 1년 이하 징역 또는 2천만원 이하 벌금이 부과될 수 있습니다. 시설, 인력 등이 기준에 맞지 않는 경우 개선 명령 또는 시설 사용 금지 명령이 내려질 수 있습니다. 변경신고를 하지 않는 경우 200만원 이하 과태료, 1년 이내의 업무정지 또는 2억원 이하의 과징금이 부과될 수 있습니다.유전자검사 기관의 휴/폐업 또한 신고가 필요하며 필요한 서류를 갖추고 온라인(질병보건통합관리시스템, http://is.kdca.go.kr)으로 제출합니다.인증 규정 위반‘임의적 인증 취소 사유’에 따라 유전자검사기관 인증이 취소될 수 있습니다. 유전자검사기관의 검사역량에 시설, 인력, 장비 등 중요한 변동사항이 발생하여 검사역량 인증기준에 맞지 아니하게 된 경우 인증받은 항목 외에 소비자 대상 직접 시행 유전자검사를 수행한 경우 검사대상자의 개인정보를 유출하거나 검사의 효용성을 왜곡하는 등 검사대상자를 현저하게 오도하는 방식으로 소비자 대상 직접 시행 유전자검사를 수행한 경우 그 밖에 보건복지부령으로 정하는 기준을 위반하여 소비자 대상 직접 시행 유전자검사를 수행한 경우Take Home Message2021년 12월 30일을 기준으로 개정 시행된 생명윤리법에 따라 유전자검사 제도에 변화가 생겼습니다. 유전자검사 목적에 따른 신고, 유전자검사기관 종사자 교육 의무화, 숙련도 평가 도입, DTC 유전자검사기관의 검사역량 인증 도입이 해당 변화 내용입니다. 유전자검사기관의 변경신고, 휴/폐업 신고는 사항이 발생한 날부터 30일 이내 신고해야 합니다." }, { "title": "ML and DL for Cancer Genomics I - Bioinformatics Trend", "url": "/posts/ML_and_DL_for_Cancer_Genomics_I/", "categories": "Bioinformatics, ML", "tags": "BI, bioinformatics, cancer, ML, DL", "date": "2023-06-09 07:22:36 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 경희대학교 이과대학 김권일 교수님의 생물정보학 동향을 정리한 내용입니다.IntroMachine learning 관련 기초 개념을 확인하고, 공개된 논문내용 및 데이터를 바탕으로 직접 실습하고 학습하는 과정입니다.생물정보학(Bioinformatics)이란?생물정보학(Bioinformatics)은 생물학적인 문제를 이해하기 위한 방법이나 프로그램을 개발하는 학제간 분야를 아우르는 학문입니다.생물정보학 개념https://www.edwith.org/deep-learning-2023/lecture/1475083생물정보학의 주요한 연구대상은 DNA입니다. DNA는 대상의 환경, 경험, 형태에 대한 정보를 담고 있습니다. Central Dogma라고 일컫는 일련의 과정(DNA → RNA → Protein)을 통해 DNA에 담긴 정보가 발현됩니다.DNA 염기서열 분석기술은 HGP(Human Genome Project) 이후 꾸준히 발달해 왔습니다. HGP는 30억 쌍의 인간 유전체를 해독한 대형 프로젝트로, 방대한 데이터를 다루면서 자연스럽게 염기서열 분석기술의 발전을 이끌었습니다. 특히 2007~2008년 경 염기서열 분석 비용이 급진적으로 하락하면서 무어의 법칙을 넘어서기 시작하는데, 바로 NGS(Next Genration Sequencing)가 본격적으로 시작된 시기입니다.HGP와 NGS의 시작https://www.edwith.org/deep-learning-2023/lecture/1475083이러한 immune system을 활용하여 tumor cell을 제거하기 위해서는, normal cell에는 존재하지 않고 tumor cell에만 존재하는 specific antigen을 목표로 삼는 것이 좋습니다. TSA(Tumor Specific Antigen)는 tumor cell에 특이적인 antigen을 의미하며, TAA(Tumor Associated Antigen)는 일부 normal cell에도 존재하지만 대부분 tumor cell에서 나타나는 antigen을 의미합니다.PCR vs. NGSConventional PCR은 염기서열 분석이 필요한 특정 구간을 선별하여 분석하므로 많은 시간과 노력이 필요합니다. 이에 반해 NGS는 화학시료와 광학기술을 활용하여 인간 유전체 전체 부위를 동시다발적으로 분석하는 기술로 비교적 적은 시간과 노력을 들이고 비용의 감소를 불러왔습니다.PCR vs. NGShttps://www.edwith.org/deep-learning-2023/lecture/1475083NGS의 시작과 함께 DNA는 big data 수준으로 축적되어 가고 있습니다. 빅데이터는 3V로 요약할 수 있는데, 데이터의 양(Volume), 데이터 생성 속도(Velocity), 형태의 다양성(Variety)을 의미합니다. 2020년 Nebula Genomics는 한 사람의 WGS data를 $299에 제공하고 있습니다.DNA is Big datahttps://www.edwith.org/deep-learning-2023/lecture/1475083또한 염기서열 분석기술의 발전은 한 명의 한 개 유전자를 분석하는 수준에서 여러 명의 여러 유전자를 분석하는 것으로 발전했습니다. (유전체학, Genomics) 그 뿐만 아니라 Epigenomics, Transcriptomics, Proteomics, Metabolomics 등 Genomics와 연관된 다양한 학문 분야로 발전했습니다.NGS와 -omics 연구의 발전https://www.edwith.org/deep-learning-2023/lecture/1475083AlphaFold를 사용한 Proteomics data 분석2021년 구글 딥마인드가 발표한 Protein 구조 예측 인공지능 AlphaFold2는 인간 Protein 3D 구조 data 갯수를 20,296개(전체의 98.5% 수준)로 늘렸습니다. 이는 지금까지 실험을 통하여 확인된 3,500여개(전체의 17% 수준)에 비해 매우 증가된 수치입니다.AlphaFold2https://www.edwith.org/deep-learning-2023/lecture/1475083Take Home Message생물정보학은 생물학과 관련된 모든 문제들을 이해하기 위한 방법론을 다루고, 학제간 분야를 아우르는 학문입니다. 생물학과 더불어 전산학, 통계학의 통합적 이해를 요구합니다.생물정보를 담고 있는 DNA 염기서열이 주 연구대상 중 하나이고, NGS 발전에 따라 Genomics, Epigenomics, Transcriptomics, Proteomics 등 주요한 생물학 분야의 문제들을 해결하는데 필수불가결한 요소가 되고 있습니다.최근 omics big data가 출현함에 따라 다양한 machine learning 및 deep learning을 수행하여 해결하기 힘든 각종 생물학 난제들을 풀어나가려는 시도가 이루어지고 있습니다." }, { "title": "Genetic Testing Agency Training 1 - 유전자검사의 이해", "url": "/posts/Genetic_Testing_Agency_Training_I/", "categories": "Study, L-Genetic Testing Agency Training", "tags": "bioinformatics, genetics", "date": "2023-06-09 07:22:36 +0900", "snippet": "본 post는 질병관리청 유전자검사기관 종사자 교육(2023)의 ‘1차시 - 유전자검사의 이해’를 정리한 내용입니다.유전자검사의 발전과 성장검사 기술 개발 및 비용 감소가 이루어 졌습니다. 차세대 염기서열 분석법(NGS)의 개발로 대용량의 염기서열을 동시에 분석할 수 있게 되었습니다. 이는 1세대 염기서열 분석법인 Sanger sequencing에 비해 분석시 소요 비용이 감소함에 따라 임상적 활용이 크게 증가하게 되었습니다.HGP(Human Genome Project)가 진행된 2003년 당시 인간 유전체 분석에 소요되는 비용이 대략 1억 달러였던 것에 반해 현재는 1,000 달러 가량으로 약 10만배 감소 되었습니다.유전자검사에 있어서 검사 기술과 함께 중요한 또 다른 요소는 검사 결과가 의미하는 바입니다. 유전자검사로 확인된 유전변이들을 어떻게 해석할 수 있는지가 중요합니다. 이것은 유전자검사로 확인할 수 있는 ‘유전정보’와, 이전에 동일한 유전정보를 가진 사람들에게 나타났었던 ‘임상적인 특징’을 데이터베이스화 해야합니다. 따라서 유전체 관련 공공 데이터베이스의 구축이 필요합니다. 이러한 데이터베이스는 유전자검사를 임상적으로 활용하는 데 많은 도움을 주고, 유전자검사를 적극적으로 활용할 수 있게 합니다. 현재 공개된 공공 데이터베이스로는 OMIM, ClinVar, gnomAD, GWAS Catalog 등이 있습니다.유전체 관련 공공 데이터베이스https://nih.kohi.or.kr/국가 주도의 대규모 유전체 프로젝트가 진행 중이며, NGS 검사법 개발과 더불어 미래 의료를 선도하고자 하는 각국의 국가적인 투자가 진행되고 있습니다.영국은 100,000 Genome Project와 UK BioBank, 미국은 All of Us, 한국은 국가 통합 바이오 빅데이터 구축사업이 대표적인 사례입니다.국가 주도의 대규모 유전체 프로젝트https://nih.kohi.or.kr/유전자검사의 활용유전자검사는 질병의 진단 및 치료에 활용하고 있습니다. 증상 전 진단(presymptomatic diagnosis), 산전진단 및 착상 전 진단(prenatal diagnosis and preimplantation diagnosis), 약물유전검사(pharmacogenetic testing)에 활용하면서 유전자검사 기술 및 치료제 개발의 비약적인 발전이 이루어지고 있습니다.질병의 진단 및 치료 활용https://nih.kohi.or.kr/또한 질병의 진단 및 치료 외에도 다양한 목적으로 활용되고 있습니다. 질병 에측, Wellness, 유전적 혈통 찾기, 친자확인 등에 활용되고 있습니다.국내 유전자검사 현황2023년 3월 31일 기준 국내 유전자검사기관은 265개소 신고되어 있습니다.국내 유전가검사기관 신고 현황https://nih.kohi.or.kr/국내 유전자검사 관련 정책은 우리나라 국민이라면 누구나 국민건강보험의 혜택을 받을 수 있습니다. 의료기관에서 질병의 진단 및 치료에 활용되는 유전자검사는 국민건강보험 급여의 대상이 됩니다. 관계부처별 관리 내역을 살펴보면 보건복지부는 의료법, 국민건강보험법 및 생명윤리법에 따라 유전자검사 전반 관리, 질병관리청은 생명윤리법에 따라 유전자검사기관의 신고 수리 및 관리, 식품믜약품안전처는 체외진단의료기기법에 따라 통과된 검사 장비로 시행되는 유전자검사 관리를 담당하고 있습니다. 국내 유전자검사 관련 정책 담당기관1https://nih.kohi.or.kr/건강보험심사평가원은 유전자검사 관련 요양급여의 적정성과 타당성 평가, 한국보건의료연구원은 새로운 유전자검사에 대한 신의료기술 적용 여부 평가, 한국유전자검사평가원은 유전자검사에 대한 숙련도 평가, 국가생명윤리정책원은 DTC 유전자검사 서비스에 대한 검사역량 인증처리를 담당하고 있습니다.국내 유전자검사 관련 정책 담당기관2https://nih.kohi.or.kr/의료기관은 기관 특성상 유전자검사의 질관리를 실시하고 있습니다. 만약 우수한 질관리가 유지되지 않는다면 검체검사에 대한 질 가산율 등에 제한을 받을 수 있습니다. 진단검사분야는 진단검사의학재단의 우수검사실 신임인증평가에서 우수한 점수를 받아야 합니다. 대한임상검사정도관리협회의 신빙도 조사사업에서 품질인증을 획득해야 합니다. 병리학분야는 대한병리학회의 정도관리/인증평가에서 적합 판정 및 우수한 등급을 획득해야 합니다.이처럼 유전자검사기관은 관련 법에 따른 책임과 의무를 준수해야 합니다. 또한 검사실의 질 수준 향상 및 유지하는 것이 중요합니다.국외(미국) 유전자검사 정책CLIA(Clinical Laboratory Improvement Amendments): 사람의 검체를 대상으로 ‘체외진단검사를 수행하는 검사실’은 인력, 외부정도관리평가, 질관리, 검사관리의 시스템, 시설 운영 등의 부분에 대해 ‘CLIA에서 규정하는 주요한 요건’ 등을 반드시 충족해야만 합니다.미국병리협회(CAP)의 검사실 인증 프로그램: 검사결과의 정확성과 환자 진단의 정확성을 유지하기 위해 외부정도관리 평가 및 검사실 현장평가 등을 받습니다. 미국의 CMS(Centers for Medicare &amp;amp; Medicaiid Services)에서는 미국병리협회에 검사실의 질평가를 할 수 있는 권한을 위임합니다.미국에서도 DTC(Direct to Consumer) 유전자검사 서비스가 시행되고 있는데, 정책적인 변화를 가져온 계기가 있습니다. 2003년 HGP가 완성된 이후 2005년부터 DTC 유전자검사 회사들이 설립되었습니다. 2010년 미국회계감사원이 DTC 유전자검사 회사들의 검사결과를 검토하여 보고서를 발표했는데, 주요 이슈사항은 유전자검사 회사마다 분석결과가 상이하다는 점이었습니다. 2013년 FDA는 건강 관련 DTC 유전자검사 서비스의 영업 중단을 권고했습니다. 2015년부터 저위험도 유전자검사를 제외한 DTC 서비스들에 대해 FDA 검토 및 허가가 필요하도록 정책이 변경되었습니다.미국의 DTC 정책 변화1https://nih.kohi.or.kr/미국의 DTC 정책 변화2https://nih.kohi.or.kr/Take Home MessageNGS 개발로 인하여 유전자검사 비용이 감소했습니다. 유전체 관련 공공 데이터베이스 구축의 중요성이 대두되면서 국가 주도 대규모 유전체 프로젝트가 진행되고 있습니다. 이러한 유전자검사는 질병의 진단, 치료를 위한 활용 뿐만 아니라 질병 예측, 예방, 유전적 혈통 찾기, 개인식별, 친자확인 등 다양한 목적으로 활용되고 있습니다. 국내/외 유전자검사기관 현황과 정책변화 등을 확인했습니다." }, { "title": "(udemy) Genetics and NGS for Bioinformatics", "url": "/posts/Certificate_Genetics_and_NextGS_for_Bioinformatics/", "categories": "Study, L-Certificate", "tags": "certificate, bioinformatics, udemy", "date": "2023-05-25 07:47:24 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 파이썬을 이용한 데이터 분석", "url": "/posts/Certificate_data_analysis_through_python/", "categories": "Study, L-Certificate", "tags": "certificate, data analysis, Woongjin", "date": "2023-05-04 07:52:04 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 데이터 분석과 비즈니스를 위한 기초 통계학_하", "url": "/posts/Certificate_basic_statistics_for_data_business2/", "categories": "Study, L-Certificate", "tags": "certificate, data analysis, Woongjin", "date": "2023-05-04 07:48:48 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 데이터 분석과 비즈니스를 위한 기초 통계학_상", "url": "/posts/Certificate_basic_statistics_for_data_business1/", "categories": "Study, L-Certificate", "tags": "certificate, data analysis, Woongjin", "date": "2023-05-04 07:45:12 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(udemy) Introduction to the MongoDB", "url": "/posts/Certificate_IntroductiontotheMongoDB/", "categories": "Study, L-Certificate", "tags": "certificate, mongoDB, database, udemy", "date": "2023-01-29 20:14:52 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(udemy) The Complete MongoDB Course 2023", "url": "/posts/Certificate_mongoDB2023/", "categories": "Study, L-Certificate", "tags": "certificate, mongoDB, database, udemy", "date": "2023-01-28 17:10:12 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(COURSERA-JHU) Introduction to Genomic Technologies", "url": "/posts/Certificate_introduction_to_genomic_tech/", "categories": "Study, L-Certificate", "tags": "certificate, genomics, JHU", "date": "2022-12-12 07:58:10 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(직무능력 인증서) 빅데이터 분야 빅데이터 가공 및 분석 과정", "url": "/posts/Certificate_bigdata_analysis/", "categories": "Study, L-Certificate", "tags": "certificate, bigdata, analysis, datastreams", "date": "2022-12-07 08:16:58 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(직무능력 인증서) 빅데이터 분야 수학적 사고 과정", "url": "/posts/Certificate_bigdata_math/", "categories": "Study, L-Certificate", "tags": "certificate, bigdata, math, datastreams", "date": "2022-12-07 08:14:02 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(EDWITH-KOBIC) Proteomics", "url": "/posts/Certificate_proteomics_analysis/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, proteomics, KOBIC", "date": "2022-11-30 17:34:12 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) SQL 정형 데이터 분석", "url": "/posts/Certificate_sql_data_analysis/", "categories": "Study, L-Certificate", "tags": "certificate, SQL, CUK", "date": "2022-11-30 11:52:10 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 대용량 데이터 처리", "url": "/posts/Certificate_bigdata_manipulation/", "categories": "Study, L-Certificate", "tags": "certificate, big data, CUK", "date": "2022-11-30 08:12:05 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(udemy) 한눈에 쏙쏙 의학 통계 배우기", "url": "/posts/Certificate_medicalstatistics/", "categories": "Study, L-Certificate", "tags": "certificate, statistics, udemy", "date": "2022-11-27 12:04:26 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(udemy) Python으로 시작하는 Kaggle 포트폴리오 만들기", "url": "/posts/Certificate_pythonkaggle/", "categories": "Study, L-Certificate", "tags": "certificate, python, kaggle, udemy", "date": "2022-11-27 09:41:02 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(Cheat Sheet) - Matplotlib", "url": "/posts/cheatsheet_matplotlib/", "categories": "Programming, Python", "tags": "programming, python, matplotlib, cheatsheet", "date": "2022-11-26 11:52:05 +0900", "snippet": "Cheetsheet - Matplotlib (beginner)https://matplotlib.org/cheatsheets/Cheetsheet - Matplotlib (beginner)Cheetsheet - Matplotlib (intermediate)https://matplotlib.org/cheatsheets/Cheetsheet - Matplotlib (intermediate)Cheetsheet - Matplotlib (tips)https://matplotlib.org/cheatsheets/Cheetsheet - Matplotlib (tips)Cheetsheet - Matplotlibhttps://matplotlib.org/cheatsheets/Cheetsheet - Matplotlibhttps://matplotlib.org/cheatsheets/Cheetsheet - Matplotlib" }, { "title": "(Cheat Sheet) - Seaborn", "url": "/posts/cheatsheet_seaborn/", "categories": "Programming, Python", "tags": "programming, python, seaborn, cheatsheet", "date": "2022-11-26 11:05:10 +0900", "snippet": "Cheetsheet - Seabornhttps://www.datacamp.com/cheat-sheet/python-seaborn-cheat-sheetCheetsheet - Seaborn" }, { "title": "(Cheat Sheet) - Pandas", "url": "/posts/cheatsheet_pandas/", "categories": "Programming, Python", "tags": "programming, python, pandas, cheatsheet", "date": "2022-11-26 10:52:42 +0900", "snippet": "Cheetsheet - Pandashttps://pandas.pydata.org/Cheetsheet - Pandashttps://pandas.pydata.org/Cheetsheet - Pandas" }, { "title": "Transcriptome III - Differential Expression &amp; Visual Exploration", "url": "/posts/Transcriptome3/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, transcriptome", "date": "2022-11-22 12:16:52 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 이화여자대학교 생명과학과 이상혁 교수님의 전사체 데이터 분석를 정리한 내용입니다.IntroRNA-seq data의 differential exporession, visual exploration에 대해 알아봅니다.Differential ExpressionTypical Process of Transcriptome Analysishttps://www.edwith.org/transcriptome/lecture/1382678 전형적인 RNA-Seq analysis 과정은 다음과 같습니다. 지난 시간 data preprocessing 및 normalization, quantification까지 알아봤습니다. 이번 차시에서는 differential expression을 알아봅니다. 다음 차시에 순차적으로 classification, clustering에 대해 알아봅니다.Visual Comparison of Two data sets - Scatter plothttps://www.edwith.org/transcriptome/lecture/1382678 두 개의 data sets를 비교하는데 visualization은 중요합니다. Scatter plot을 그려보면 data integrity, outlieres 등을 파악하는데 도움이 됩니다. Gene expression range는 gene별로 큰 차이가 나기때문에(매우 작은 양부터 매우 큰 양까지) log scale에서 비교하면 보기가 좋습니다.Visual Comparison of Two data sets - MA plothttps://www.edwith.org/transcriptome/lecture/1382678 MA plot으로도 두 개의 data set을 비교해서 볼 수 있습니다. x axis는 average express 값을 의미합니다. 즉, 오른쪽으로 갈수록 많이 expression 된다고 해석할 수 있습니다. y axis는 fold-change 값을 의미합니다. 즉, 위로 올라갈수록 E1이 E2에 비해 많이 expression 된다고 해석할 수 있습니다.Differential Expression Differentially Expressed Genes(DEGs)는 다양한 조건에서 gene expression이 증가 혹은 감소하는 양상을 확인하는 방법입니다. normal vs. tumor treated vs. untreated time series profiles Fold change does not take variation into accounthttps://www.edwith.org/transcriptome/lecture/1382678 그림에서 두 개 genes에 대해 평균은 각각 같지만 expression 분포가 세 가지 유형으로 나뉘는 것을 확인할 수 있습니다. low variability: variable이 작고 두 개 genes 사이 express에 명확한 차이가 있음을 확인할 수 있습니다. high variability: variable이 크고 두 개 genes 사이 express에 거의 차이가 없음을 확인할 수 있습니다. Hypothesis Testing and p-valuehttps://www.edwith.org/transcriptome/lecture/1382678 Normal과 tumor 사이 mean 값의 차이가 있는지 없는지 확인하기 위해 hypothesis testing을 진행합니다. 두 mead 값의 차이가 없다는 null hypothesis를 세우고 p-value(오른쪽 그래프의 녹색 면적)를 계산합니다. p-value가 기준(normally 0.05)보다 낮을 때 우연한 결과가 아니라고 추정할 수 있고 null hypothesis를 기각하여 두 mean 값에 차이가 있다고 결론내릴 수 있습니다.t-testhttps://www.edwith.org/transcriptome/lecture/1382678 t-test는 두 개 그룹의 mean 값에 차이가 없다는 hypothesis를 test하는 방식입니다. $\\frac{signal}{noise}$ 두 개 그룹 mean 값의 차이(signal)를 두 개 그룹 분포의 크기의 차이(noise, standard error)로 나눠준 값으로 계산합니다. 그룹이 세 개 이상일 때 t-test는 ANOVA로 변경됩니다.Volcano plothttps://www.edwith.org/transcriptome/lecture/1382678 p-value와 fold-change를 동시에 표현한 plot입니다. x축의 fold-change는 -1 미만과 1 이상이 두 배 이상 차이나는 gene으로 볼 수 있습니다. y축의 p-value는 2 이상일 때 $10^{-2} = 0.01$이하, 곧 유의미하게 차이나는 gene으로 볼 수 있습니다. Multiple comparison test problem 생물학에서 비교반복실험은 흔히 있습니다. p-value 0.05 이하라는 의미는, 두 개 그룹간 차이가 존재할 확률이 95%라는 의미인 동시에 우연히 차이나는 것처럼 보일 확률이 5%라는 의미입니다. 예를 들어 10,000개의 gene 대상으로 p-value 5% 기준으로 잡으면 500개 gene이 우연하게 선정될 수 있습니다. (잘못된 결과) 10,000번의 t-test p-value 5% 기준으로 1,000개의 gene이 선택됐을 때, 결국 500/1,000 선택된 gene의 50%가 잘못된 결과로 볼 수 있습니다. (very high false discovery rate) 여러 번 비교반복실험을 진행할 때 단일 테스트의 p-value 5% 기준을 그대로 사용하면 이러한 문제가 발생할 수 있으므로, 따라서 multiple comparison을 위한 p-value의 보정이 필요합니다. Boneferroni correction p-value를 p-value/test counts로 보정합니다. 예를 들어, 1,000번의 test를 진행하면 p-value 0.05는 0.05/1,000 = 0.00005로 기준으 삼는 것입니다. 그러나 이 방법은 too conservative하여 많이 사용하지는 않습니다. False discovery rate(FDR) $\\frac{#false positives}{#called significant}$ Benjamini-Hochberg procedure 반복실험의 p-value들을 오름차순으로 정렬합니다. Bonferroni correction의 corrected p-value(p-value/test counts)를 2배, 3개, 4배, … , k배로 늘려가면서 기준을 만족하는 k값을 찾습니다. FDR approach를 통해 찾은 adjusted p-value를 q-value라고 합니다. 즉, q-value 5%는 significant tests 중 false positive로 확인된 비율이 5%임을 의미합니다. Statistical testing for differential expression 생물학 실험할 때 반드시 세 번 이상 반복실험 하는 것이 좋습니다. Normalization은 샘플간 expression 비교할 때 필수입니다. 분포 모델은 negative binomial distribution 사용하는 것이 바람직 합니다. multiple testion problems를 해결하기 위한 correction 과정은 필수입니다. Sample Validation 다양한 이유로 sample이 서로 뒤바뀌는 경우가 발생할 수 있습니다. 이를 확인할 수 있는 다양한 방법이 있습니다. Paired sample shcek SNP concordance에 기반한 paired sample check 방법입니다. tool: NGSCheckMate, BAMixChecker Gender check X/Y chromosome 상에서 read depth나 allele frequency에 기반한 gender check 방법입니다. tool: SEXCMD Ethnicity inference 인종별로 나타나는 allele에 기반하여 ethnicity를 추정하는 방법으로 WGS or WES data를 대상으로 사용 가능합니다. tool: SeqSQC, EthSEQ, LASER 2.0 MappingRNA-Seq Mappinghttps://www.edwith.org/transcriptome/lecture/1382678 다양한 mapping 방법이 있습니다. 최근에는 genome에 mapping하는 방법이 주로 사용됩니다.Strategies for gapped alignmentshttps://www.edwith.org/transcriptome/lecture/1382678 RNA-Seq data를 genome에 mapping하는 방식은 크게 두 가지로 나눠 생각할 수 있습니다. Exon-first approach 이미 알려진 exon sequence에 read를 mapping하는 방식입니다. tool: MapSplice, SpliceMap, TopHat 하지만 gene과 pseudogene을 구분하지 못하고 모두 mapping 한다는 단점이 있습니다. Seed-extend methods N-mer의 seed reads가 어디에 matching 되는지 확인 후 확장시켜 나가는 방식입니다. tool: GSNAP, QPALMA Tophat: Spliced Read Mapperhttps://www.edwith.org/transcriptome/lecture/1382678 Tophat - spliced read mapper Exon 내 mapping되는 reads를 먼저 선별합니다. 두 개의 exon에 걸쳐있는 reads는 각각 exon 영역에 맞는 영역으로 나눕니다. 이 때 canonical intron이 지니고 있는 특징적인 서열(intron의 시작과 끝 서열: GT-AG, GC-AG, AT-AC)을 활용합니다. STAR: spliced transcripts alignment to a referencehttps://www.edwith.org/transcriptome/lecture/1382678 STAR - spliced transcripts alignment to a reference step1. seed searching Suffiix array 알고리즘을 사용하여 MMP(Maximal Mappable Prefix)를 찾습니다. N-mer의 seed reads가 mapping되면 extend하면서 read를 연장합니다. setp2. clustering/stiching/scoring step clustering: seed reads를 모아 cluster를 만듭니다. stitching: frugal dynamic programming altorithm을 사용하여 각 pair of seeds를 연결합니다. 이 때 두 개 이상의 window를 사용하는데 scoring하여 가장 적합한 position을 찾습니다. TopHat vs STAR TCGA RNA-Seq AML data를 사용하여 비교한 결과입니다. 동일한 data의 mapping에 TopHat2는 480분, STAR는 27분 소요됐습니다. STAR가 월등히 빠른 것을 알 수 있습니다. 하지만 정확도는 TopHat2가 약간 더 앞선 결과를 보였습니다. STAR를 사용하는 것이 더 효율적인 방법임을 생각해 볼 수 있습니다. SAM/BAMhttps://www.edwith.org/transcriptome/lecture/1382678 Alignment Data Format (SAM/BAM) mapping 결과로 나오는 output 파일입니다. 6th column의 CIGAR string은 mapping 결과를 요약해서 보여주는데, RNA-Seq data에서 N은 intron 영역을 의미합니다. 예) 5M14N8M: exon 5bp + intron 14bp + exon 8bp Normalization Normalization이 필요한 이유는, raw data가 mRNA의 concentration이 아닐 수 있기 때문입니다. 다양한 이유가 존재합니다. Sample preparation과 관련된 이슈가 있습니다. tissue contamination RNA degradation amplification efficiency reverse transcription efficiency microarrays와 관련된 이슈가 잇습니다. hybridization efficiency and specificity image segmentation signal quantificaion ‘background’ correction RNA-Seq과 관련된 이슈가 있습니다. uneven depth of coverage uncertainties in mapping and quantification Normalizationhttps://www.edwith.org/transcriptome/lecture/1382678 Normalization은 데이터의 분포와 scale을 조정하여 데이터간 비교 가능하도록 만드는 과정입니다.Normalization for microarray datahttps://www.edwith.org/transcriptome/lecture/1382678 Microarray data의 normalization은 여러 가지 방법이 존재합니다. 오른쪽 아래 그림을 보면 실제 duplicate였던 색상별 reads가 normalization 이후 동일한 수준으로 변경되었음을 확인할 수 있습니다.Normalization for RNA-Seq datahttps://www.edwith.org/transcriptome/lecture/1382678 RNA-Seq data를 normalization 할 때 두 가지 사항을 고려해야 합니다. 1-2: Sequencing depth가 높을수록(2) mapped reads도 증가합니다. 3-4: transcript length가 길수록(4) mapped reads도 증가합니다. 따라서 sequencing depth, transcript length에 대해 normalization이 필요합니다. RPKM Reads Per Kilobase of transcript per Million mapped reads reads 백만개 당 kilobase transcript에 mapping된 reads 수를 의미합니다. normalization order: depth first -&amp;gt; then length FPKM Fragments Per Kilobase … Paired-end sequencing을 했을 때 하나의 fragment에 대해 forward, reverse 두 번을 sequencing 하는데, 이를 한 개로 간주하고 계산한 결과입니다. TPM Transcripts Per Million normalization order: length first -&amp;gt; then depth TPM values can be compared between different samples directly because the sum of all TPMs in each sample art the same 지금은 TPM이 정석처럼 사용되고 있습니다. QuanltificationRead Counting Ruleshttps://www.edwith.org/transcriptome/lecture/1382678 gene 하나의 uniquely mapping되는 read가 있지만 복수 개의 genes에 걸쳐서 mapping되는 경우도 있습니다. 다음과 같은 방법으로 이러한 문제를 처리합니다. Estimating using unique reads (old) Uniquely mapped reads만 사용하는 방식입니다. 상대적으로 많은 reads를 버려야하는 단점이 잇습니다. tool: NEUMA Maximum Likelihood Estimation (MLE) low level expression은 정확하게 측정되지 않는 단점이 있습니다. tool: EMSAR, MISO, Cufflinks Expectation-Maximization 현재 가장 많이 사용하는 방식입니다. tool: RSEM, eXpress RNA-Seq Analysis PipelineSTAR-RSEM Anlysis Pipelinehttps://www.edwith.org/transcriptome/lecture/1382678 Sickle / STAR / RSEM 을 사용한 RNA-Seq analysis pipeline 입니다. Trimming: Sickle Mapping STAR v2.6.0c Quantification: RSEM v1.3.0 Differential expression analysis: R v3.6.0 (package: edgeR, preprocessCore, gplots, RColorbrewer) Fusion analysis: STARfusion v1.6.0 STAR-RSEM Anlysis Pipeline: trimminghttps://www.edwith.org/transcriptome/lecture/1382678STAR-RSEM Anlysis Pipeline: preparing referencehttps://www.edwith.org/transcriptome/lecture/1382678STAR-RSEM Anlysis Pipeline: mapping &amp;amp; quantificationhttps://www.edwith.org/transcriptome/lecture/1382678STAR-RSEM Anlysis Pipeline: mapping &amp;amp; quantificationhttps://www.edwith.org/transcriptome/lecture/1382678STAR-RSEM Anlysis Pipeline: mapping &amp;amp; quantificationhttps://www.edwith.org/transcriptome/lecture/1382678Take Home MessageRNA-Seq data preprocessing 과정에 대해 배울 수 있었습니다. STAR-RSEM pipeline이 가장 많이 사용되고 있음을 알 수 있었습니다." }, { "title": "Transcriptome II - Data Preprocessing", "url": "/posts/Transcriptome2/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, transcriptome", "date": "2022-11-22 07:47:12 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 이화여자대학교 생명과학과 이상혁 교수님의 전사체 데이터 분석를 정리한 내용입니다.IntroRNA-seq data의 mapping, normalization, quantification에 대해 알아봅니다.Quality Control Sequencing data를 얻으면 base quality(Q score)를 확인합니다. 사용 가능한 프로그램으로 FastQC, MultiQC, PRINSEQ, RSeQC 등이 있습니다.Trimming Mapping 전 contaminated or low-quality reads를 제거하는 과정입니다. 사용 가능한 프로그램으로 Sickle, FASTX-Toolkit, Cutadapt, Trimmomatic 등이 있습니다.Reads Trimminghttps://www.edwith.org/transcriptome/lecture/1382678Sample Validation 다양한 이유로 sample이 서로 뒤바뀌는 경우가 발생할 수 있습니다. 이를 확인할 수 있는 다양한 방법이 있습니다. Paired sample shcek SNP concordance에 기반한 paired sample check 방법입니다. tool: NGSCheckMate, BAMixChecker Gender check X/Y chromosome 상에서 read depth나 allele frequency에 기반한 gender check 방법입니다. tool: SEXCMD Ethnicity inference 인종별로 나타나는 allele에 기반하여 ethnicity를 추정하는 방법으로 WGS or WES data를 대상으로 사용 가능합니다. tool: SeqSQC, EthSEQ, LASER 2.0 MappingRNA-Seq Mappinghttps://www.edwith.org/transcriptome/lecture/1382678 다양한 mapping 방법이 있습니다. 최근에는 genome에 mapping하는 방법이 주로 사용됩니다.Strategies for gapped alignmentshttps://www.edwith.org/transcriptome/lecture/1382678 RNA-Seq data를 genome에 mapping하는 방식은 크게 두 가지로 나눠 생각할 수 있습니다. Exon-first approach 이미 알려진 exon sequence에 read를 mapping하는 방식입니다. tool: MapSplice, SpliceMap, TopHat 하지만 gene과 pseudogene을 구분하지 못하고 모두 mapping 한다는 단점이 있습니다. Seed-extend methods N-mer의 seed reads가 어디에 matching 되는지 확인 후 확장시켜 나가는 방식입니다. tool: GSNAP, QPALMA Tophat: Spliced Read Mapperhttps://www.edwith.org/transcriptome/lecture/1382678 Tophat - spliced read mapper Exon 내 mapping되는 reads를 먼저 선별합니다. 두 개의 exon에 걸쳐있는 reads는 각각 exon 영역에 맞는 영역으로 나눕니다. 이 때 canonical intron이 지니고 있는 특징적인 서열(intron의 시작과 끝 서열: GT-AG, GC-AG, AT-AC)을 활용합니다. STAR: spliced transcripts alignment to a referencehttps://www.edwith.org/transcriptome/lecture/1382678 STAR - spliced transcripts alignment to a reference step1. seed searching Suffiix array 알고리즘을 사용하여 MMP(Maximal Mappable Prefix)를 찾습니다. N-mer의 seed reads가 mapping되면 extend하면서 read를 연장합니다. setp2. clustering/stiching/scoring step clustering: seed reads를 모아 cluster를 만듭니다. stitching: frugal dynamic programming altorithm을 사용하여 각 pair of seeds를 연결합니다. 이 때 두 개 이상의 window를 사용하는데 scoring하여 가장 적합한 position을 찾습니다. TopHat vs STAR TCGA RNA-Seq AML data를 사용하여 비교한 결과입니다. 동일한 data의 mapping에 TopHat2는 480분, STAR는 27분 소요됐습니다. STAR가 월등히 빠른 것을 알 수 있습니다. 하지만 정확도는 TopHat2가 약간 더 앞선 결과를 보였습니다. STAR를 사용하는 것이 더 효율적인 방법임을 생각해 볼 수 있습니다. SAM/BAMhttps://www.edwith.org/transcriptome/lecture/1382678 Alignment Data Format (SAM/BAM) mapping 결과로 나오는 output 파일입니다. 6th column의 CIGAR string은 mapping 결과를 요약해서 보여주는데, RNA-Seq data에서 N은 intron 영역을 의미합니다. 예) 5M14N8M: exon 5bp + intron 14bp + exon 8bp Normalization Normalization이 필요한 이유는, raw data가 mRNA의 concentration이 아닐 수 있기 때문입니다. 다양한 이유가 존재합니다. Sample preparation과 관련된 이슈가 있습니다. tissue contamination RNA degradation amplification efficiency reverse transcription efficiency microarrays와 관련된 이슈가 잇습니다. hybridization efficiency and specificity image segmentation signal quantificaion ‘background’ correction RNA-Seq과 관련된 이슈가 있습니다. uneven depth of coverage uncertainties in mapping and quantification Normalizationhttps://www.edwith.org/transcriptome/lecture/1382678 Normalization은 데이터의 분포와 scale을 조정하여 데이터간 비교 가능하도록 만드는 과정입니다.Normalization for microarray datahttps://www.edwith.org/transcriptome/lecture/1382678 Microarray data의 normalization은 여러 가지 방법이 존재합니다. 오른쪽 아래 그림을 보면 실제 duplicate였던 색상별 reads가 normalization 이후 동일한 수준으로 변경되었음을 확인할 수 있습니다.Normalization for RNA-Seq datahttps://www.edwith.org/transcriptome/lecture/1382678 RNA-Seq data를 normalization 할 때 두 가지 사항을 고려해야 합니다. 1-2: Sequencing depth가 높을수록(2) mapped reads도 증가합니다. 3-4: transcript length가 길수록(4) mapped reads도 증가합니다. 따라서 sequencing depth, transcript length에 대해 normalization이 필요합니다. RPKM Reads Per Kilobase of transcript per Million mapped reads reads 백만개 당 kilobase transcript에 mapping된 reads 수를 의미합니다. normalization order: depth first -&amp;gt; then length FPKM Fragments Per Kilobase … Paired-end sequencing을 했을 때 하나의 fragment에 대해 forward, reverse 두 번을 sequencing 하는데, 이를 한 개로 간주하고 계산한 결과입니다. TPM Transcripts Per Million normalization order: length first -&amp;gt; then depth TPM values can be compared between different samples directly because the sum of all TPMs in each sample art the same 지금은 TPM이 정석처럼 사용되고 있습니다. QuanltificationRead Counting Ruleshttps://www.edwith.org/transcriptome/lecture/1382678 gene 하나의 uniquely mapping되는 read가 있지만 복수 개의 genes에 걸쳐서 mapping되는 경우도 있습니다. 다음과 같은 방법으로 이러한 문제를 처리합니다. Estimating using unique reads (old) Uniquely mapped reads만 사용하는 방식입니다. 상대적으로 많은 reads를 버려야하는 단점이 잇습니다. tool: NEUMA Maximum Likelihood Estimation (MLE) low level expression은 정확하게 측정되지 않는 단점이 있습니다. tool: EMSAR, MISO, Cufflinks Expectation-Maximization 현재 가장 많이 사용하는 방식입니다. tool: RSEM, eXpress RNA-Seq Analysis PipelineSTAR-RSEM Anlysis Pipelinehttps://www.edwith.org/transcriptome/lecture/1382678 Sickle / STAR / RSEM 을 사용한 RNA-Seq analysis pipeline 입니다. Trimming: Sickle Mapping STAR v2.6.0c Quantification: RSEM v1.3.0 Differential expression analysis: R v3.6.0 (package: edgeR, preprocessCore, gplots, RColorbrewer) Fusion analysis: STARfusion v1.6.0 STAR-RSEM Anlysis Pipeline: trimminghttps://www.edwith.org/transcriptome/lecture/1382678STAR-RSEM Anlysis Pipeline: preparing referencehttps://www.edwith.org/transcriptome/lecture/1382678STAR-RSEM Anlysis Pipeline: mapping &amp;amp; quantificationhttps://www.edwith.org/transcriptome/lecture/1382678STAR-RSEM Anlysis Pipeline: mapping &amp;amp; quantificationhttps://www.edwith.org/transcriptome/lecture/1382678STAR-RSEM Anlysis Pipeline: mapping &amp;amp; quantificationhttps://www.edwith.org/transcriptome/lecture/1382678Take Home MessageRNA-Seq data preprocessing 과정에 대해 배울 수 있었습니다. STAR-RSEM pipeline이 가장 많이 사용되고 있음을 알 수 있었습니다." }, { "title": "(K-MOOC) 정보의학개론", "url": "/posts/Certificate_MEDICALINFORMATICS/", "categories": "Study, L-Certificate", "tags": "certificate, medical informatics, KOHI", "date": "2022-11-21 08:05:50 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(EDWITH-KOBIC) ChIP-seq", "url": "/posts/Certificate_ChIP-seq1/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, ChIP-seq, KOBIC", "date": "2022-11-18 08:12:55 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "Sub-query and JOIN, UNION", "url": "/posts/database-sql_tmp4/", "categories": "Programming, Database", "tags": "programming, database, SQL, query", "date": "2022-11-13 21:08:12 +0900", "snippet": "본 post는 K-MOOC 고려사이버대학교(매치업) 이건길 교수님의 SQL 정형 데이터 분석 강의를 정리한 내용입니다.Intro관계대수를 이해하고 설명할 수 있습니다. Sub-query문을 이해하고 활용할 수 있습니다.관계대수 관계대수 정의 릴레이션 = tuple의 집합 관계대수 = 릴레이션을 처리하기 위한 연산(operation)의 집합 특징: 피연산자와 연산 결과가 모두 릴레이션 절차적 언어(Procedural Language)로써 관계대수 연산자의 절차적인 적용을 통해서 원하는 결과(릴레이션)을 얻습니다. 관계대수 역할 릴레이션 조작에 대한 이론적 기초를 제공합니다. 데이터베이스 질의(query)를 구현하고 최적화하는 데 사용됩니다. RDBMS의 표준 언어인 SQL이 관계대수의 일부 연산을 사용합니다.관계대수 역할http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 관계대수 종류 일반 집합 연산(Set Operation) 릴레이션 = tuple의 집합이므로 집합 연산을 그대로 적용할 수 있습니다. 합병 가능(Union Compatible)한 릴레이션에 적용 가능합니다. 종류: 합집합(Union), 교집합(Intersection), 차집합(Difference), 곱집합(Cartesian Produce) 순수 관계 연산 릴레이션의 조작을 위해서 정의된 연산입니다. 종류: 셀렉트(Select), 프로젝트(Project), 조인(Join), 디비전(Division) Sub-query 연산자 연산자의 역할 SELECT문의 WHERE절은 조회하려는 데이터에 특정 조건을 부여할 목적으로 사용합니다. 비교 연산자, SQL 연산자, 논리 연산자를 사용하여 조건식을 구성합니다. SELECT [DISTINCT] &amp;lt;컬럼리스트&amp;gt;FROM &amp;lt;테이블 리스트&amp;gt;[WHERE &amp;lt;조건&amp;gt;][GROPU BY &amp;lt;컬럼명&amp;gt;[HAVING &amp;lt;그룹 조건&amp;gt;]][ORDERED BY &amp;lt;컬럼명&amp;gt;[ASC | DESC]] 연산자의 종류연산자의 종류http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 연습문제 질의문) 연봉이 4000 이하인 사원들의 이름과 연봉, 부서번호를 검색하세요.(단순 비교 연산자) SQL) SELECT ename, salary, dno FROM employee WHERE salary &amp;lt;= 4000; 연봉이 4000 이상 5000 이하인 사원들의 이름과 연봉, 부서번호를 검색하세요.(BETWEEN a AND b) SQL) SELECT ename, salary, dno FROM employee WHERE salary &amp;gt;= 4000 AND salary &amp;lt;= 5000; SQL) SELECT ename, salary, dno FROM employee WHERE salary BETWEEN 4000 AND 5000; Take Home MessageSQL 기본 명령어(삽입, 삭제/수정, 검색)를 알 수 있었습니다." }, { "title": "SQL 기초", "url": "/posts/database-sql_3/", "categories": "Programming, Database", "tags": "programming, database, basicSQL", "date": "2022-11-13 18:05:01 +0900", "snippet": "본 post는 K-MOOC 고려사이버대학교(매치업) 이건길 교수님의 SQL 정형 데이터 분석 강의를 정리한 내용입니다.Intro데이터 삽입문을 이해하고 활용할 수 있습니다. 데이터 삭제/수정문을 이해하고 활용할 수 있습니다. 데이터 검색문을 이해하고 활용할 수 있습니다.데이터 삽입 데이터 삽입 명령어 INSERT INTO 명령어 INSERT INTO명령어를 사용하여 데이터를 삽입합니다. 데이터의 삽입은 행(row, tuple) 단위로 이루어집니다. DEFAULT 제약조건이 있는 경우, 삽입되는 값이 없을 때 DEFAULT 값이 들어갑니다. INSERT INTO 예시http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 데이터 삽입 확인 SELECT 명령어를 사용해서 테이블에 입력된 데이터를 확인합니다. SELECT * FROM [테이블명] 데이터 삭제/수정 데이터 삭제 명령어 DELETE 명령어 DELETE 명령어를 사용하여 데이터를 삭제합니다. 데이터의 삭제는 행(row, tuple) 단위로 이루어집니다. 삭제 조건을 주어서 원하는 행만 삭제할 수 있습니다. DELETE FROM 예시http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 연습문제 질의문) student 테이블에서 성별이 남자인 행을 삭제하세요. SQL) DELETE FROM student WHERE st_sex = ‘M’; enrol 테이블에서 중간시험 점수가 90점 이상인 행을 삭제하세요. SQL) DELETE FROM enrol WHERE mid&amp;gt;=90; 데이터 수정 명령어 UPDATE 명령어 UPDATE 명령어를 사용하여 데이터를 수정합니다. 데이터의 수정은 컬럼(column, attribute) 단위로 이루어집니다. 조건에 맞는 행(row)들의 지정한 컬럼을 주어진 값으로 바꿉니다.UPDATE 예시http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 연습문제 질의문) 최현주 학생의 주소를 ‘부산’으로 변경하세요. SQL) UPDATE student SET st_addr = ‘부산’ WHERE st_name = ‘최현주’; 질의문) 모든 학생의 중간고사 점수를 1점 올리세요. SQL) UPDATE enrol SET mid = mid + 1; 데이터 검색 데이터 검색 명령어 SELECT 명령어 관계형 데이터베이스는 데이터를 가져오기 위해 SELECT 명령어를 사용합니다. 데이터의 검색은 행(row, tuple, record) 단위로 이루어집니다. 원하는 행 또는 원하는 열의 데이터만 가져올 수 있습니다. SELECT 예시http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 연습문제 질의문) 학생에 대한 모든 정보를 검색하세요. (테이블의 모든 컬럼에 대한 데이터를 보여주고 싶을 경우) SQL) SELECT * FROM student; 질의문) 학생의 학번, 이름을 검색하세요. (테이블의 컬럼 일부를 검색하는 경우) SQL) SELECT st_id ‘학번’, st_name ‘이름’ FROM student; 질의문) 학생이 소속된 학과만을 출력하세요. (검색 결과에 중복된 로우(레코드)를 제거할 경우) SQL) SELECT dept_id FROM student; 질의문) 학생 정보를 이름의 오름차순으로 검색하세요. (검색 결과를 정렬해서 보여주기 1) SQL) SELECT * FROM student ORDER BY st_name ASC; SQL) SELECT * FROM student ORDER BY st_name DESC; 질의문) 등록 테이블의 정보를 성적순(오름차순)으로 정렬하세요. (검색 결과를 정렬해서 보여주기 2) SQL) SELECT * FROM enrol ORDER BY grade ASC; 질의문) 등록 테이블에서 시험 점수 합계를 포함해서 보여주세요. (계산해서 보여주기) SQL) SELECT *, mid+final FROM enrol WHERE co_num = ‘IT111’; SQL) SELECT *, mid+final ‘총정’ FROM enrol WHERE co_num = ‘IT111’; 조건검색 WHERE절 SELECT &amp;lt;컬럼리스트&amp;gt; FROM &amp;lt;테이블리스트&amp;gt; WHERE &amp;lt;행검색조건&amp;gt; 원하는 조건을 만족하는 행만을 검색하고자 하는 경우 WHERE절에 조건을 명시합니다. WHERE절에는 조건식이 들어갑니다. 조건식은 비교연산자와 논리연산자를 사용하여 구성합니다. 연습문제 질의문) 경영학과(BZ)에 재학중인 학생의 이름과 연락처를 검색하세요. SQL) SELECT st_name ‘이름’, st_phn_mlb ‘연락처’ FROM student WHERE dept_id = ‘BZ’; 조건식의 연결 1 &amp;lt;조건식&amp;gt; 논리연산자 &amp;lt;조건식&amp;gt; 논리연산자를 이용해서 두 개 이상의 컬럼에 대해 조건을 적용합니다. NOT: 논리적 부정 AND: 논리곱. 연산 대상이 모두 참 OR: 논리합. 연산 대상 중 하나라도 참이면 참 연습문제 질의문) 소프트웨어공학 과목에서 중간고사 성적이 90점 이상인 학생을 검색하세요. SQL) SELECT * FROM enrol WHERE co_num = ‘IT111’ AND mid&amp;gt;=90; 집계함수 집계함수 개요 통계나 집계 목적으로 사용되는 함수입니다. 자주 사용하는 집계함수 SUM(): 합계 AVG(): 평균 MIN(), MAX(): 최소값, 최대값 COUNT(): 행의 개수 연습문제 질의문) 중간고사, 기말고사 점수의 평균을 구하세요. SQL) SELECT avg(mid) ‘중간평균’, avg(final) ‘기말평균’ FROM enrol; 그룹별 집계 GROUP BY절 검색 결과를 일정한 기준에 의해 그룹으로 묶어주는 역할을 합니다. 집계함수와 함께 사용되는 경우가 많습니다. 여러 그룹별 집계 자료를 만드는 경우 유용하게 사용됩니다. 연습문제 질의문) 과목별 기말시험 점수의 합계를 구하세요. SQL) SELECT sum(final) ‘과목별 총점’ FROM enrol GROUP BY co_num; HAVING절 그룹별 집계 자료에서 조건에 맞는 결과만 보여줍니다. 연습문제 질의문) 과목별 기말시험 점수의 합계를 구하세요. 단, 합계가 200 이상인 과목만 보여줍니다. SQL) SELECT co_num ‘과목번호’, sum(final) ‘총점’ FROM enrol GROUP BY co_num HAVING sum(final)&amp;gt;=200; Take Home MessageSQL 기본 명령어(삽입, 삭제/수정, 검색)를 알 수 있었습니다." }, { "title": "Transcriptome I - Introduction to Transcriptome", "url": "/posts/Transcriptome1/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, transcriptome", "date": "2022-11-10 07:58:52 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 이화여자대학교 생명과학과 이상혁 교수님의 전사체 데이터 분석를 정리한 내용입니다.IntroRNA-seq과 microarray에 대한 전반적인 내용을 알아봅니다.전사체 연구란? Omics: 어떤 대상을 모두 모아서 연구하는 학문 Transcriptome 연구: 다양한 상황에서 RNA 전체를 대상으로 하는 연구 유전자 활동: 유전자 발현의 결과물(RNA, Protein 등)로 판단유전자 발현 where? tissue or organ profile. 장소에 따라 어떤 gene이 발현되느냐가 달라집니다. Under certain circumstances? temporal progress. 동일한 organ 내에서라도 시간에 따라 normal cell이 cancer cell로 변하면서 발현되는 gene의 종류와 양도 달라집니다. Gene expression and Gene regulation a “proxy” measure for transcription/translation events! RNA/protein의 발현 정도로 발현/조절을 파악할 수 있습니다. Omics 연구의 장점 survey of all components efficient for “biomarker discovery” unbiased view! “system biology” Transcriptome 연구를 통해 해결할 수 있는 문제들 compare two (or more) conditions to identify differentially expressed genes control vs. treatment disease vs. normal exploratory analysis what genes are expressed in response to drought stress? what gene expression changes occur during normal retinal development? diagnostic &amp;amp; prognostic tool development can we predict certain conditions (breast cancer vs. normal) 암 진단법을 만들 수 있습니다. can we identify patterns of gene expression that predict a patient’s response to treatment/drug? 치료 예후예측 사람의 몸에 침입한 antigen은 antigen-presenting cell에 의하여 우리 몸이 침입을 감지하고 대응할 수 있도록 알리는 역할을 합니다. Cytotoxic T-cell이 직접 antigen을 공격하는 동시에 helper T-cell이 B-cell로 하여금 antibody를 생성, 배출하도록 리드합니다. 또한 memory T-cell로 하여금 적응면역을 갖도록 합니다.Applications of Gene Expression clustering gene function inference regulatory network molecular pathology classification diagnosis and prognosis Transcriptome 연구 범위 exporession profiling mRNA, miRNA, IncRNA, … alternative splicing differentially expressed genes (DEGs) gene set and pathway analysis precision medicine fusion gene analysis patient stratification cell type and composition inference Transcriptome 연구 방법 microarray: universal biochemistry platformsmicroarrayhttps://www.edwith.org/transcriptome/lecture/1382678 micro(작은) + array(행렬): 2d 배열의 작은 hole에 물질을 넣고 분석할 수 있는 방식 motivations: hundreds, thousands or even millions of individual experiments are conducted in parallel, with very few reagents. 즉, 동시에 20,000개~30,000개의 gene의 발현을 한 번에 알 수 있다는 점에서 효율적입니다. many different types DNA mRNA in cDNA proteins (antbodies) chemical compounds tissues carbohydrates principles extension of southern and northern blotting microarray는 gene에 specific한 sequence로 구성된 fixed probes가 hole마다 고정되어 있습니다. (hybridization-bases) normal vs. tumor의 mRNA를 각각 green, red dye를 붙인 뒤 1:1 비율로 microarray에 loading하면 normal vs. tumor에서 더 많이 발현되는 색상이 우세하게 나타납니다. microarray principleshttps://www.edwith.org/transcriptome/lecture/1382678 Affymetrix expression arrays Affymetrix사에서 만든 expression arrays로, 25-mers 길이의 oligo로 구성되었습니다. Human Transcriptome Array 2.0은 285,000개 이상의 RNA 서열을 대상으로 발현양을 확인할 수 있습니다. Affymetrix Expression Arrayshttps://www.edwith.org/transcriptome/lecture/1382678 RNA-Seq (Transcriptome Sequencing) the high throughput sequencing of cDNA using NGS technology the goal is to identify regions in the genome that are being transcribed in a sample strategies for reconstructing transcripts from RNA-Seq align-then-assemble: human reference genome에 align 한 뒤 gene별로 얼마나 붙는지 확인합니다. Quantification assemble-then-align: sequencing reads끼리 assembly 한 뒤 reference genome에 align 합니다. Novel RNAs를 확인할 수 있습니다. RNA-Seqhttps://www.edwith.org/transcriptome/lecture/1382678 common analysis of RNA-Seq gene expression analysis differential expression analysis transcript discovery and annotation novel transcripts/genes noncoding RNAs: miRNAs, IncRNAs, … gene fusion detection (structural variants) alternative splicing event RNA-specific phenomena allele-specific expression: 부/모 어느 쪽에서 온 allele이 발현되는지 확인합니다. RNA editing Mutation discovery &amp;amp; prioritization advantages of RNA-Seq over microarray one sample reparation, various analysis RNA-Seq has higher resolution single-base pair resolution dynamic range of gene expression variatin of RNA-Seq single cell sequencing miRNA sequencing Long read sequencing challenges of RNA-Seq RNA is fragile compared to DNA (easily degraded) 샘플 변성이 매우 잘 일어납니다. Sample!!! purifu? quantity? quality? RNAs consist of small exons separated by introns the relative abundance of RNAs vary wildly RNAs come in a wide range of sizes RNA-Seq library enrichment strategies total RNA: all types RNAs가 sequencing 됩니다. rRNA reduction: rRNAs를 제거한 나머지 RNAs만 sequencing 합니다. PolyA selection: mRNA만 선별적으로 sequencing 합니다. cDNA capture: interesting genes의 mRNA만 선택하여 sequencing 합니다. RNA-Seq library enrichment strategieshttps://www.edwith.org/transcriptome/lecture/1382678 stranded vs. unstranded 최근에는 대부분 stranded sequencing을 진행합니다. stranded vs. unstrandedhttps://www.edwith.org/transcriptome/lecture/1382678 RNA quality control RIN: RNA integrity number. 0(bad) ~ 10(good). RNA quality를 나타내는 수치입니다. RINhttps://www.edwith.org/transcriptome/lecture/1382678 replicates biological replicate: multiple isolations of cells showing the same phenotype, stage of other experimental condition. 즉, 시료의 양이 충분하다면 가급적 3개 이상으로 시료를 나누어 sequencing, analysis 하는 것을 권장합니다. 3개 중 1개 데이터에 이상이 있더라도 나머지 2개 데이터를 통계처리하여 올바른 결과를 도출할 수 있기 때문입니다. Take Home Messagemicroarray 대비 RNA-Seq이 가지는 장점을 확인할 수 있었습니다. RNA-Seq에서 샘플의 quality가 매우 중요하고, 얻은 data로부터 gene expression level, gene fusion analysis, mutation discovery 등 다양한 결과를 얻을 수 있음을 확인 했습니다." }, { "title": "(EDWITH-KOBIC) 암 유전체 분석", "url": "/posts/Certificate_cancer_genomics_analysis/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, cancer genomics, KOBIC", "date": "2022-11-07 08:00:00 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "Definition of Data", "url": "/posts/database-sql222/", "categories": "Programming, Database", "tags": "programming, database, relationalmodel, SQL", "date": "2022-11-06 21:05:13 +0900", "snippet": "본 post는 K-MOOC 고려사이버대학교(매치업) 이건길 교수님의 SQL 정형 데이터 분석 강의를 정리한 내용입니다.IntroSQL의 개념을 이해하고 설명할 수 있습니다. 데이터베이스를 정의하여 활용할 수 있습니다. 테이블을 정의하여 활용할 수 있습니다. SQL 개요 SQL 정의 SQL(Structured Query Language)이란? 데이터베이스에 접근할 수 있는 데이터베이스 언어입니다. 1974년 IBM 연구소에서 발표한 SEQUEL(Strructured English QUEry Language)에서 유래했습니다. 관계 대수와 관계 해석을 기초로 한 고급 데이터 언어입니다. MySQL, DB2, SQL Server, ORACLE, INFORMIX, SYBASE 등 관계형데이터베이스에서 모두 사용합니다. SQL 발전과정 SQL 발전과정http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ SQL 특징 SQL 특징http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 관계 연산과 SQL 관계 연산과 SQLhttp://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ SQL 명령어 SQL 명령어 종류 SQL 명령어 종류http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ SQL 명령어 예http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 데이터베이스 정의 데이터 저장 구조 관계형 DBMS 관계형 DBMShttp://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ ORACLE 데이터 저장 구조 무결성을 강조하는 구조로 금융권에서 많이 사용합니다. MySQL/MariaDB 저장 구조도 이와 유사합니다. ORACLE 데이터 저장 구조http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ ORACLE 데이터 저장 구조http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ SQL을 이용한 데이터베이스 생성 CREATE DATABASE 명령어 - SQL Server, MySQL/MariaDB SQL 명령어 종류http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 테이블 정의 SQL 테이블 정의 테이블 구조 SQL 테이블 구조http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ CREATE TABLE 명령어 CREATE TABLE 명령어 - 형식http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ CREATE TABLE 명령어 - 컬럼 제약http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ CREATE TABLE 명령어 - 테이블 제약http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 제약조건 정의 데이터베이스 무결성을 구현하기 위한 도구입니다. 컬럼이나 테이블에 저장되는 값이 준수해야 할 조건을 명시한 것입니다. ‘NOT NULL’, ‘PRIMARY KEY’, ‘UNIQUE’, ‘DEFAULT’, ‘CHECK’, ‘FOREIGN KEY’가 존재합니다. ‘PRIMARY KEY’ 제약조건 PRIMARY KEY 제약조건http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ ‘NOT NULL’ 제약조건 NOT NULL 제약조건http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ ‘DEFAULT’ 제약조건 DEFAULT 제약조건http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ ‘CHECK’ 제약조건 ‘CKECK’ 제약조건을 사용하면 데이터의 무결성을 지킬 수 있지만 작업의 로드가 높아질 수 있는 단점이 있습니다. CHECK 제약조건http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ ‘UNIQUE’ 제약조건 UNIQUE 제약조건http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ ‘FOREIGN KEY’ 제약조건 - 테이블 정의 시 FOREIGN KEY’ 제약조건 - 테이블 정의 시http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ ‘FOREIGN KEY’ 제약조건 - 제약조건 추가 FOREIGN KEY’ 제약조건 - 제약조건 추가http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ SQL 테이블 변경 테이블 삭제 명령어 테이블 삭제 명령어http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 테이블 변경 명령어 테이블 변경 명령어http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 컬럼의 추가 컬럼의 추가http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 컬럼의 수정 컬럼의 수정http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 컬럼의 삭제컬럼의 삭제http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ Take Home MessageSQL 데이터베이스와 테이블의 생성/수정/삭제 등 다루는 법을 알 수 있었습니다." }, { "title": "Relational Model", "url": "/posts/database-sql1/", "categories": "Programming, Database", "tags": "programming, database, relationalmodel", "date": "2022-11-06 08:12:21 +0900", "snippet": "본 post는 K-MOOC 고려사이버대학교(매치업) 이건길 교수님의 SQL 정형 데이터 분석 강의를 정리한 내용입니다.Intro데이터베이스의 개념과 관계형 모델의 개념에 대해 알아봅니다. 그리고 관계형 모델을 다루는 SQL 언어에 대해 설명할 수 있습니다.데이터베이스 개요 데이터베이스 정의 데이터베이스에 대한 정의는 다음과 같습니다. A collection of related data (Fundamentals of Database System, Elmasri and Navathe) An organized collection of data, generally stored and accessed electronically from a compyter system (wikipedia) 데이터베이스 특성데이터베이스 특성http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 실시간 접근성(Real-time Accessibility) 데이터베이스는 사용자의 데이터 요구에 실시간으로 응답해야 합니다. 사용자의 개인 특성이나 제공되는 서비스 유형에 따라 허용되는 응답 시간이 다르지만 대개 몇 초를 넘지 않는 시간 내에 데이터를 제공할 수 있어야 합니다. 계속적인 변화(Continuous Evolution) 데이터베이스는 현실 세계의 상태를 정확히 반영해야 하며 데이터베이스에 저장된 데이터도 계속 변해야 합니다. 데이터를 계속 삽입(insert), 삭제(delete), 수정(update)하여 현재의 정확한 데이터를 유지합니다. 동시 공용(Concurrent Sharing) 데이터베이스는 여러 사용자가 동시에 이용할 수 있어야 합니다. 사용자가 서로 다른 데이터를 동시에 사용하는 것뿐만 아니라 같은 데이터를 동시에 사용하는 것도 모두 지원해야 합니다. 여러 사용자가 함께 사용하지만 단독으로 사용하는 것과 같은 일관성을 유지해야 합니다. 내용에 의한 참조(Content Reference) 일반적으로 컴퓨터에 저장된 데이터는 저장 주소를 알아야 검색이 가능합니다. 데이터베이스는 저장된 주소나 위치가 아닌 데이터의 내용(content), 즉 값(value)으로 참조합니다. 찾고자 하는 데이터의 내용 조건만 제시하면 조건에 맞는 데이터가 저장된 위치에 관계없이 모두 검색합니다. 데이터베이스 구축 목적데이터베이스 구축 목적http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 데이터베이스 스키마(Schema)데이터베이스 스키마http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 관계형 모델 개요 데이터 모델링데이터의 세계http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 데이터 모델링이란 정보시스템을 구축하기 위해, 어떤 데이터가 존재하는지 또는 업무가 필요로 하는 정보는 무엇인지를 분석/표현하는 방법입니다. 또한 고객으로부터 데이터에 대한 요구사항을 파악하고, 프로젝트에 참여하는 분석자, 설계자, 개발자, 사용자 간의 효율적인 의사 소통을 위해 필수적인 과정입니다. 신규 또는 개선 시스템 개발을 위한 기초가 됩니다. 데이터 모델링 단계는 아래와 같습니다.데이터 모델링 단계http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 데이터 모델 데이터 모델이란 현실 세계를 데이터베이스로 표현하는 과정에서 데이터베이스의 구조를 개념적/논리적으로 표현하기 위해 사용되는 도구입니다. 데이터 모델의 종류와 장단점은 다음과 같습니다. 데이터 모델 종류http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 데이터 모델 장단점http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 관계 모델 1970년 IBM 연구소의 “A relational model for large shared data banks”라는 논문에서 처음으로 소개된 모델입니다. Mathmatical relation의 개념을 사용해서 table의 형태로 표현합니다. 현재 대부분의 상업용 DBMS에서 지원합니다. (ORACLE, SQL Server, MySQL, IBM DB2 등) 관계 모델에서는 데이터베이스를 relation(table)의 집합으로 정의합니다. 즉, table 형태로 데이터를 저장하는 것입니다.관계 모델 구조http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 관계 모델 용어 정의http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/ 관계 모델의 특징은 다음과 같습니다. Set theory(집합이론)에 기초합니다. 한 relation에 포함된 tuple들은 모두 상이합니다. 모든 attribute 값은 atomic value(원자 값)입니다. 한 relation을 구성하는 tuple과 attribute 사이에는 순서가 없습니다. 관계형 모델과 SQL 데이터베이스 언어데이터베이스 언어http://www.kmooc.kr/courses/course-v1:MA_CUK+MATCHUP_CUK03+2022_2/course/데이터베이스 언어는 데이터베이스를 정의하고 접근하기 위한 목적으로 만들어진 언어입니다. 데이터 정의어, 데이터 조작어, 데이터 제어어로 나뉩니다. 데이터 정의어(Data Definition Language) 데이터베이스를 정의하거나 그 정의를 수정할 목적으로 사용하는 언어입니다. 데이터베이스 스키마를 컴퓨터가 이해할 수 있게끔 기술하는 데 사용합니다. 데이터베이스 관리자나 데이터베이스 설계자가 주로 사용합니다. DDL로 기술된 스키마는 통상 DDL 컴파일러가 컴파일하여 데이터 사전이나 시스템 카탈로그에 저장하여 놓고 필요한 경우에 시스템이 활용합니다. 예) 테이블 생성, 변경 등 데이터 조작어(Data Manipulation Language) 사용자로 하여금 데이터를 처리할 수 있게 하는 도구입니다. 사용자(응용프로그램)와 DBMS 간의 인터페이스를 제공합니다. 예) 데이터의 검색, 삽입, 삭제, 변경 등 데이터 제어어(Data Control Language) 여러 사용자가 데이터베이스를 올바르게 공용하고, 정확하게 유지하기 위해 관리 및 통제 기능을 목적으로 사용하는 언어입니다. 주로 데이터 관리 목적으로 데이터베이스 관리자가 사용합니다. Take Home Message관계형 모델에 대한 전반적인 개요 내용을 살펴볼 수 있었습니다." }, { "title": "Variants Analysis VI - Cancer Immunotherapy", "url": "/posts/Variants_Analysis_VI/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, variant, cancer, immune, immunotherapy", "date": "2022-11-03 08:12:21 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 연세대학교 의과대학 김상우 교수님의 NGS 데이터 분석 기초 강의를 정리한 내용입니다.IntroNGS를 이용하여 cancer immune analysis에 대해 알아봅니다. Cancer immune 및 면역항암의 기초, TMB(tumor mutation burden), HLA 및 HLA 변이, neoantigen 분석 등을 알아봅니다.Cancer Immunotherapy기본 개념은 host의 immune system을 cancer 제거하는 방향으로 가이드하는 것입니다.Adaptive Immunity and T-cell Activationhttps://www.edwith.org/ngs-data-variation/joinLectures/356132사람의 몸에 침입한 antigen은 antigen-presenting cell에 의하여 우리 몸이 침입을 감지하고 대응할 수 있도록 알리는 역할을 합니다. Cytotoxic T-cell이 직접 antigen을 공격하는 동시에 helper T-cell이 B-cell로 하여금 antibody를 생성, 배출하도록 리드합니다. 또한 memory T-cell로 하여금 적응면역을 갖도록 합니다.Tumor Antigenhttps://www.edwith.org/ngs-data-variation/joinLectures/356132이러한 immune system을 활용하여 tumor cell을 제거하기 위해서는, normal cell에는 존재하지 않고 tumor cell에만 존재하는 specific antigen을 목표로 삼는 것이 좋습니다. TSA(Tumor Specific Antigen)는 tumor cell에 특이적인 antigen을 의미하며, TAA(Tumor Associated Antigen)는 일부 normal cell에도 존재하지만 대부분 tumor cell에서 나타나는 antigen을 의미합니다.Benefits from Cancer Immunotherapyhttps://www.edwith.org/ngs-data-variation/joinLectures/356132Immunotherapy는 chemotherapy, genomically targeted therapy와 비교해서 환자의 생존률 향상의 효과를 보입니다. 두 가지 함께 사용하면 효과가 증가하므로 궁극적으로는 이러한 치료방법을 함께 사용하여 환자의 생존률을 높이는데 목적이 있습니다.TMB (Tumor Mutation Burden)Immunotherapy의 효과를 예측하거나 대상자를 선정할 때, 가장 좋은 방법은 환자가 immunotherapy의 target antigen(neoantigen)을 얼마나 가지고 있는지 확인하는 것입니다. 하지만 neoantigen만 동정하는 것이 쉽지 않으므로 이를 가늠할 수 있는 보조지표로 TMB를 활용할 수 있습니다.Who can benefit from checkpoint inhibitor?https://www.edwith.org/ngs-data-variation/joinLectures/356132B figure에서 100개 이상의 mutations를 가진 환자가 100개 미만 mutations를 가진 환자에 비해 치료결과 생존률이 더 높은 것을 확인할 수 있습니다.TMB - from Hopes to Doubtshttps://www.edwith.org/ngs-data-variation/joinLectures/356132TMB는 유용한 지표가 될 수 있지만 TMB를 구할 때, 해석할 때 주의해야 합니다. 어느 정도 score를 기준으로 high/low를 구분해야 하는지, TMB score를 다시 분석해도 재현 가능한지, panel의 target gene region에 대한 depth가 uniform한지 등을 유의해야 합니다.HLA Typing in the Antigen ProcessingNeoantigen Processinghttps://www.edwith.org/ngs-data-variation/joinLectures/356132Neoantigen에 의해 어떻게 immune system이 작동하는지 보여주는 그림입니다. Somatic mutation이 AA 변형을 가져와 proteasome에 의해 protein이 degradation 됩니다. 이 때 생성된 neopeptides가 ER로 들어가서 specific하게 MHC와 결합합니다. peptide-MHC는 golgi를 거쳐 cell membrane에 presenting되고 T-cell에 의해 인지되어 immune system이 작동합니다.HLA (Human Leukocyte Antigen)https://www.edwith.org/ngs-data-variation/joinLectures/356132HLA gene은 6p21.31 위치에 뭉쳐서 존재하고 있습니다. Class I은 cytotoxic T-cell, CD8 T-cell의 immunogenicity를 제공하는 gene들로 구성되어 있습니다. Class II는 helper T-cell, CD4 T-cell의 immunogenicity를 제공하는 gene들로 구성되어 있습니다.HLA gene은 다른 gene에 비해 훨씬 더 많은 polymorphism을 가지고 있습니다. 즉, 사람마다 HLA gene의 allele이 다르고 그 종류가 매우 여러가지 이므로 사람에 따라서 immunogenicity를 가질 수도 있고 가지지 않을 수도 있습니다.HLA Alleles are Ethnic Specifichttps://www.edwith.org/ngs-data-variation/joinLectures/356132인종마다, 지역마다 사람의 HLA allele은 매우 다양한 분포를 보입니다. HLA 변이는 약속된 표기법을 따르는데 gene, allele group, specific HLA protein 등의 정보를 담고 있습니다.HLA Typing Methodshttps://www.edwith.org/ngs-data-variation/joinLectures/356132과거에는 실험적 방법이나 sanger sequencing, microarray와 유사한 방식은 sequence-specific oligonucleotide hybridization 등의 방법을 사용했습니다.NGS 방식으로도 분석이 가능한데 다음과 같은 장단점이 있습니다. Pros Use of (already) produced NGS-data No extra-cost Fast Cons Short-read HLA genes are GC-rich: lower-sequencing coverage NGS-based HLA Typing Toolshttps://www.edwith.org/ngs-data-variation/joinLectures/356132Assembly 방식과 alignment 방식의 analysis tool이 존재합니다.MHC Binding and ImmunogenicityNeoantigen이 MHC와 결합할지 여부는 경우의 수가 매우 많고 mutation이 존재할 수 있으므로 예측이 매우 어렵습니다.Prediction Algorithmhttps://www.edwith.org/ngs-data-variation/joinLectures/356132따라서 PSSM, SVM, HMM 등 기계학습을 이용하여 이미 알려진 antigen, MHC set data을 통해 학습하고 immunogenicity를 예측하는 알고리즘을 만들기 위한 노력들이 이어지고 있습니다.Neoantigen Analysis &amp;amp; Integrated PipelinesTumor-Normal 시료를 input으로 사용하고 DNA, RNA NGS data를 생산하여 neoantigen을 확인할 수 있는 분석을 진행할 수 있습니다.Overall Pipeline: pVAC-Seqhttps://www.edwith.org/ngs-data-variation/joinLectures/356132Take Home MessageNGS를 적용하여 cancer의 immunogenicity에 대한 분석을 할 수 있습니다. 관련된 분석으로는 TMB(Tumor Mutation Burden), HLA typing 및 변이, somatic mutation/neopeptide-neoantigen 후보군 예측 등이 있습니다. Personalized cacner immunotherapy를 위해서는 유전체 분석이 필수적입니다. 이를 통해 neoantigen, tymor microenvironment에 대한 정보를 얻을 수 있습니다." }, { "title": "Variants Analysis V - Cancer Analysis", "url": "/posts/Variants_Analysis_V/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, variant, cancer, calling", "date": "2022-10-25 08:28:05 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 연세대학교 의과대학 김상우 교수님의 NGS 데이터 분석 기초 강의를 정리한 내용입니다.IntroNGS를 이용하여 cancer genome analysis에 대한 내용을 알아봅니다.Cancer is a Genetic DiseaseCancer is a genetic diseasehttps://www.edwith.org/ngs-data-variation/joinLectures/356132Cancer는 hallmark genes에 genetic variations이 축적되면서 발생하는 genetic disease입니다.Cancer Cells have a Higher Rate of Mutationhttps://www.edwith.org/ngs-data-variation/joinLectures/356132Cancer cell은 replication 중 발생하는 mismatch error를 복구하거나 버리지 않고 variant로 가져감으로써 gene function에 영향을 줍니다. Cell 분열속도가 normal cell에 비해 빠르므로 이러한 mismatch error의 숫자는 급속도로 증가합니다.Analysis of Cancer Somatic Mutation Profiles Tumor Mutation Burden (TMB) Cacner cell에 존재하는 non-synonymous somatic mutations 수를 의미합니다. Cancer type마다 서로 다른 TMB 경향을 보이는 것을 알 수 있습니다. Tumor Mutation Burden https://www.edwith.org/ngs-data-variation/joinLectures/356132 Microsatellite Instability (MSI) Impaired DNA mismatch repair (MMR)의 결과로 발생하는 genetic hypermutability 현상을 의미합니다. 아래 그림과 같이 repeat 영역에서 replication이 진행될 때 1base 이상 차이가 날 수 있는데 이로 인하여 mutation이 발생하는 case 입니다. Microsatellite Instability https://www.edwith.org/ngs-data-variation/joinLectures/356132 Mutational Signature Mutation이 발생한 pattern을 의미하며, 환자의 분류, 치료에 사용할 수 있는 지표입니다. 보통 특정 position에서 발생할 수 있는 SNP 경우의 수(6 cases: C&amp;gt;A, C&amp;gt;G, C&amp;gt;T, T&amp;gt;A, T&amp;gt;C, T&amp;gt;G)와 1bp 앞뒤로 발생할 수 있는 각각 4 cases를 종합하여 총 96 cases (=644)가 존재합니다. Mutational Signature https://www.edwith.org/ngs-data-variation/joinLectures/356132 이러한 mutational signature의 상대적인 pattern을 연구하고 어떤 mutagen에 의해 발생했는지 연구하여 21가지 pattern을 발표했습니다. Mutational Signature https://www.edwith.org/ngs-data-variation/joinLectures/356132 Mutation Landscape Mutation의 종류와 어떤 gene에서 발생했는지, 그리고 frequency 등을 한 번에 볼 수 있는 plot 입니다. Mutational Signature https://www.edwith.org/ngs-data-variation/joinLectures/356132 Hotspot Positions (lollipop plot) Mutations가 모여있는 hotspot position을 확인할 수 있는 lollipop plot 입니다. Mutation이 gene의 어느 곳에 몰려있는지, 혹은 넓게 흝어져 있는지 한 눈에 파악할 수 있습니다. Mutational Signature https://www.edwith.org/ngs-data-variation/joinLectures/356132 Mutation Specificity 각 pathoway와 연관된 gene에서 발생하는 mutation 비율을 정리한 plot 입니다. Red box처럼 다양한 cancer type에서 발견되는 pathway가 있는가하면, blue box처럼 특정 cancer type에서 발견되는 pathway가 있음을 확인할 수 있습니다. Mutational Signature https://www.edwith.org/ngs-data-variation/joinLectures/356132 Take Home MessageCancer genome analysis에 NGS를 적용하면 많은 정보를 알아낼 수 있습니다. Cancer related mutations type, 수, 특성, 발병 원인, subgroup, 중요한 gene의 mutation 등의 정보가 해당합니다." }, { "title": "Variants Analysis IV", "url": "/posts/Variants_Analysis_IV/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, variant, calling", "date": "2022-10-25 08:20:14 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 연세대학교 의과대학 김상우 교수님의 NGS 데이터 분석 기초 강의를 정리한 내용입니다.IntroNGS 최적 분석 파이프라인에 대해 알아봅니다.Artigacts of variant callingArtifacts of variant callinghttps://www.edwith.org/ngs-data-variation/joinLectures/356132Variant calling 과정에 다양한 종류의 artifacts가 나타납니다. Sequencing error, uneven read depth, platform specific errors, misclassification, DNA damage, PCR-induced error, read mapping error, DNA contamination 등이 있습니다.이 외에도 NGS data analysis 관련 다음과 같은 위험요소들이 있습니다. Artifacts in sample handling Sample Swap 환자 A, B의 시료가 서로 뒤바뀌는 case로 생각보다 빈번하게 일어납니다. 해결1) Tumor, matched normal을 함께 가지고 있는 경우, 두 시료로부터 germline variants를 calling한 뒤 matrix를 그려보면 sample swap을 확인할 수 있습니다. 해결2) HYSYS, NGSCheckMate, BAMixChecker 등의 이미 개발된 tool을 활용하여 sample swap을 확인할 수 있습니다. Check Sample Swap by Calling Germline Variants https://www.edwith.org/ngs-data-variation/joinLectures/356132 Sample Contamination Human sample이 다른 종과 뒤섞인 case입니다. 해결) CONTEST 등의 이미 개발된 tool을 활용하여 sample contamination을 확인할 수 있습니다. DNA damage DNA는 보통 paraffin block에 보관하는데, 이 때 cytosine이 deamination 과정을 거쳐 uracil로 변하는 damage를 입게 됩니다. Paraffin block으로 오래 보관한 시료일수록 C&amp;gt;T false positive variant가 많이 나타남을 알 수 있습니다. 해결) 이미 개발된 tool을 활용하여 DNA damage false positive variant를 제거할 수 있습니다. Artifacts in library preparation DNA damage by OxoG DNA capture 과정에서 OxoG(G&amp;gt;T, C&amp;gt;A variant) false positive variant가 발생합니다. 해결) 이미 개발된 tool을 활용하여 OxoG false positive variant를 제거할 수 있습니다. PCR-induced error PCR 과정에서 false positive variant가 발생합니다. Low frequency variants Tumor와 normal이 섞여 있는 상태에서 low allele frequency variant calling은 매우 도전적인 과제입니다. Platform specific errors Ion-Torrent: homopolymer 영역에서 정확한 base calling이 어렵습니다. 해결) ion-torrent에 특화된 analysis tool을 활용하여 해결할 수 있습니다. Take Home MessageNGS variant calling은 단순한 pipeline 실행이 아닙니다. Human error, DNA damage, contamination, platform specific error 등 다양한 위험 요소가 존재합니다. 특히 환자의 genome analysis와 같은 실수가 용납되지 않는 analysis에서는 이러한 error를 고려한 pipeline 구성이 필수적입니다." }, { "title": "(EDWITH-KOBIC) 후성 유전체 데이터 분석", "url": "/posts/Certificate_Methylation_analysis/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, methylation, KOBIC", "date": "2022-10-25 08:00:05 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "Variants Analysis III", "url": "/posts/Variants_Analysis_III/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, next generation sequencing, variant, calling, SV", "date": "2022-10-20 11:53:51 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 연세대학교 의과대학 김상우 교수님의 NGS 데이터 분석 기초 강의를 정리한 내용입니다.IntroNGS를 이용한 structural variation 탐지 방법을 알아봅니다.Structural VariationsList of Structural Variationshttps://www.edwith.org/ngs-data-variation/joinLectures/356132Structural variations 종류입니다. NGS를 사용하여 대부분 검출할 수 있습니다.Methods for SV Detectionhttps://www.edwith.org/ngs-data-variation/joinLectures/356132SV 검출은 어려운 과정이므로 아래와 같이 여러 가지 방법(알고리즘)을 사용하여 결과를 도출하는 것이 좋습니다.Methods for SV Detectionhttps://www.edwith.org/ngs-data-variation/joinLectures/356132Take Home MessageNGS를 이용한 SV 검출은 read depth, split reads, assembly 등의 정보를 활용하여 가능함을 알 수 있었습니다." }, { "title": "Clustering of Single Cell &amp; Cell Type Assignment I", "url": "/posts/Preprocessing_of_Single_Cell_Analysis_III/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, single cell analysis", "date": "2022-10-16 20:37:33 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 아주대학교 의과대학 김규태 교수님의 단일세포 클러스터링 및 Cell Type Assign (이론)을 정리한 내용입니다.IntroClustering analysis의 의미와 종류, 방법을 이해합니다. Cell type assignment 과정을 이해합니다.Clustering AnalysisClustering Analysishttps://www.edwith.org/single-cell/lecture/1417886Clustering이란 그림과 같이 특정 기준에 따라 유사한 것끼리 묶는 과정입니다.Evaluation of Clusteringhttps://www.edwith.org/single-cell/lecture/1417886Clustering 평가 방법은, 같은 cluster에 속하는 요소끼리 거리는 가까울수록(intra-scluster distance), 서로 다른 cluster끼리 거리는 멀수록(inter-cluster distance) good clustering으로 평가할 수 있습니다.Clustering 방법과 종류5강 15:13Take Home MessageSingle cell analysis 전반적인 분석 과정에 대해 알아볼 수 있었습니다." }, { "title": "Preprocessing of Single Cell Analysis II", "url": "/posts/Preprocessing_of_Single_Cell_Analysis_II/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, single cell analysis", "date": "2022-10-16 16:02:50 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 아주대학교 의과대학 김규태 교수님의 단일세포 전사체 데이터 전분석 (실습)을 정리한 내용입니다.IntroSingle cell data의 mapping, normalization, batch 제거 과정을 이해합니다.Single Cell Data MappingBasic Data Processing Workflowhttps://www.edwith.org/single-cell/lecture/1417886Sequencing data가 나오면 가장 먼저 QC check를 진행합니다. FastQC를 사용하여 read1,2 quality에 이상이 없는지 확인합니다.Pre-peocessing Pipeline of 10X CellRangerhttps://www.edwith.org/single-cell/lecture/141788610x Genomics에서 제공하는 CellRanger로 분석을 진행합니다. Fastq를 input으로 받아서 분석한 뒤 gene level expression matrix data를 cell별로 제공합니다.Data Processing and Normalization in scRNA-seq Datahttps://www.edwith.org/single-cell/lecture/1417886Data 전분석과 normalization 과정에 대한 설명입니다. CellRanger와 Seurat을 사용하여 진행할 수 있습니다.Estimation of Gene Abundanceshttps://www.edwith.org/single-cell/lecture/1417886RNA sequencing data는 보통 RPKM/FPKM으로 read counts를 보정하여 특정 gene이 샘플에서 얼마나 발현되었는지 확인합니다.Estimation of Gene Abundanceshttps://www.edwith.org/single-cell/lecture/1417886하지만 RPKM/FPKM은 샘플 사이에서 특정 gene의 발현이 증가/감소되었는지 경향을 확인하는데 문제가 있습니다. 이 때 TPM(transcript per million) 단위를 사용합니다.Take Home MessageSingle cell analysis 전반적인 분석 과정에 대해 알아볼 수 있었습니다." }, { "title": "Preprocessing of Single Cell Analysis I", "url": "/posts/Preprocessing_of_Single_Cell_Analysis_I/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, single cell analysis", "date": "2022-10-15 21:05:23 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 아주대학교 의과대학 김규태 교수님의 단일세포 전사체 데이터 전분석 I를 정리한 내용입니다.IntroSingle cell analysis의 의의, 구조와 형식, 전분석 과정을 이해합니다.Single Cell Analysis 의의사람의 몸은 많은 cell이 모여 구성하고 있습니다. 모든 cell은 각각 특성을 지니고 있으며 다른 cell과 구분되는데 이를 cellular heterogeneity(세포 이질성)이라고 합니다.Waddington’s modelhttps://www.edwith.org/single-cell/lecture/1417886Pluripotent cell로부터 다양한 cell state로 differentiation되는 과정을 설명하는 Waddington’s model입니다. Pluripotent cell로부터 methylation을 거쳐 다양한 특성을 가진 cell로 분화된다는 이론입니다.Tumor Micro-Environmenthttps://www.edwith.org/single-cell/lecture/1417886A cell은 B, C cell과 같이 현재 normal cell 상태입니다. 하지만 혈관에 인접해 있으므로 산소 등의 물질을 공급받는데 유리합니다. C cell은 tumor cell과 인접해 있으므로 시간이 지나면 tumor cell 분비물질의 영향을 받아 유사하게 변해갈 것입니다.이처럼 하나의 pluripotent cell로부터 시간, 공간적으로 다양한 성격을 지닌 cell로 분화되며, 이를 모두 구분하여 분석하는 것은 도전적 과제인 동시에 현재 상태를 정확히 파악할 수 있는 방법입니다.Bulk RNA-seq 대비 scRNA-seq의 장점https://www.edwith.org/single-cell/lecture/1417886아리스토텔레스는 ‘전체는 부분의 합보다 크다.’는 이야기를 남겼습니다. 하지만 RNA-seq에서는 부분(single-cell)이 전체(bulk)보다 더 많은 의미를 담고 있습니다.Bulk RNA-seq은 모든 cell에서 gene expression level이 평균적인 값으로 나타납니다. 반면에 single cell RNA-seq은 cell별로 gene expression level을 구분하여 파악하고 clustering 할 수 있습니다.History of Single Cell Analysishttps://www.edwith.org/single-cell/lecture/1417886Single Cell Data의 구조와 형식Basic Single Cell Analysis Workflowhttps://www.edwith.org/single-cell/lecture/1417886기본적인 single cell analysis 과정은 다음과 같습니다. Droplet-based microfludics와 같은 방식으로 single cell을 분리한 다음 sequencing을 통해 amplifying 과정을 진행합니다. 마지막으로 statistical/algorithmical mining을 진행하여 각 cell이 지니는 의미를 파악합니다.10x Genomicshttps://www.edwith.org/single-cell/lecture/141788610x genomics사의 commercial service를 많이 사용하고 있습니다. 하나의 droplet에 single cell 한 개가 들어가도록 조정하고, 10x barcode와 UMI를 사용하여 transcript의 양을 확인하고 분석합니다.Single Cell Data의 전분석 과정Seurat R Packagehttps://www.edwith.org/single-cell/lecture/141788610x genomics에서도 sequencing 결과 분석에 Seurat R package를 사용하도록 권고하고 있습니다. 위와 같은 과정으로 분석을 진행합니다.Take Home MessageSingle cell analysis가 지닌 의의와 전반적인 분석 과정에 대해 알아볼 수 있었습니다." }, { "title": "Introduce to Single Cell Analysis", "url": "/posts/Introduce_to_Single_Cell_Analysis/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, single cell analysis", "date": "2022-10-03 21:10:40 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 광주과학기술원(GIST) 박지환 교수님의 단일세포 분석 기술 소개를 정리한 내용입니다.IntroSingle cell analysis의 다양한 기술을 자세히 알아봅니다.RNA in Mammalian Cellhttps://www.edwith.org/single-cell/joinLectures/361836Mammalian cell에 존재하는 10~30pg의 RNA 중 protein coding mRNA는 0.25~0.9pg밖에 존재하지 않습니다. 이를 분자수로 환산하면 약 36만 개 정도입니다.Evolution of scRNAseq Techniqueshttps://www.edwith.org/single-cell/joinLectures/3618362009년 경 수작업으로 single cell analysis 시도가 시작되었습니다. 이후 Fluidigm, drop-seq 등의 기술 발전을 거쳐 최근에는 SPLiT, sci-seq 방법들을 사용하여 동시에 수 십 만개의 single cell을 분석할 수 있는 방법이 개발되었습니다.Single Cell Isolation Techniqueshttps://www.edwith.org/single-cell/joinLectures/361836Pipette로 dialution하며 isolation 하던 방법부터 LCM까지 발전을 거듭해 왔습니다. 현재는 Microfluidics를 이용한 isolation과 CTC(Circulate Tumor Cell)와 같이 미량의 cell을 분리하기 위해 antibody와 magnetic particle을 사용하는 방법을 사용합니다.Full Length vs 3’ end cDNA seqhttps://www.edwith.org/single-cell/joinLectures/3618363’ end cDNA seq의 경우 gene exporession quantification만 가능한 반면 full length cDNA seq은 alternative splicing, somatic mutation, 그리고 eQTL analysis까지 가능한 장점을 가지고 있습니다.Droplet Technique - 10x GenomicsDroplet single cell analysis 방식으로 대표되는 10x Genomics사의 원리에 대해 알아봅니다.10x Genomics Techniquehttps://www.edwith.org/single-cell/joinLectures/361836Lane당 약 10,000개의 cell을 분석할 수 있으며, 총 8개 lane이 있으므로 한 번에 80,000개까지 가능합니다. 하나의 oil droplet 안에는 한 개의 gel bead와 한 개의 cell이 들어있으며 cDNA 합성 과정을 거쳐 single cell analysis에 사용됩니다.10x Genomics Techniquehttps://www.edwith.org/single-cell/joinLectures/361836Cell membrane이 lysis된 후 bead에 붙은 약 70만 개의 oligo와 함께 cDNA 합성이 진행됩니다. 이 때 Poly-A 부분이 poly(dT)에 binding하고 이후 UMI, 10x barcode가 차례로 상보적 sequence가 합성됩니다.10x Genomics Techniquehttps://www.edwith.org/single-cell/joinLectures/361836Barcode processing부터 기본분석 완료 후 expression analysis를 진행합니다. 이 때 ‘seurat’ 프로그램을 사용하여 QC, normalization, PCA, tSNE, clustering 분석을 차례대로 진행합니다.Take Home MessageSingle cell analysis와 연관된 다양한 기술을 알아볼 수 있었습니다." }, { "title": "Experimental Design for Single Cell Analysis", "url": "/posts/Experimental_Design_for_Single_Cell_Analysis/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, single cell analysis", "date": "2022-10-03 14:26:55 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 광주과학기술원(GIST) 박지환 교수님의 단일세포 분석 소개 및 실험 디자인을 정리한 내용입니다.IntroSingle cell analysis의 필요성 및 연구배경, 실험 디자인에 대한 내용을 이해합니다.Single Cell Analysis 필요성https://www.edwith.org/single-cell/joinLectures/361836과거에는 RT-PCR, bulk RNA-seq 등으로 cell에서 gene expression level을 확인했습니다. 그 결과 structure, location, function, a small number of markers 등에 따라 사람은 약 200여 개 종류의 서로 다른 cell types이 존재한다고 알려졌습니다. 하지만 single cell analysis를 통해서 동일한 organ이라도 서로 다른 cell type이 존재함을 확인했습니다. 또한 한 사람당 약 20,000개의 cell과 그 곳에 포함된 약 20,000~30,000개의 gene에 대해 분석하고 더 정확한 결과를 얻을 수 있게 되었습니다.Single Cell Analysis 필요성Single Cell Analysis 필요성https://www.edwith.org/single-cell/joinLectures/361836RNA-seq은 cell을 구분하지 못하고 평균적인 gene expression level을 확인합니다.반면 single cell analysis는 cell별로 gene exporession level을 구분하여 확인할 수 있습니다.Single Cell Analysis 필요성https://www.edwith.org/single-cell/joinLectures/361836또한 single cell analysis를 활용하면 cell specific change와 cell type composition change를 구분할 수 있습니다. 예를 들어 정상인과 환자의 single cell analysis를 진행하면 disease와 연관된 red cell의 green gene expression high level이 cell 내 exporession 증가에 의해서인지(cell specific change), 혹은 red cell의 증가에 의해서인지(cell type coposition change) 구분할 수 있습니다.Single Cell Analysis 필요성https://www.edwith.org/single-cell/joinLectures/361836뿐만 아니라 cell이 분화하면서 변화하는 gene expression level을 추적 관찰할 수도 있습니다. 더 나아가 생물의 진화 양상을 추적할 수도 있습니다.Basic Steps of Single Cell AnalysisSingle Cell Analysis 기본 단계https://www.edwith.org/single-cell/joinLectures/361836Single cell analysis의 기본적인 단계입니다. Tissue에서 cell을 분리한 다음 library를 만들고 rna seq을 진행합니다. Gene expression data를 clustering한 뒤 발현양을 비교합니다.Single Cell Analysis: Library Preparationhttps://www.edwith.org/single-cell/joinLectures/361836Library prep에 사용할 수 있는 방법은 여러 가지 개발되어 있으며 상요화 된 기술도 존재합니다. UMI 사용여부, cDNA를 얼만큼 cover하는지, 그리고 한 번에 몇 개의 cell을 cover할 수 있는지 등에 차이가 있습니다.Experimental Design for Single Cell Analysis기본적으로 모든 tissue에 대해 single cell analysis를 진행할 수 있습니다. 하지만 tissue 종류에 따라 dissociation 난이도가 다르고 포함하고 있는 total RNA 양도 다르기 때문에, 특성을 고려한 실험 디자인이 필요합니다.Sample Preparation Protocol Varies by Cell-typeshttps://www.edwith.org/single-cell/joinLectures/361836RNA 양이 적은 solid tissue나 adherent cell culture는 dissociation을 수행합니다. 관심있는 cell만 골라낼 필요가 있는 경우에는 MACS나 FAC sorting으로 enrichment를 수행합니다.Doublets Problemshttps://www.edwith.org/single-cell/joinLectures/361836Single cell analysis의 문제점 중 하나는 바로 doublets입니다. Droplet 방식을 사용하는 single cell anlaysis는 필연적으로 doublelets 문제를 나타내는 것으로 알려져 있는데, cell loading 개수에 따라 그 비율이 증가한다고 알려져 있습니다.Sequencing Depth for scRNAseqhttps://www.edwith.org/single-cell/joinLectures/361836Single call analysis에 적당한 sequencing depth를 찾기 위한 data입니다. 약 30,000~50,000x에서 적당한 genes 개수와 umi 수를 확인할 수 있습니다. 물론 적당한 depth 또한 tissue types에 따라 달라질 수 있음을 고려해야 합니다.또한 흥미로운 사실은 86,503x data에서 확인된 네 개의 cell clustering 결과가 25,000x, 5,000x, 500x로 줄였을 때 변함없이 네 개의 cluster가 나타남을 봤을 때 depth가 cell clustering에는 별다른 영향을 주지 않음을 확인할 수 있습니다.Chanllenges and Future Direction for scRNAseq The sparsity of data Transcript가 적으므로 data signal보다는 noise가 더 많이 나타나는 문제가 있습니다. 따라서 발현량이 0인 gene을 다수 나타납니다. 이는 RNA capture 효율과 cDNA conversion의 문제로 나타난 결과입니다. Batch effect 실험자, 어떤 연구실에서 실험했는지, 혹은 어떤 실험조건으로 진행했는지 등에 따라서 batch effect가 발생할 수 있습니다. 이는 computational method나 서로 다른 샘플을 multiplexing하여 해결할 수 있습니다. Integration of Single Cell Multi-omics Datahttps://www.edwith.org/single-cell/joinLectures/361836미래에는 single cell isolation 이후 genomics부터 metabolomics까지 다양한 multi-omics data를 분석하고 활용할 수 있을 것입니다.Take Home MessageSingle cell analysis의 원리와 활용 가능성에 대해 알아볼 수 있었습니다. 현재 업무에서 사용중인 genomics data와 disease, treatment와 연관된 database들이 scRNAseq 결과와 결합한다면 personalized medicine에 활용될 수 있음을 엿볼 수 있었습니다." }, { "title": "Variants Analysis II", "url": "/posts/Variants_Analysis_II/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, next generation sequencing, variant, calling", "date": "2022-09-27 08:15:04 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 연세대학교 의과대학 김상우 교수님의 NGS 데이터 분석 기초 강의를 정리한 내용입니다.IntroNGS를 이용한 somatic mutation 탐지 방법을 알아봅니다. 또한 low allele frequency mutation, mosaic mutation과 같이 검출하기 어려운 mutation에 대해 알아봅니다.Germline vs Somatic MutationGermline vs Somatic MutationGermline mutation은 생식세포에서 발생한 mutation으로 사람이 성장하면서 모든 cell이 mutation을 공유합니다.반면 Somatic mutation은 체세포에서 발생한 mutation으로 사람의 일부 cell만 mutation을 가지고 있습니다.Variant Allele FrequencyVariant Allele FrequencyTumour가 발달하면서 여러 개의 subclone으로 나뉠 수 있습니다. 그림에서 subclone1과 subclone2에서 공통적으로 나타나는 노란색 mutation은 common somatic mutation으로 high-allelic frequency를 보입니다. 반면에 subclone2에서만 나타나는 하얀색 mutation은 specific somatic mutation으로 low-allelic frequency를 보입니다.해당 tumour를 sequencing 했을 때 read의 구성은 오른쪽 그림과 같습니다. Common mutation은 모든 read에서 확인되는 반면, subclone-specific mutation은 일부 read에서만 확인됩니다.Somatic Mutation Analysis: JointSNVMixJointSNVMixhttps://doi.org/10.1093/bioinformatics/bts053University of British Columbia의 Shah Lab에서 제안한 Joint Genotype Prbability로 somatic mutation analysis 방법 중 하나입니다. (Andrew Roth et al., JointSNVMix : A Probabilistic Model For Accurate Detection Of Somatic Mutations In Normal/Tumour Paired Next Generation Sequencing Data)동일한 position에서 tumour와 matched normal의 allele을 모두 고려하여 somatic mutation을 찾습니다. 사람은 diploid이며 이론상 하나의 position에서 나올 수 있는 genotype은 A, B만 있다고 가정하면, 가능한 genotype은 AA, AB, BB입니다. Tumour와 normal에서 총 아홉 가지의 genotype 조합이 가능합니다. 그리고 각 조합이 의미하는 바는 아래와 같습니다. Somatic mutation은 (AA,AB), (AA,BB)인 경우입니다.JointSNVMixhttps://doi.org/10.1093/bioinformatics/bts053각 position에서 allele을 count한 다음 아래와 같이 두 가지 확률 모델을 사용하여 확률적으로 가능성이 높은 genotype을 결정합니다. 각 node에 대한 설명은 논문(Andrew Roth et al., JointSNVMix : A Probabilistic Model For Accurate Detection Of Somatic Mutations In Normal/Tumour Paired Next Generation Sequencing Data)을 참고해 주세요.JointSNVMixhttps://doi.org/10.1093/bioinformatics/bts053마지막으로 JointSNVMix의 성능평가 결과입니다. 그 외 caller들은 성능평가를 위해 변형하거나 사용한 다른 방식의 somatic mutation analysis입니다. JointSNVMix가 F-measure, MCC(Matthews Correlation Coefficient)에서 가장 우수한 결과를 보입니다.JointSNVMixhttps://doi.org/10.1093/bioinformatics/bts053Somatic Mutation Analysis: MuTectMuTect2https://doi.org/10.1093/bioinformatics/bts053MuTect2는 Broad Institute에서 개발한 somatic variants caller입니다. Baysian classifier를 사용하며 대상 position에서 variant가 없다고 가정($M_{0}$)하고 구한 확률과 varinat가 있다고 가정($M_{f}^{m}$)하고 구한 확률을 비교하여 더 가능성이 높은 쪽을 택하는 방식입니다. 이후에 다양한 방식의 variant filters를 거쳐 FP를 제거하고, normal 사람들을 sequencing하여 얻은 변이(MAF)를 제거한 뒤 candidate somatic mutations를 추립니다.br&amp;gt;저빈도 변이와 모자이크 변이Mosaic Variantshttps://doi.org/10.1093/bioinformatics/bts053Mosaic은 한 개체 또는 한 지역 내에 서로 다른 유전형이 함께 공존하는 것을 의미합니다. 비교적 이른 시기에 발생한 mutation은 많은 세포가 mutation을 공유하게되고, 비교적 늦은 시기에 발생한 mutation은 상대적으로 일부 세포만 mutation을 공유하게 됩니다.Liquid Biopsyhttps://doi.org/10.1093/bioinformatics/bts053혈액 내 미세하게 떠다니는 DNA를 뽑아서 sequencing하고 mutations를 확인하는 기술입니다. 일례로 산모의 혈액에는 태아의 DNA가 떠다니는데 이를 뽑아서 genotype을 확인하여 태아의 건강을 확인합니다.Unique Molecular Identifierhttps://doi.org/10.1093/bioinformatics/bts053저빈도 변이를 calling할 때 발생하는 error들을 제거하기 위해 UMI를 사용합니다. 원본 DNA fragment마다 고유한 index를 붙이고, duplicate를 제거할 때 동일한 UMI를 가진 duplicate들만 모아서 PCR error로 추정되는 mutation은 제거합니다.이 밖에도 liquid biopsy는 variant 찾는 것이 매우 어려우므로 다양한 기술이 개발 중에 있습니다.Take Home MessageSomatic variants call 과정과 저빈도, 모자이크 변이에 대해 이해할 수 있었습니다." }, { "title": "(EDWITH-KOBIC) 예제 데이터를 활용한 전사체 데이터 분석", "url": "/posts/Certificate_Transcriptome_analysis_with_example/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, transcriptome, RNAseq, KOBIC", "date": "2022-09-26 12:14:32 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 비정형 데이터 분석", "url": "/posts/Certificate_data_analysis/", "categories": "Study, L-Certificate", "tags": "certificate, data analysis, CUK", "date": "2022-08-31 08:10:10 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 머신러닝 빅데이터 분석", "url": "/posts/Certificate_ML_bigdata/", "categories": "Study, L-Certificate", "tags": "certificate, ML, CUK", "date": "2022-08-31 08:07:21 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 선형대수로 배우는 빅데이터", "url": "/posts/Certificate_bigdata_by_linear_algebra/", "categories": "Study, L-Certificate", "tags": "certificate, linear algebra, CUK", "date": "2022-08-31 08:05:02 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 빅데이터를 위한 확률과 통계", "url": "/posts/Certificate_statistics_for_bigdata/", "categories": "Study, L-Certificate", "tags": "certificate, statiatics, CUK", "date": "2022-08-31 08:02:15 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(EDWITH-KOBIC) R을 활용한 데이터 분석(중급)", "url": "/posts/Certificate_R_data_analysis/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, R, data science, KOBIC", "date": "2022-08-30 12:11:03 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(EDWITH-KOBIC) 단일세포 분석", "url": "/posts/Certificate_Singlecell/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, singlecell, KOBIC", "date": "2022-08-17 08:22:14 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "Variants Analysis I", "url": "/posts/Variants_Analysis/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, next generation sequencing, variant, calling", "date": "2022-08-11 07:52:13 +0900", "snippet": "Variants TypesDNA 서열에서 다양한 종류의 변이가 나타날 수 있으며, 일부 변이는 암, 유전성 질환과 연관되어 있습니다. Variants Types Description Substitution - Missense Coding region에서 nucleotide의 substitution으로 나타나는 variants. 그 결과 region이 coding하는 amino acid가 다른 amino acid로 바뀜 Substitution - Nonsense Coding region에서 nucleotide의 substitution으로 나타나는 variants. 그 결과 region이 coding하는 amino acid가 stop codon으로 바뀌고 protein의 기능에 영향을 줌 Insertion 한 개 이상의 nucleotides가 추가된 variants. 그 결과 protein이 적절한 기능을 하지 못하도록 영향을 줄 수 있음 Deletion 적어도 한 개 이상의 nucleotides가 삭제된 variants. 그 결과 protein이 적절한 기능을 하지 못하도록 영향을 줄 수 있음 Deletion-Insertion(delins), Insertion-Deletion(indel) Deletion과 Insertion이 같은 시간 같은 region에서 일어난 variants. 그 결과 protein이 적절한 기능을 하지 못하도록 영향을 줄 수 있음 Duplication 한 개 이상의 nucleotides가 복제되거나 반복되어 나타나는 variants. 그 결과 protein이 적절한 기능을 하지 못하도록 영향을 줄 수 있음 Inversion Original sequence 상에서 한 개 이상의 nucelotides가 reverse 방향으로 대체된 variants. Frameshift 한 개 이상의 nucleotides가 추가되거나 삭제되어 codon 서열을 변경시키는 variants. 그 결과 protein이 적절한 기능을 하지 못하도록 영향을 줄 수 있음 Substitution - Missensehttps://medlineplus.gov/genetics/understanding/mutationsanddisorders/possiblemutations/Substitution - Nonsensehttps://medlineplus.gov/genetics/understanding/mutationsanddisorders/possiblemutations/Insertionhttps://medlineplus.gov/genetics/understanding/mutationsanddisorders/possiblemutations/Deletionhttps://medlineplus.gov/genetics/understanding/mutationsanddisorders/possiblemutations/Duplicationhttps://medlineplus.gov/genetics/understanding/mutationsanddisorders/possiblemutations/Frameshifthttps://medlineplus.gov/genetics/understanding/mutationsanddisorders/possiblemutations/Variants ErrorVariants Errorhttps://www.edwith.org/ngs-data-variation/lecture/1382349?isDesc=falseReference genome과 다른 bases로 확인된 variants의 대부분이 사실 sequencer error입니다. 여기에서 최종 driver somatic mutations로 남는 variants를 선별하는 것은 까다로운 과정입니다. 따라서 처음에 called variants에서 sequencer error를 찾고 제거하는 과정은 매우 중요합니다.Sequencer error를 제거하기 위해서 특정 region을 여러 번 반복해서 sequencing 합니다. 이를 정량화한 값을 read depth라고 부르는데, 특정 영역을 지나는 read의 수를 count한 값 입니다. 이처럼 특정 region을 반복해서 시퀀싱하면 sequencer error가 발견되더라도 이를 error로 분류할 가능성이 높아집니다.또한 basecall error를 정량화한 수치인 phred score를 사용하여 sequencer error를 찾아낼 수 있습니다. 이 수치는 basecall이 틀렸을 확률 e에 대해 $-10log_{10}$을 대입한 값을 의미합니다. 10, 20, 30, 40 값이 각각 basecall 틀렸을 확률 10%, 1%, 0.1% 0.01%를 의미합니다.Mapping error를 정량화한 수치인 MapQ를 사용하여 mapping error를 가늠해 볼 수 있습니다. 마찬가지로 mapping이 틀렸을 확률 e에 대해 $-10log_{10}$을 대입한 값을 의미합니다. 예를 들어 하나의 read가 여러 곳에 mapping 될 수 있다면 e가 증가하는 등 여러가지 근거에 기반하여 MapQ를 계산합니다.Variants CallingVariants error를 확인할 수 있는 수치들을 기반으로 sequencing 결과 관찰된 variants가 true positive인지 error인지 판단합니다. 아래와 같이 reference sequence가 T인 position에서 다섯 개의 read가 mapping된 상황을 가정해 봅니다. 네 개 read는 T, 한 개 read는 G이고 각각 basecall quality와 mapping quality가 표기되어 있습니다.Variants Callinghttps://www.edwith.org/ngs-data-variation/lecture/1382349?isDesc=false사람의 genome은 diplod이므로 하나의 position에서 두 개의 allele이 존재합니다. A, T, C, G 네 개의 base가 있으므로 경우의 수를 따지면 총 16가지 조합이 가능합니다. Reference sequence와 동일할 때 A, 동일하지 않을 때 B라고 지칭하면 경우의 수는 4가지 조합으로 단순화 할 수 있습니다.Simplify Genotypinghttps://www.edwith.org/ngs-data-variation/lecture/1382349?isDesc=false다시 처음에 가정한 상황으로 돌아와서 genotyping을 단순화 했습니다. 이제 B가 true positive인지, 혹은 error로 인한 false positive인지 검증하는 단계입니다.Simplify Genotypinghttps://www.edwith.org/ngs-data-variation/lecture/1382349?isDesc=false여기부터 확률 개념이 사용됩니다. 사람의 유전체는 diploid이므로 해당 위치의 genotype은 AA or AB or BB 중 하나가 될 수 있습니다. Pr(G=AA) or Pr(G=AB) or Pr(G=BB) 중 가장 확률이 높은 genotype으로 추론하는 것이 바람직 합니다. 이 과정에 sqeuncing data를 활용할 수 있습니다. 즉, data가 주어졌을 때 각 genotype을 얻을 수 있는 확률은 Pr(G=AA|D) or Pr(G=AB|D) or Pr(G=BB|D)로 계산할 수 있습니다. 확률을 바로 계산하기 어려우므로 bayes rule을 활용합니다.\\[Pr(G|D) = \\frac{Pr(G,D)}{Pr(D)} = \\frac{Pr(D|G)Pr(G)}{Pr(D)}\\] 위 식에서 $$ Pr(D G) $$를 계산해 봅시다. 즉, genotype이 주어진 상태에서 data가 확인될 확률을 구하는 것입니다. 첫 번째 자리의 base는 ‘A’이며 base quality는 ‘+’입니다.Genotype을 ‘AA’라고 가정할 때, ‘A’가 sequencing될 확률은, P(1-e) 입니다.Genotype을 ‘AB’라고 가정할 때, ‘A’가 sequencing될 확률은 error없이 ‘A’가 읽힐 확률 \\(\\frac{1}{2}*P(1-e)\\)와 ‘B’가 error에 의해 ‘A’로 읽힐 확률 \\(\\frac{1}{2}*\\frac{1}{4}*P(e)\\)를 더한 값 입니다.Genotype을 ‘BB’라고 가정할 때, ‘A’가 sequencing될 확률은 error에 의해 ‘A’로 읽힐 확률 \\(\\frac{1}{4}*P(e)\\)입니다.세 번째 자리의 base ‘B’에 대한 Pr(D|G)도 마찬가지로 계산할 수 있습니다.Calculation of Pr(D|G)https://www.edwith.org/ngs-data-variation/lecture/1382349Take Home MessageNGS DNA variants 종류와 genotyping logic을 이해할 수 있었습니다." }, { "title": "(EDWITH-KOBIC) WES 기초편", "url": "/posts/Certificate_WES_basic/", "categories": "Study, L-Certificate", "tags": "certificate, WES, KOBIC", "date": "2022-07-26 17:09:25 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "WES Clinical Interpretaion II", "url": "/posts/WES_Clinical_Interpretaion_II/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, NGS, WES, interpretation", "date": "2022-07-26 11:32:23 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 의과대학 최무림 교수님의 WES 기초편 강의를 정리한 내용입니다.IntroWES 분석을 통한 환자의 진단, 후속 단계에 대한 이해를 통하여 WES 분석의 효용성을 극대화 할 수 있음을 이해합니다. WES에 의한 진단률을 최대화 할 수 있는 방법을 제시합니다.Undiagnosed Disease by WES - US Undiagnosed Disease Network in US www.edwith.org/wes-beginnerUDN(Undiagnosed Disease Network)는 미국에서 진단이 어려운 환자들 대상으로 다양한 방법을 통해 진단하기 위해 노력하는 단체입니다. 601명의 환자들이 UDN을 통해 진단되었고 그 중 382명은 WES를 시행한 case입니다. Undiagnosed Disease Network in US www.edwith.org/wes-beginner382명 중 약 35% 환자가 진단받았는데, 그 중 8%는 WES 재분석을 통해 진단되었습니다. 참고로 환자 1명 당 UDN을 통한 진단 비용은 평균 18,903 USD 입니다.Practical DatabasesWES 결과를 해석하는데 유용한 database들이 있습니다.GeneMatcher는 앞서 다른 강의에서 본 것 처럼 협력/공동연구로 확장하는데 도움이 됩니다.ClinVar는 submitted/published variants나 diseases를 검색할 수 있는 database입니다.OMIM(Online Mendelian Inheritance in Man)은 gene과 disease의 관계를 확인할 수 있는 database입니다.WES 효율 최적화하기WES를 통해 phenotype과 disease 사이 관계를 밝혀내는 것은 유용하지만 아직 문제가 되는 것은 진단률이 떨어진다는 사실입니다. 아래와 같은 내용이 원인입니다. 진단률을 떨어뜨리는 원인 www.edwith.org/wes-beginnerSequencing, analysis와 관련된 technical issue가 있습니다.기본적으로 symptom은 genetic origin이 아니며, 환자의 나이가 증가하면서 symptom이 변화하는 등 clinical issue가 있습니다.마지막으로 variant의 존재는 확인했으나 어떤 function을 하는지 완전히 알지 못하는 genetic issue가 있습니다.이런 issue를 극복하기 위해 WES re-analysis, WGS, RNA-seq 등을 시도할 수 있습니다. 이 때 각 방법의 장단점을 이해하고 얼마나 효율적인 결과를 가져올 수 있을지 충분히 예상한 뒤 시도하는 것이 좋습니다.Summary WES 발견은 환자들에게 다양한 범위의 혜택을 부여할 수 있습니다. 이후 GeneMatching, ClinVar, OMIM 등의 database 도움을 받을 수 있습니다. 적극적인 유전자 조절 약물 시도를 해볼 수 있습니다. WGS/RNA-seq 등의 방법도 적절하게 사용 가능합니다." }, { "title": "WES Clinical Interpretaion I", "url": "/posts/WES_Clinical_Interpretaion_I/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, NGS, WES, interpretation", "date": "2022-07-26 08:13:52 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 의과대학 최무림 교수님의 WES 기초편 강의를 정리한 내용입니다.IntroWES 분석 전 환자의 임상 정보를 이해합니다. 환자의 임상 자료에서 WES 분석에 필요한 정보를 획득합니다. Known/Novel/Unknown case로 구분하여 실제 WES 결과와 비교합니다.Diagnostic Yield of WES 1,000 Mendelian Disorder Patients from Saudi Arabia www.edwith.org/wes-beginnerSaudi Arabia에서 수행된 1,000명의 환자 대상으로 gene panel과 WES 분석을 수행한 결과입니다. Gene panel보다 WES에서 positive가 더 많이 나온 것을 알 수 있습니다. 또한 Positive case에서 recessive variants가 2/3정도를 차지하는데, Saudi Arabia는 중동에 위치하며 근친혼이 많이 일어나고 있으므로 recessive variants가 다수를 차지함을 추정해 볼 수 있습니다. 1,000 Mendelian Disorder Patients from Germany www.edwith.org/wes-beginnerGermany에서 수행된 1,000명의 환자 대상으로 WES 분석을 수행한 결과입니다. HPO는 human phenotype ontology의 약자로 환자의 phenotype들을 모아놓은 term입니다. 그래프에서 환자의 phenotype 숫자가 증가할수록 positive case도 증가함을 볼 수 있습니다. 이유로는 첫째로 다양한 phenotype을 보이면서 더 심각한 증상을 보이는 환자가 유전적으로 disease를 물려받아 나타날 가능성이 크기 때문입니다. 둘째로 하나의 phenotype을 가진 환자보다는 다양한 phenotype을 가진 환자가 상대적으로 연구결과가 많으므로 positive case로 판정할 수 있는 기회도 늘어나기 때문입니다.따라서 환자에 대한 풍부한 임상자료가 존재할 때, 그리고 더 심각한 증상을 가지고 있을 때 WES의 genotype 결과와 mendelian disorder를 연결짓는데 성공할 가능성이 높다는 것을 알 수 있습니다. 진단률을 향상시키려면? 진단률을 향상시키기 위한 방법 www.edwith.org/wes-beginner분석 방법을 확장시킬 수 있습니다. 왼쪽 그래프를 보시면 mitochondrial variants, breakpoint analysis 등 분석 방법을 확장해서 약 4.2% positive case가 증가한 것을 확인할 수 있습니다.또한 재분석을 할 수 있습니다. 오른쪽 그래프를 보시면 2014년 분석결과와 비교해서 2017년 분석결과의 diagnostic 숫자가 증가한 것을 볼 수 있습니다. 시간이 지나면서 분석 파이프라인과 database가 업그레이드 되어 향상된 결과를 가져올 수 있습니다. 진단률을 향상시키기 위한 방법 www.edwith.org/wes-beginner또한 WGS를 수행할 수 있습니다. 하지만 효율성이 떨어집니다. WES로 진단하지 못한 108명 환자 중 WGS로 진단한 환자는 3명 이었습니다. 이는 WES 재분석을 통해 추가 진단한 4명과 비교해서 효율성이 떨어집니다.RNA-seq을 통해서 추가로 진단에 성공한 환자가 일부 있습니다. RNA-seq도 진단에 도움을 줄 수 있습니다.Known CasesWES 분석을 통해 기존에 알려진 병인 genes 혹은 variants를 발견하여 질병 원인을 명확히 밝힌 경우를 알아봅시다. Known Case 1: 임상정보 www.edwith.org/wes-beginner32개월 남아입니다. 관찰되는 임상적 symptoms를 이해하는 것이 중요합니다. 이전 테스트 결과들도 이해하는 것이 중요합니다. 이 자료들을 토대로 diagnostic이 어려운 상태이므로 WES를 진행하고 분석합니다. Known Case 1: WES 분석결과 www.edwith.org/wes-beginner2개의 de novo variants, 1개의 homozygous variants, 2개의 hemizygous variants가 확인됩니다. DHDH gene의 homozygous variants를 보면 mom은 ref homo, dad는 hetero 결과를 보입니다. 두 가지 가설을 생각해 볼 수 있는데, 첫째는 mom에서 alt allele에 deletion이 일어난 경우입니다. 둘째는 mom의 난자에서 de novo variant가 생성되고 mom의 alt allele과 dad의 alt allele이 만나서 자녀의 homozygous variant가 발생한 경우입니다. 확률적으로는 전자의 가능성이 더 높습니다.다섯 개 vairnats 중 MRAS gene의 de novo variant가 임상적으로 Noonan syndrome과 연관되어 있음이 확인되었습니다. 이는 previous test에서 Noonan gene test 결과와 같고 관련된 symptoms도 확인됩니다. 또한 MRAS gene이 Noonan syndrome과 연관되어 있다는 논문도 추가로 확인됩니다. 따라서 환자는 Noonan syndrome으로 진단할 수 있습니다.Novel/Unknown CasesKnown case에서 candidate variants 및 genes이 나왔을 때, disease와의 관계나 과거 연구결과가 없다면 novel case가 됩니다. 이 때 GeneMatching을 통해 후속 협력/공동 연구가 진행된다면 novel case, 진행되지 않는다면 unknown case로 분류됩니다.Summary Known case는 환자 특이적 de novo 혹은 recessive variants가 비슷한 증상을 보이는 patients에게서 기존 보고가 되어 있을 경우(OMIM, 논문 등)에 해당합니다. 유전학, 다양한 분야의 생물학, 의학적인 시직을 통합하여 병인이 되는 variants를 탐색할 수 있어야 합니다. 적극적인 sequencing, 국제 공동연구가 활발히 일어나야 합니다." }, { "title": "WES Structural Variants", "url": "/posts/WES_structural_variants/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, NGS, WES, structural variant, CNV", "date": "2022-07-25 16:01:05 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 의과대학 최무림 교수님의 WES 기초편 강의를 정리한 내용입니다.IntroSV(Structural Variant)의 형태와 의미를 이해합니다. SV 탐색을 위한 소프트웨어들을 알아봅니다.De novo SV De novo SV www.edwith.org/wes-beginner왼쪽 그래프에서 probands는 patient, siblings는 control입니다. C, F 그래프를 보면 De novo rare CNV로 인해 probands도 증가함을 확인할 수 있습니다.오른쪽 그래프에서도 마찬가지로 5~10%의 환자가 de novo SV를 가지고 있음을 확인 했습니다. Calling SVs Algorithms of gnomAD www.edwith.org/wes-beginnerDe novo SVs calling 소프트웨어는 굉장히 다양합니다. MAF Database인 gnomAD도 네 가지 algorithm으로 SV를 분석한 뒤 교집합인 SV를 사용하고 있습니다. 왜 네 가지 algorithm을 사용했는지 이어서 확인해 보겠습니다.SV Calling Algorithms SV Calling Algorithms for Deletion www.edwith.org/wes-beginnerDeletion SV calling algorithms는 다음과 같이 여러 종류가 존재합니다. RP (Read Pair) Paired-end sequencing 결과로 나온 r1, r2 read 사이의 insert size로 추정합니다. 예상되는 insert size (150bp~300bp)보다 훨씬 더 긴 길이를 보인다면 deletion이 존재함을 추정할 수 있습니다. SR (Split Read) Read 하나가 split되어 mapping 된다면 역시 deletion이 존재함을 추정할 수 있습니다. RD (Read Depth) Deletion이 발생한 region은 주변에 비해 read depth가 낮습니다. AS (Assembly) Short read들을 모아서 assembly하여 deletion이 일어난 retion을 추정할 수 있습니다. Combination RP+SR, RP+RD, RP+AS, RP+SR+AS, RP+SR+RD 등 다양한 조합의 algorithms로 SV를 찾아낼 수 있습니다. SV Calling Algorithms for Insertion www.edwith.org/wes-beginnerInsertion SV calling algorithms는 다음과 같이 여러 종류가 존재합니다. RP (Read Pair) Paired-end sequencing 결과로 나온 r1, r2 read가 mapping되는 양상으로 insertion을 추정합니다. Paired-end read 중 하나는 reference에 mapping되고(one end anchor read) 나머지 read는 insert region에 mapping 됩니다.(full orphan read) SR (Split Read) One end anchor read가 split되어 mapping 된다면 역시 insertion이 존재함을 추정할 수 있습니다. RD (Read Depth) Insertion은 RD로 확인할 수 없습니다. Insert region을 읽은 read는 mapping 될 수 없고 일부 걸친 read만 mapping 가능하기 때문입니다. 즉, RD의 차이가 거의 없습니다. 이 외에도 Tandem duplication, Interspersed duplication, Inversion, Translocation, Novel sequence insertion, Mobile-element insertion 등의 SVs가 존재합니다.SVs callling algorithms 유형별 장단점은 아래와 같습니다. RD가 직관적이며 빠르고 쉽게 해석 가능하지만 resolution이 가장 낮습니다. RP, SR, AS로 갈수록 resolution은 늘어나지만 conputation resource가 많이 소모됩니다. 또한 공통적으로 repeat region에서의 SV calling은 어렵고 false positive ratio가 증가하므로, 소프트웨어에서 나온 SV result를 IGV 등을 통해 직접 repeat region 여부와 FP 가능성 확인이 필요합니다. SV Calling Algorithms: Pros &amp;amp; Cons www.edwith.org/wes-beginnerAlgorithms 유형별 소프트웨어 종류는 다음과 같습니다. Bold체 네 개 소프트웨어는 gnomAD에서 사용한 네 가지 소프트웨어입니다. RP(Read Pair): 1-2-3-SV, BreakDancer, Ulysses SR(Split Read): Pindel, SVseq2, Sprites RD(Read Depth): BICseq2, CNVantor, PennCNV-seq, cn.MPOS, readDepth AS(Assembly): laSV, FermiK, BreakSeek RP+SR: SoftSV, Wham, DELLY, Meerkat, MELT, PRISM RP+RD: inGAP-sv, GASVPro, forests RP+AS: Hydra, CREST RP+SR+AS: GRIDSS, Manta, SvABA RP+SR+RD: Lympy, MATOHCUP, TIDDIT, Svelter소프트웨어별 SV 결과의 bias 편차가 심하기 때문에 biasgnomAD는 네 개 소프트웨어를 사용하여 편차를 줄였습니다. 이처럼 multi-platform 방식으로 보완이 가능합니다.Manta: De novo Deletion Result Manta: De novo Deletion www.edwith.org/wes-beginnerManta 소프트웨어로 분석한 결과 중 de novo deletion을 IGV로 확인한 결과입니다. De novo deletion이 존재하는 region에서 soft-clipped reads가 확인됩니다. Manta: De novo Deletion www.edwith.org/wes-beginnerInsert size 크기로 coloring한 뒤 sorting한 결과입니다. 마찬가지로 de novo deletion이 존재하는 region에서 insert size가 큰 reads가 확인됩니다.Summary SV는 비록 많은 비율은 아니지만 대부분의 disease 유발 인자로 생각되고 있습니다. SV calling은 SNV보다 어렵고 독립적인 algorithm을 사용해야 합니다. SV calling 결과에 대한 후속 확인이 필수적입니다." }, { "title": "WES Recessive Variants", "url": "/posts/WES_recessive_variants/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, NGS, WES, recessive", "date": "2022-07-25 14:01:21 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 의과대학 최무림 교수님의 WES 기초편 강의를 정리한 내용입니다.IntroCompound geterozygous, rare homozygous, hemizygous variants 의미를 이해합니다. 각 recessive variants에 맞는 filtering criteria를 이해합니다.Trio-based Mendelian Disorder Research Trio-based Mendelian Disorder www.edwith.org/wes-beginner1번 pedigree는 부모 한 쪽에 dominant variant를 가지고 있어서 자녀에게도 disease가 유전된 경우를 보여주고 있습니다.2번 pedigree는 부모 모두 하나의 allele에 variant를 가지고 있는 보인자 상태이고 자녀에게 variant를 가진 allele들이 유전되어 disease가 발현된 경우를 보여주고 있습니다.3번 pedigree는 부모 모두 variant가 없고 정상이지만 자녀에게서 dominant variant가 발생하여 disease가 발현된 경우를 보여주고 있습니다.1번, 3번 pedigree는 dominant variants 경우를, 2번은 recessive variants 경우를 보여주고 있습니다.Dominant vs Recessive Dominant vs Recessive www.edwith.org/wes-beginnerDominant variants인 De novo variants와 De novo CNV(structural variants)가 약 2/3 가량, recessive variants인 나머지가 약 1/3 가량을 차지합니다.Recessive variants는 오른쪽 그림과 같이 여러 가지 종류로 분류합니다. Compound Heterozygous는 두 개 variants가 멀리 떨어져 있는 경우 short read length의 illumina sequencer로는 in trans와 in cis를 구분하기 어렵습니다. 구분이 필요한 경우 long read를 사용하는 PacBio와 같은 sequencer로 해당 region을 sequencing 해야합니다. Heterozygous: 두 개 allele 중 하나의 allele에 variants가 존재하는 경우입니다. Homozygous: 두 개 allele 모두 같은 위치에서 variants가 존재하는 경우입니다. Compound Heterozygous (in trans): 하나의 gene에 두 개의 서로 다른 position에서의 variants가 각각 다른 allele에 존재하는 경우입니다. Compound Heterozygous (in cis): 하나의 gene에 두 개의 서로 다른 position에서의 variants가 동일한 allele에 존재하는 경우입니다. Dominant vs Recessive www.edwith.org/wes-beginnerImportance of Understanding Recessive Variants Importance of Understanding Recessive Variants www.edwith.org/wes-beginnerRecessive variants가 유발하는 대표적인 disease로 $\\beta$-thalassaemia와 Ty-Sachs disease가 있습니다. 각각 HBB, HEXA gene의 variants로 유발되는 disease이며 specific population에서 높은 발병률을 보입니다. 어떤 recessive variants가 disease를 유발하는지 이해한 뒤로 보인자인 남녀가 결혼을 하거나 자녀를 출생하기 전 자녀의 disease 발병을 예방할 수 있습니다. 그래프에서 시간이 지남에 따라 $\\beta$-thalassaemia의 새로운 환자 발병률이 점점 감소하는 것으로 볼 수 있습니다.실제로 Myriad사에서는 Foresight Carrier Screen 서비스를 제공하고 있습니다. 175개 이상의 genetic diseases 대상으로 남녀의 carrier 보유 여부를 검사하고 결과를 제공합니다.Call Compound Heterozygous Variants Check reference coverage and non-reference coverage and calculate minor allele frequency(MAF) $MAF = \\frac{non-ref coverage}{(ref coverage + non-ref coverage)}$ MAF should be approximately 0.5 higher coverage the better Check allele frequencies(AF) of genome databases like gnomAD, ExAC, 1000 genome, etc 다수의 정상인이 보유하고 있는 variants라면 disease를 유발할 가능성이 떨어집니다. 따라서 위와 같은 정상인 variants database에서 AF 0.01보다 작은 variants를 선별합니다. One mutation should come from paternal. Another from maternal. Call Rare Homozygous Variants Check reference coverage and non-reference coverage and calculate minor allele frequency(MAF) $MAF = \\frac{non-ref coverage}{(ref coverage + non-ref coverage)}$ MAF should be very close to 1 higher coverage the better Check allele frequencies(AF) of genome databases like gnomAD, ExAC, 1000 genome, etc 다수의 정상인이 보유하고 있는 variants라면 disease를 유발할 가능성이 떨어집니다. 하지만 정상인이 보유하고 있는 variants가 recessive 형태일 수 있고 결과적으로 환자가 가진 homozygous 형태에서는 AF가 그보다 높게 나타날 수 있습니다. 따라서 AF가 낮되 다른 recessive variants와 비교해서는 너무 낮지 않도록 고려합니다. Call Hemizygous Variants Check reference coverage and non-reference coverage and calculate minor allele frequency(MAF) $MAF = \\frac{non-ref coverage}{(ref coverage + non-ref coverage)}$ MAF should be approximately 1 higher coverage the better Check allele frequencies(AF) of genome databases like gnomAD, ExAC, 1000 genome, etc 다수의 정상인이 보유하고 있는 variants라면 disease를 유발할 가능성이 떨어집니다. 따라서 위와 같은 정상인 variants database에서 AF 0.01보다 작은 variants를 선별합니다. Should be very conserved Check the number of different amino acid among species Summary Recessive pattern을 따르는 variants는 Mendelian Disorder의 주요 병인으로 작용합니다. Recessive pattern을 따라는 variants 종류로는 homozygous, compound heterozygous, hemizygous variants가 있습니다." }, { "title": "WES Dominant Variants", "url": "/posts/WES_dominant_variants/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, NGS, WES, dominant", "date": "2022-07-25 11:42:19 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 의과대학 최무림 교수님의 WES 기초편 강의를 정리한 내용입니다.IntroDe novo variant에 대해 이해하고 true/false call 여부를 판단할 수 있습니다. Trio-based WES 데이터에서 dominant pattern으로 유전되는 variants를 탐색합니다.Trio-based Mendelian Disorder Research Trio-based Mendelian Disorder www.edwith.org/wes-beginner1번 pedigree는 부모 한 쪽에 dominant variant를 가지고 있어서 자녀에게도 disease가 유전된 경우를 보여주고 있습니다.2번 pedigree는 부모 모두 하나의 allele에 variant를 가지고 있는 보인자 상태이고 자녀에게 variant를 가진 allele들이 유전되어 disease가 발현된 경우를 보여주고 있습니다.3번 pedigree는 부모 모두 variant가 없고 정상이지만 자녀에게서 dominant variant가 발생하여 disease가 발현된 경우를 보여주고 있습니다.1번, 3번 pedigree는 dominant variants 경우를, 2번은 recessive variants 경우를 보여주고 있습니다.De novo Variants De novo Variants www.edwith.org/wes-beginner생식세포에서 variants가 발생하면 그림에서와 같이 세 가지 case 중 하나로 귀결됩니다. 생존에 위협이 되는 등 deleterious case에 해당한다면 negative selection에 의해서 사라지게 됩니다. 반면 advantageous case에 해당한다면 positive selection에 의해서 대대로 유전되게 됩니다. 북유럽 인종에서 lactase(lactose를 분해할 수 있는 효소)를 분비하도록 variants가 발생했는데 오늘날 대부분의 북유럽 사람들이 lactase를 분비하는 것이 하나의 advantageous case 예시입니다. De novo Variants www.edwith.org/wes-beginner앞서 본 그림에서와 같이 de novo variants를 표현한 pedigree 입니다. 1번, 2번 case는 충분히 true de novo variants로 추정할 수 있습니다. 2번의 Mom:AA에서 확인된 1개의 alt allele은 illumina sequencer의 error로 감안할 수 있습니다. 하지만 3번은 Mom, Dad, Offspring 모두에서 소수의 alt allele이 확인되었고 mismapping에 의한 false call로 추정할 수 있습니다. 4번은 low coverage로 인해(최소 10x 이상 권장) false call로 추정할 수 있습니다.Call De novo Variants어떤 variants가 de novo variants인지 판단하는 기준은 크게 두 가지로 나타낼 수 있습니다. Inheritance pattern에 따른 filtering 앞서 본 trio-based de novo variants에서 세 번째 pedigree에 해당하는 경우입니다. 즉, 부모에게서는 disease와 variants가 없는데 자녀에게서 variants가 존재하고 disease로 발병한 case입니다. Variant’s annotation information에 따른 filtering Effect of variants: missense, nonsense, frameshift, splicing variant와 같은 effect를 가진 경우 pathogenic variants일 가능성이 높습니다. Amino acid conservarion score: 진화적인 관점에서 서로 다른 종이더라도 비슷한 역할을 하는 protein sequence는 서로 유사성(homology)를 가집니다. 일반적으로 중요한 기능을 수행하는 region의 amino acid는 conserved sequence로 되어 있는 경우가 많습니다. 따라서 amino acid conservation score가 높을수록 해당 variants가 deleterious case일 가능성이 높습니다. Variant’s allele frequency in healthy population: 건강한 사람들이 가지고 있는 variants는 disease를 유발할 가능성이 낮습니다. AF &amp;lt; 0.001 기준으로 variants를 filtering 할 수 있습니다. 관련된 database로 ‘1000 Genome’, ‘ExAC’, ‘gnomAD’ 등이 존재합니다. OMIM information: Variants가 특정 disease의 원인으로 보고되었는지 확인할 수 있습니다. 관련된 database로 ‘OMIM’이 있습니다. Summary De novo variants는 Mendelian Disorder의 주요 원인 variants 입니다. De novo variants calling 과정 동안 false call을 줄이는 것이 중요합니다." }, { "title": "WES 데이터 처리와 해석법", "url": "/posts/WES_data_analysis/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, NGS, WES", "date": "2022-07-25 10:10:05 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 의과대학 최무림 교수님의 WES 기초편 강의를 정리한 내용입니다.IntroWES 데이터 처리 단계와 주요 parameter를 소개합니다. WES 데이터의 질적 평가를 할 수 있습니다. WES 데이터 처리를 위한 파이프라인을 소개합니다. WES 데이터 처리의 예시를 수행합니다.WES 데이터 처리 단계 Read alignment bwa mem 주로 사용합니다. Removing PCR duplicates PCR 과정에서 발생하는 duplicate를 확인하고 제거하는 과정입니다. PCR duplicates는 biological duplicates와 다르며 임의로 중복 생산된 상태이므로 이를 제거하는 과정이 필요합니다. picard를 주로 사용합니다. PCR duplicates www.edwith.org/wes-beginner Variant calling gatk Haplotypecaller를 주로 사용합니다. Variant annotation SnpEff를 주로 사용합니다. WES 데이터의 각종 parameter Parameters of WES data www.edwith.org/wes-beginnerWES 데이터 분석 파이프라인 GATK Best Practice www.edwith.org/wes-beginnerWES 분석 파이프라인은 GATK best practice가 가장 잘 알려져 있고 손쉽게 따라할 수 있습니다.Summary WES 분석 파이프라인은 GATK best practice가 잘 구축되어 있고 주로 사용합니다." }, { "title": "WES 연구 디자인법", "url": "/posts/WES_research_design/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, NGS, WES", "date": "2022-07-25 08:25:13 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 의과대학 최무림 교수님의 WES 기초편 강의를 정리한 내용입니다.IntroWES 연구 예시를 접합니다. 연구 주제 정할 때 주의점을 이해합니다. 그리고 연구 규모에 대한 예측과 연구 디자인 시 주의점을 이해합니다.WES 연구예시 AML WES Research www.edwith.org/wes-beginnerAML 환자 2,869명과 control 6,405명 대상으로 WES 진행한 뒤 variants로 구분되는 gene을 확인 했습니다. Top 10 genes를 표기했는데 각각 gene이 가지는 AML에 대한 기여도는 약 1%에 지나지 않습니다. 즉, AML이 매우 complex한 disease임을 생각해 볼 수 있습니다. Autism WES Research www.edwith.org/wes-beginnerAutism 환자를 대상으로 WES 진행한 뒤 variants가 발견된 gene을 표기 했습니다. 위로 갈수록 gene name 크기가 커지는데, autism에 더 많은 영향을 미친다는 의미를 내포하고 있습니다. Type 2 diabetes WES Research www.edwith.org/wes-beginnerType 2 diabetes 환자 20,791명과 control 24,440명 대상으로 WES 진행한 뒤 variants로 구분되는 gene을 확인 했습니다. 만성질환은 유전적인 요인보다 환경적인 요인의 작용이 더 크며 WES로 영향을 미치는 gene을 찾아내는데 어려움이 있습니다.WES 최근 연구예시 The American Journal of Human Genetics www.edwith.org/wes-beginnerAJHG(The American Journal of Human Genetics)는 sequencing 결과 어떤 gene에서 발생한 variants가 disease와 연관되는지 보고한 논문들을 모아 발표하는 학술지 입니다. 논문의 내용은 다음과 같이 정형화되어 있습니다. Patient information: pedigrees, phenotype table, brain MRI, pictures etc Variant profile in a protein map Structural analysis Functional analysis #1: variants are functional/pathogenic Functional analysis #2: genes are functional/pathogenic최근 학술지에 보고된 논문들도 형식에 따라 발표되고 있음을 확인할 수 있습니다. The American Journal of Human Genetics https://www.cell.com/ajhg/homeWES 디자인Monogenic Mendelian disorder의 경우, 전통적으로 진행하던 특정 syndrome의 원인 유전자 찾는 작업은 거의 종료 되었습니다. 아직 보고되지 않았다면 누군가 시도했으나 원인 유전자를 찾지 못한 경우일 가능성이 높습니다. 과거에는 phenotype-driven ascertainment로 접근했다면, 오늘날에는 genotype-driven ascertainment로의 방향 전환이 일어났습니다. WES at 2010 특정 증상이 동일한 환자 00명 모집 → WES 분석 → 동일한 variants/genes 가지고 잇는 사람들 선택(최소 10% 이상) → Functional analysis WES at 2020 증상이 다를 수 있으나 발달장애, 선천성 심장병 등 큰 임상적 범주에 드는 환자군 000/0000명 모집 → WES 분석 → 동일한 variants/genes 가지고 있는 사람들 선택(1% 정도도 가능) → GeneMatching → Functional analysis 그런데 희귀질환 연구의 딜레마는 바로 여기에 있습니다. 데이터의 보안 유지를 통한 연구의 novelty를 확보하는 것은, 데이터 공개를 통한 동일 돌연변이 환자군 확보와 배치되는 방향입니다. 따라서 GeneMatching site를 통해 연구 중인 gene을 입력하면 같은 gene을 입력한 연구자들에게 mail이 전달되어 서로 협력하고 공동연구 할 수 있는 기회를 만들어주고 있습니다. Gene Matcher https://genematcher.org/How many genes remain to be found?그렇다면 아직 기능이 완전히 연구되지 않은 gene은 얼마나 될까요? How many genes remain to be found? www.edwith.org/wes-beginnerSummary WES는 2009년 처음 개발된 이후로 발전을 거듭해 왔으며 질환 유전자 발견의 기법으로 사용되어 왔습니다. 현재도 계속 분석과 활용이 이루어지고 있습니다. 최근 몇년간 유전자 발견 경향에 큰 변화가 일어나고 있습니다. 빅데이터 &amp;amp; 유전형 기반 환자 모집과 GeneMatching을 통한 유전자 발견, 공유, 기능연구가 진행되고 있습니다. 하지만 아직 돌연변이가 생겼을 때 그 결과를 모르는 유전자가 많이 있습니다." }, { "title": "WES 개념과 유전학적 의의", "url": "/posts/WES_definition_genetic/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, NGS, WES", "date": "2022-07-24 21:21:40 +0900", "snippet": "본 post는 국가생명연구자원정보센터(KOBIC) 주관 서울대학교 의과대학 최무림 교수님의 WES 기초편 강의를 정리한 내용입니다.IntroWES의 개념, 역사, 장단점, 실험적 과정, 의학유전학적 의의를 이해합니다.WES의 개념WES는 target sequencing의 한 종류입니다. Protein coding region은 human genome의 약 1% 정도를 차지하고 있습니다. 그에 반면 실제 질병을 유발하는 변이의 약 75%가 coding region에 포함됩니다. 따라서 WES는 경제적, 시간적으로 분석 효율성이 높은 방식이라고 할 수 있습니다.Human genome에 관련된 몇 가지 유전학 내용을 먼저 알아봅시다. # of bases in human genome? 3 billion bases, 약 30억 bases # of (coding) genes in human genome? 20,000개 # of bases in (coding) genes? 30 million bases, 약 3,000만 개 coding region은 약 1% # of variants in human genome? (compared to what?) 3 million, 약 300만 개 human reference genome과 비교하여 약 1,000 bases 당 1개 variants가 존재하는 것으로 알려져 있습니다. # of variants in coding genes? 0.3 million, 약 3만 개 coding region은 약 1% # of variants that change proteins? 15,000개 # of variants that change proteins and rare? 200개 nomad와 같은 MAF database들의 variants 제외하면 rare variants는 약 200개 # of variants that are specific to yourself? 부모로부터 유전된 variants까지 모두 제거하면 count 가능 WES의 장단점 장점 cost: 비용이 WGS에 비해 저렴합니다. small data size: 상대적으로 분석하기 용이합니다. 단점 Does not cover non-coding regions Not all genes are covered Low sensitivity toward structural variations Variable coverage pattern WES Process WES Process www.edwith.org/wes-beginnerWES는 그림과 같은 process를 따라 진행합니다. Shear: DNA를 잘게 자릅니다. Hybridize: Human exon에 선택적으로 결합하는 kit를 사용하여 exon만 선별합니다. Wash/elute: Exon만 남기고 나머지 region은 씻어 버립니다. Sequencing: Exon 영역을 sequencing 합니다. Computational pipeline: WES 분석을 진행한 뒤 disease associated novel variants를 찾아냅니다.WES 유전학적 의의 WES 유전학적 의의 www.edwith.org/wes-beginner2015년 논문에 발표된 내용에 따르면 human genes의 약 52%가 Mendelian phenotypes와 어떻게 연결되는지 알 수 없었습니다.하지만 2020년 OMIM database 내용에 따르면 그 숫자가 약 30%로 감소 했습니다.예전보다 human genome과 phenotype 사이 더 많은 사실관계를 확인한 것입니다. WES 발전과 MC 증가 www.edwith.org/wes-beginner1990년대 sequencing 기술이 발전하면서 human genes-Mendelian condition의 상관관계 뿐만이 아니라 new Mendelian condition 발견도 증가했습니다. 특히 WES 방식이 널리 사용되면서 그 숫자는 폭발적으로 증가했습니다.뿐만 아니라 과거에는 전통적인 방식으로 human genes를 확인했다면 2010년 이후에는 NGS가 그 방식을 대체하고 있습니다. WES의 유전학적 의의 www.edwith.org/wes-beginner위 그래프에서 보는 것과 같이 WES의 사용은 new novel gene 확인 속도를 증가시켰습니다. 또한 과거에는 pheotype으로부터 시작하여 syndrome을 확인했다면, 현재는 genotype으로부터 syndrome을 확인하는 방식으로 변화했습니다. 즉, 수 천명의 환자를 대상으로 WES를 시행한 뒤 genotype을 가지고 syndrome과의 관계를 연구하는 것입니다.Summary WES는 protein coding region인 exon의 선택적 시퀀싱 분석을 가능케 하는 기법입니다. WES는 낮은 가격과 적은 데이터라는 장점으로 효율적인 질환 유발 변이 발견을 할 수 있게 합니다. 최근 10년간 약 천 여건의 질환 유발 유전자 발견을 선도해 왔습니다." }, { "title": "ch9. Expectation, Indicator Random Variables, Linearity", "url": "/posts/ch9_Expectation_Indicator_Random_Variables_Linearity/", "categories": "Study, L-Statistics", "tags": "statistics, harbard, CDF, expectation, linearity", "date": "2022-07-23 23:10:32 +0900", "snippet": "Intro누적분포함수를 이용하여 특정 사건의 확률과 기댓값을 구하는 방법을 알고, 지시확률변수 및 선형성을 이용하여 기댓값을 구할 수 있습니다.누적분포함수 (CDF)누적분포함수는 세 가지 속성을 가지고 있습니다. increasing(증가함수) right continuous (우연속함수) $F(X) \\to 0 as X \\to -\\infin$, $F(X) \\to 1 as X \\to \\infin$독립확률변수모든 x, y에 대해서 $P(X \\leq x, Y \\leq y) = P(X=x)P(Y=y)$ 가 성립할 때, 확률변수 X, Y가 독립이라고 합니다.평균을 구하는 방법확률변수는 우리가 모르는 값임을 앞서 확인했습니다. 확률변수의 평균을 구하기 앞서 일반적인 수들의 평균 구하는 방법을 알아봅니다. Unweighted average: 모든 숫자를 더해서 개수로 나눠주는 방식입니다. 예시) 1, 2, 3, 4, 5 $\\frac{1+2+3+4+5}{6}$ Weighted average(가중평균): 가중치를 부여하여 평균을 구하는 방식입니다. 예시) 1, 1, 1, 1, 1, 3, 3, 5 $\\frac{5}{8} \\times 1 + \\frac{2}{8} \\times 3 + \\frac{1}{8} \\times 5$ 이산확률변수의 평균 (기댓값)Weighted average 구하는 방식을 적용하여 이산확률변수의 평균(기댓값)을 구할 수 있습니다.$E(X) = \\Sigma{x} X\\times P(X=x)$$= \\Sigma 값 \\times 확률질량함수$이에 대한 예시들을 살펴봅니다.베르누이 확률변수의 기댓값X~Bern(p)베르누이 확률변수의 기댓값은 다음과 같습니다.$E(X) = 1 \\times P(X=1) + 0 \\times P(X=0) = P$여기에서 X는 사건 A가 발생한 경우 확률이 1, 그 외의 경우 확률이 0입니다.$E(X) = P(A)$로 표현할 수 있고, X는 indicator random variable(지시확률변수)로 볼 수 있습니다.이항 확률분포의 기댓값X~Bin(n,p)이항분포 확률변수의 기댓값은 다음과 같습니다.$E(X) = \\Sigma_{k=1}^{n}k\\begin{pmatrix}nk\\end{pmatrix}p^{k}q^{n-k}$$=\\Sigma_{k=1}^{n}n\\begin{pmatrix}n-1k-1\\end{pmatrix}p^{k}q^{n-k}$(j = k-1)$=np\\Sigma_{k=1}^{n}n\\begin{pmatrix}n-1j\\end{pmatrix}p^{j}q^{n-1-j}$이항정리에 의하여$=np$꽤 성가신 계산 과정이었습니다. 이보다 간단히 풀어낼 수 있는데 바로 기댓값의 가장 유용한 속성인 linearity를 이용하는 것입니다.Linearity (선형성)선형성을 이용하여 다음과 같이 기댓값을 구할 수 있습니다.E(X+Y) = E(X) + E(Y)E(cX) = cE(X)X, Y가 dependent 하더라도 성립합니다.이항 확률변수의 기댓값도 선형성을 이용하여 구할 수 있습니다.$X = X_{1} + … + X_{n}$$X_{i}$는 각각 베르누이 시행일 때,$E(X) = n \\times E{X_{1}} = np$로 계산할 수 있습니다.기하분포Geom(p): 여러 번의 베르누이 독립 시행에서 첫 번째 성공할 때까지 실패한 횟수확률질량함수를 구해봅시다.PMF: $P(X=k) = q^{k}p, k \\in {0,1,2,…}$기하분포의 기댓값을 구해봅시다. 정의에 의한 방법 $E(X) = \\Sigma_{k=0}^{\\infin}kpq^{k}$ = $p\\Sigma_{k=1}^{\\infin}kq^{k}$ = $\\frac{pq}{p^{2}}$ = $\\frac{q}{p}$ Storyproof c = E(X) $c = 0 \\times p + (1 + c) \\times q$ = $q + cq$ = $\\frac{q}{1-q} = \\frac{q}{p}$ IMO기대값을 구하는 과정을 알아보는 시간이었습니다. 선형성이 중요한 개념임을 다시 한 번 확인 했습니다." }, { "title": "ch3. Linear Algebra Calculations", "url": "/posts/ch3_Linear_Algebra_Calculations/", "categories": "Study, B-Guide_to_Linear_Algebra", "tags": "linear algebra, study, vector, Gauss-Jordan elimination, determinant, matrix inverse", "date": "2022-07-23 18:10:42 +0900", "snippet": "기약행 사다리꼴 행렬 (3.1)가우스-조던 소거법을 사용해서 선형 연립방정식을 풀 수 있습니다. 가우스-조던 소거법은 임의의 행렬을 기약행 사다리꼴 행렬(RREF: Reduced Row Echelon Form)로 변환하여 연립방정식의 해를 쉽게 찾을 수 있습니다. 첨가행렬 (agumented matrix) 선형 연립방정식은 첨가행렬(augmented matrix)로 표현할 수 있습니다. 첫 번째 열은 첫 번째 변수의 계수, n 번째 열은 n 번째 변수의 계수, 그리고 마지막 열은 우변에 있는 상수를 의미합니다. 행 연산 다음과 같이 행렬의 행을 조작하여 행연산 수행 후 연립방정식 해를 구할 수 있습니다. 두 행의 위치를 교환합니다. 한 행에 상수를 곱합니다. 어느 한 행에 상수를 곱한 후 다른 행을 더합니다. 기약행 사다리꼴은 가장 간단한 첨가행렬 형태입니다. 각 행에는 피벗(pivot)이라고 하는 그 행에서 가장 먼저 나타나는 숫자 1(선행 1)이 있습니다. 각 열의 피벗은 동일한 열에서 아래/위 숫자를 제거하는데 사용됩니다. 이 과정을 거치면 결국 기약행 사다리꼴 형태가 됩니다. 정의 행렬의 j행에 대한 피벗은 j행의 가장 왼쪽에 있는 0이 아닌 성분입니다. 모든 피벗은 각 행에 적절한 숫자를 곱하여 선행 1로 변환할 수 있습니다. 가우스 소거법은 행렬을 행 사다리꼴 형태(REF)로 변환하는 과정입니다. 선행 1 아래의 모든 성분이 0이면 이 행렬은 행 사다리꼴 형식(REF)이라고 합니다. 가우스-조던 소거법은 행렬을 기약행 사다리꼴 형태(RREF)로 변환하는 과정입니다. 피봇 위/아래에 있는 모든 성분이 0이면 기약행 사다리꼴 형식(RREF)이라고 합니다. rank(A): 행렬 A의 랭크는 A의 RREF에 있는 피벗의 개수입니다. 가우스-조던 소거 알고리즘 가우스-조던 소거 알고리즘(Gauss-Jordan elimination algorithm)은 왼쪽에서 오른쪽으로 이동하는 순방향과, 오른쪽에서 왼쪽으로 이동하는 역방향의 두 단계로 진행됩니다. 순방향 단계(왼쪽에서 오른쪽) 맨 왼쪽 열에서 피벗(선행 1)을 얻습니다. 1단계의 피벗 아래에 있는 열의 모든 성분이 0이 되도록 그 아래의 모든 행에서 피벗이 있는 행을 뺍니다. 다음 열의 선행 1을 찾아 반복합니다. 역방향 단계(오른쪽에서 왼쪽) 맨 오른쪽 피벗을 찾아 이를 이용하여 해당 피벗 열에서 피벗 위의 모든 숫자를 제거합니다. 한 열 왼쪽으로 이동해서 반복합니다. 해의 개수 세 개의 변수를 갖는 세 개의 선형 연립방정식에서 서로 조건이 다른 경우를 알아봅시다. 해가 유일할 때 어떤 행렬의 RREF에 각 행마다 피벗이 있으면, 해를 바로 알 수 있습니다. $\\begin{vmatrix} 1 &amp;amp; 0 &amp;amp; 0 \\bigm| c_{1} 0 &amp;amp; 1 &amp;amp; 0 \\bigm| c_{2} 0 &amp;amp; 0 &amp;amp; 1 \\bigm| c_{3} \\end{vmatrix}$ 유일한 해는 $x_{1} = c_{1}, x_{2} = c_{2}, x_{3} = c_{3}$ 입니다. 해가 무수히 많을 때 방정식 중 하나가 중복되면 RREF로 변환된 행렬에 0으로만 이루어진 행이 나타납니다. 이것은 원래 방정식 중 하나가 나머지 두 방정식에 대해 선형결합일 때 발생합니다. 이 경우에는 세 개의 변수로 두 개의 방정식을 풀어야 하므로, 알려지지 않은 변수 중 하나를 고정할 수 없습니다. 이때 해가 자유 변수를 포함한다고 합니다. $\\begin{vmatrix} 1 &amp;amp; 0 &amp;amp; a_{1} \\bigm| c_{1} 0 &amp;amp; 1 &amp;amp; a_{2} \\bigm| c_{2} 0 &amp;amp; 0 &amp;amp; 0 \\bigm| 0 \\end{vmatrix}$ $x_{3} = t$가 자유 변수이며 $-\\infin$와 $\\infin$사이의 어떤 값을 취할 수 있습니다. $x_{1} = c_{1} - a_{1}t, x_{2} = c_{2} - a_{2}t$로 표현할 수 있습니다. 2차원에서 해가 무수히 많을 때 0이 아닌 3개의 방정식이 모두 일치할 때 발생합니다. 그 결과 하나의 선행 1과 두 개의 자유 변수가 생깁니다. 해가 존재하지 않는 경우 3개의 방정식을 모두 동시에 만족하는 수 $x_{1}, x_{2}, x_{3}$가 없다면, 연립방정식의 해는 존재하지 않습니다. RREF 형식에서 계수가 모두 0인 행을 포함하고, 우변에 0이 아닌 상수인 경우에는 해가 없습니다. 기하학적 해석 2차원 상의 직선 방정식 $ax + by = c$는 $\\mathbb{R}^2$ 상의 직선입니다. 두 개의 연립방정식이 있을 때 해를 찾기 위해서는 두 직선이 교차하는 점 (x, y)를 찾아야 합니다. 해집합은 세 가지 경우가 있습니다. 하나의 해: 두 직선이 한 점에서 교차하는 경우 무수히 많은 해: 두 직선이 겹치는 경우 해가 존재하지 않음: 두 직선이 평행하고 교차하지 않는 경우 3차원 상의 평면 방정식 $ax + by + cz= d$는 $\\mathbb{R}^3$ 상의 평면입니다. 세 개의 연립방정식이 있을 때 해를 찾기 위해서는 세 개의 방정식을 동시에 만족하는 점 (x, y, z)를 찾아야 합니다. 해집합은 네 가지 경우가 있습니다. 단 하나의 해: 평행하지 않은 세 개의 평면이 한 점에서 만나는 경우 1차원의 무수히 많은 해: 세 개의 평면 중 두 평면이 일치하는 경우, 평행하지 않은 두 평면은 직선으로 표차하며 하나의 직선에서 만남 2차원의 무수히 많은 해: 세 개의 평면이 모두 일치하고 0이 아닌 식일 경우, 해집합은 평면임 해가 존재하지 않는 경우: 세 개의 평면이 교차점이 없는 경우 행렬방정식 (3.2)선형 연립방정식 문제를 행렬방정식으로 표현한 다음 역행렬을 사용하여 해를 구할 수 있습니다.$x_{1} + 2x_{2} = 5$$3x_{1} + 9x_{2} = 21$이 연립방정식을 행렬-벡터 곱으로 다시 쓸 수 있습니다.$\\begin{bmatrix}1 &amp;amp; 23 &amp;amp; 9\\end{bmatrix}$$\\begin{bmatrix}x_{1}x_{2}\\end{bmatrix}$ =$\\begin{bmatrix}521\\end{bmatrix}$더 간단하게 $A\\vec{x} = \\vec{b}$로 나타낼 수도 있습니다. 여기서 A는 2x2 행렬, $\\vec{x}$는 미지수 벡터(2x1 행렬), $\\vec{b}$는 상수 벡터(2x1 행렬)입니다. 이 행렬방정식의 양변에 역행렬 $A^{-1}$를 곱하여 $\\vec{x}$를 풀 수 있습니다.$A^{-1}A\\vec{x} = \\mathbb{I}\\vec{x} = \\vec{x} = A^{-1}\\vec{b}$따라서, 계수 행렬의 역행렬을 구한 후에 곱을 계산하여 선형 연립방정식을 풉니다.$A^{-1}$를 찾는 데 들이는 노력은 첨가행렬 $[A \\mid \\vec{b} ]$를 RREF로 변환하는 데 들이는 노력과 비슷합니다. 연립방정식을 행렬 형태로 변환해서 해를 구하면 수십 개의 계수를 각각 계산하지 않아도 된다는 점에서 유용합니다. A가 2x2 행렬이든 1000x1000 행렬이든 행렬의 크기와 상관없이 같은 식 $\\vec{x} = A^{-1}\\vec{b}$가 적용됩니다. 행렬과 벡터의 곱 방정식 $A\\vec{x} = \\vec{b}$를 푼다고 가정해 봅시다. 이는 nxn행렬 A를 벡터 $\\vec{x}$에 곱하여 벡터 $\\vec{b}$를 생성한다는 의미입니다. 벡터는 ‘높고 좁은’ nx1 행렬로 생각할 수 있습니다. 행렬과 벡터의 곱 $A\\vec{x} = \\vec{b}$에서 때때로 행렬 A의 역행렬이 존재하지 않는 경우가 있습니다. 연립방정식이 부족하게 설정된 경우(A가 높이보다 더 넓은 경우), 가능한 해 $\\vec{x}$의 부분공간(subspace)이 존재합니다. 이전 절에서 살펴본 해가 무수히 많은 경우에 해당합니다. 행렬곱셈 (3.3)행렬의 곱셈은 행렬 A의 각 행과 행렬 B의 각 열 사이에 내적을 취하여 계산합니다. 행렬의 곱셈 행렬의 곱셈 법칙 행렬의 곱셈은 결합법칙이 성립합니다. 접촉하는 열과 행은 각각 크기가 동일해야 합니다. 행렬의 곱셈은 교환법칙이 성립하지 않습니다. 선형변환의 구성 행렬의 곱셈이 이러한 방식으로 정의되는 이유는 무엇일까요? 이 질문에 대한 제대로 된 대답은 선형변환에서 자세히 다루게 될 것입니다. 열벡터 $\\vec{x} \\in \\mathbb{R}^n$를 행렬 $A \\in \\mathbb{R}^{m \\times n}$에 곱하는 것은 선형변환 $T_{A}$를 적용하는 것과 비슷합니다. $T_{A} : \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$ 선형변환 $T_{A}$를 입력 $\\vec{x}$에 적용하는 것은 행렬과 벡터의 곱 $A\\vec{x}$를 계산하는 것과 동일합니다. $\\mathbb{R}^{n}$에서 $\\mathbb{R}^{m}$으로의 모든 선형변환은 어떤 행렬 $A \\in \\mathbb{R}^{m \\times n}$와 같은 행렬 곱으로 설명할 수 있습니다. 행렬식 (3.4)어떤 행렬 A의 행렬식은 det(A) 또는 $\\mid A \\mid$라고 표시하며, 행렬의 성분들을 곱해 결과값이 숫자가 되는 특별한 방법입니다. 다음과 같은 의미를 가집니다. 도형의 부피 행렬식을 기하학적 계산으로서 직관적으로 해석할 수 있습니다. 어떤 도형의 면이 행렬의 행이라면, 행렬식은 그 도형의 부피입니다. 2x2 행렬의 경우, 행렬식은 평행사변형의 넓이입니다. 3x3 행렬의 셩우, 행렬식은 평행육면체의 부피입니다. 차원 d&amp;gt;3에 대해서, 행렬식은 d차원의 초부피(hyper-volume)를 측정합니다. 선형변환 비례인자(scale factor) 행렬 $A_{T}$와 행렬-벡터 곱 $T(\\vec{x}) \\equiv A_{T}\\vec{x}$로 정의된 선형변환 $T : \\mathbb{R}^{2} \\to \\mathbb{R}^{2}$에서, 행렬식은 선형변환 T와 연관된 비례인자(scale factor)입니다. 비례인자는 입력공간에서 단위 정사각형(1x1 차원의 사각형)의 넓이가 T로 인해 어떻게 변환되는지 설명합니다. T를 통과한 후, 단위 정사각형은 det($T_{A}$)의 넓이를 갖는 평생사변형으로 변환됩니다. 선형독립성 검사 주어진 벡터 집합에 대해 선형독립성을 검사할 때 사용합니다. 벡터를 행렬의 행으로 하여 행렬을 구성하고 행렬식을 계산합니다. 행렬식이 0이 아닌 경우, 벡터는 선형독립입니다. 역행렬 존재 여부 역행렬이 존재하는지 여부를 알려줍니다. 만약 행렬식이 0이 아니면 행렬은 역행렬이 존재하며, 0이면 역행렬이 존재하지 않습니다. 이 외에도 벡터 외적과 관련 있으며, 고윳값 방정식의 정의에도 사용됩니다. 햏렬식이 선형변환 비례인자로 작용 행렬식 공식2x2 행렬의 행렬식은 다음과 같습니다. 2x2 행렬의 행렬식3x3 행렬의 행렬식은 다음과 같습니다. 3x3 행렬의 행렬식, Sarrus Method 3x3 행렬의 행렬식 쉽게 구하기$n \\times n$ 행렬의 행렬식은 더이상 쉬운 공식으로 간략히 구하기 어렵습니다. 대신 체계적으로 구할 수 있는 과정을 알아봅니다. nxn 행렬의 행렬식 nxn 행렬의 행렬식 nxn 행렬의 행렬식" }, { "title": "ch2. Introduce Linear Algebra", "url": "/posts/ch2_Introduce_Linear_Algebra/", "categories": "Study, B-Guide_to_Linear_Algebra", "tags": "linear algebra, study, vector, linearity", "date": "2022-07-23 11:42:13 +0900", "snippet": "정의 (2.1) 행렬-벡터 곱 행렬 $A \\in \\mathbb{R}^{m \\times n}$와 벡터 $\\vec{x} \\in \\mathbb{R}^{n}$에 대하여, 행렬-벡터 곱 $A\\vec{x}$는 계수 $\\vec{x}$를 갖는 행렬 $A$의 열들의 선형결합(linear combination)을 생성합니다. 예를 들어, $3 \\times 2$ 행렬 $A$와 $2 \\times 1$ 벡터 $\\vec{x}$의 곱은 $3 \\times 1$ 벡터가 되고, $\\vec{y} = A\\vec{x}$로 표현합니다. $\\begin{bmatrix}y_{1}y_{2}y_{3}\\end{bmatrix}$ = $\\begin{bmatrix}a_{11} &amp;amp; a_{12}a_{21} &amp;amp; a_{22}a_{31} &amp;amp; a_{32}\\end{bmatrix}$$\\begin{bmatrix}x_{1}x_{2}\\end{bmatrix}$ =$\\begin{bmatrix}x_{1}a_{11} + x_{2}a_{12}x_{1}a_{21} + x_{2}a_{22}x_{1}a_{31} + x_{2}a_{32}\\end{bmatrix}\\equiv$$x_{1}\\begin{bmatrix}a_{11}a_{21}a_{31}\\end{bmatrix}$ +$x_{2}\\begin{bmatrix}a_{12}a_{22}a_{32}\\end{bmatrix}$ 위 식에서 관찰해야 할 핵심은 ‘행 표현’과 ‘열 표현’에서 행렬-벡터 곱 $A\\vec{x}$에 대한 이중 해석입니다. ‘행 표현’은 행렬 $A$의 각 행과 $\\vec{x}$의 내적을 계산하여 $\\vec{y}$를 해석합니다. ‘열 표현’은 행렬 $A$의 첫 번째 열의 $x_{1}$배와 두 번째 열의 $x_{2}$배의 합으로 $\\vec{y}$를 해석합니다. 즉, $\\vec{y}$는 $A$ 열들의 선형결합입니다. 예를 들어, $A$의 첫 번째 열의 3배와 두 번째 열의 4배로 구성된 선형결합을 얻으려면 행렬 $A$에 $\\vec{x}$ = $\\begin{bmatrix}34\\end{bmatrix}$를 곱하면 됩니다. 선형변환 (linear transformation) 선형변환 (linear transformation)은 선형대수학의 핵심 개념입니다. 이 책에서 핵심이고 주요 아이디어입니다. 행렬-벡터 곱은 선형대수학 학습의 핵심 개념 중 하나인 선형변환의 추상화에 해당합니다. 행렬 $A \\in \\mathbb{R}^{m \\times n}$에 의한 곱셈은 n-벡터를 입력으로 가져와 m-벡터를 출력으로 생성하는 선형변환 $T_{A}$를 계산한 것으로 생각할 수 있습니다. $T_{A}: \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$ 행렬 $A$는 m행이므로 행렬-벡터 곱의 결과는 m-벡터입니다. 선형변환 $T_{A}$를 벡터 $\\vec{x}$에 적용하는 것은 행렬 $A$와 열벡터 $\\vec{x}$의 곱에 해당합니다. $T_{A}$는 행렬 $A$로 표현된다고 합니다. 선형대수학의 개요 함수는 입력공간(정의역)에서 출력공간(치역)으로의 변환입니다. 선현변환 $T_{A}: \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$은 n-벡터를 입력으로 받고 m-벡터를 출력으로 내놓는 함수입니다. 만약 함수 $T$가 선형이면, $\\vec{x}$에 적용된 $T$에 의한 출력 $\\vec{y} = T(\\vec{x})$는 어떤 행렬 $A_{T} \\in \\mathbb{R}^{m \\times n}$에 대해 행렬-벡터 곱인 $A_{T}\\vec{x}$로 계산될 수 있습니다. $T$는 행렬 $A_{T}$로 표현된다고 합니다. 모든 행렬 $A \\in \\mathbb{R}^{m \\times n}$은 선형변환 $T_{A}: \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$에 대응됩니다. 행렬과 선형변환은 동치이므로, “선형대수학은 벡터와 행렬에 대한 것이다.”라는 말은 “선형대수학은 벡터와 선형변환에 관한 것이다.”라는 말로 재해석할 수 있습니다. 벡터 연산 (2.2)$\\vec{u} = (u_{1},u_{2},u_{3})$, $\\vec{v} = (v_{1},v_{2},v_{3})$와 임의의 상수 $\\alpha \\in \\mathbb{R}$에 대하여 벡터 대수는 다음의 연산에 의해 결정됩니다. 덧셈: $\\vec{u} + \\vec{v} \\equiv (u_{1}+v_{1},u_{2}+v_{2},u_{3}+v_{3})$ 뺄셈: $\\vec{u} + \\vec{v} \\equiv (u_{1}-v_{1},u_{2}-v_{2},u_{3}-v_{3})$ 스케일링: $\\alpha\\vec{u} \\equiv (\\alpha u_{1},\\alpha u_{2},\\alpha u_{3})$ 내적: $\\vec{u} \\cdot \\vec{v} \\equiv u_{1}v_{1} + u_{2}v_{2} + u_{3}v_{3}$ 외적: $\\vec{u} \\times \\vec{v} \\equiv (u_{2}v_{3} - u_{3}v_{2},u_{3}v_{1} - u_{1}v_{3},u_{1}v_{2} - u_{2}v_{1})$ 길이: $\\vert\\vert\\vec{u}\\vert\\vert = \\sqrt{u_{1}^2+u_{2}^2+u_{3}^2}$행렬 연산 (2.3) 역행렬 역변환 가능한 행렬 $A$에 역행렬 $A^{-1}$을 곱하면 항등행렬 $AA^{-1} = I = A^{-1}A$를 만들 수 있습니다. 항등행렬(identity matrix)은 모든 $\\vec{v}$에 대해 $I\\vec{v} = \\vec{v}$를 만족합니다. 역행렬 $A^{-1}$은 $A$가 수행한 모든 작업을 상쇄합니다. 모든 행렬이 역행렬을 갖는 것은 아닙니다. 가역행렬(invertible matrix)만 역행렬을 갖습니다. 대각합 (trace) $n \\times n$ 행렬의 대각합 (trace)은 대각선에 있는 n 값들의 합계입니다. $Tr: \\mathbb{R}^{n \\times n} \\to \\mathbb{R}, Tr[A] \\equiv \\Sigma_{i=1}^{n}a_{ii}$ 대각합의 성질은 다음과 같습니다. Tr[$\\alpha$A + $\\beta$B] = $\\alpha$Tr[A] + $\\beta$Tr[B] (선형성) Tr[AB] = Tr[BA] Tr[ABC] = Tr[CAB] = Tr[BCA] (주기성) Tr[$A^{T}$] = Tr[A] Tr[A] = $\\Sigma_{i=1}^{n}\\lambda_{i}$ (여기서 $\\lambda_{i}$는 A의 고윳값=eigenvalue 입니다.) 행렬식 (determinant) 행렬식(determinant)은 행렬의 모든 계수를 포함하고 단일 숫자를 출력하는 계산입니다. $det : \\mathbb{R}^{n \\times n} \\to \\mathbb{R}$ 행렬식은 행렬의 행 벡터들에 의하여 결정되는 도형의 기하학적 양과 관계가 있습니다. 행렬 A의 행렬식은 A의 행에 의해 주어지는 변으로 이루어진 상자의 크기를 알려줍니다. 예를 들어 아래 행렬의 행렬식은 다음과 같습니다. $det(A) = det(\\begin{bmatrix}a &amp;amp; bc &amp;amp; d\\end{bmatrix})$ = $\\begin{vmatrix}a &amp;amp; bc &amp;amp; d\\end{vmatrix}$ = $ad - bc$ ad - bc는 벡터 (a,b)와 (c,d)에 의해 형성된 평생사변형의 면적입니다. (a,b) = $\\alpha$(c,d)인 경우, A의 행들이 같은 방향을 가리키면 평행사변형의 면적은 0이 됩니다. 행렬의 행렬식이 0이 아니면, 그 행렬의 행들은 선형독립입니다. 선형성, Linearity (2.4)선형성(linearity)이란 무엇이며 이 책 전체에서 선형성의 학습에 전념하고 있는 이유는 무엇일까요?$f(x) = \\frac{a}{x} + b + mx + qx^{2} + cx^{3}$mx항은 이 수식의 선형 항으로서 x의 1제곱입니다. 다른 모든 항은 비선형적입니다. 선형항은 입력 x의 값을 변경하면 mx의 값이 비례하여 변하기 때문에 특별합니다. 비선형항에는 적용되지 않는 특징입니다. 정의 선형 함수는 입력의 선형결합을 동일한 출력의 선형결합으로 대응시킵니다. 함수 f가 임의의 두 입력 $x_{1}$과 $x_{2}$, 그리고 모든 상수 $\\alpha$와 $\\beta$에 대해 다음의 방정식을 만족하면 선형(linear)입니다. $f(\\alpha x_{1} + \\beta x_{2}) = \\alpha f(x_{1}) + \\beta f(x_{2})$ 원점을 지나지 않는 직선은 선형 함수가 아니다 $l(x) = mx + b$ 위 함수는 선형 함수가 아닙니다. 아래 수식을 만족하지 못하기 때문입니다. 이와 같이 선형 부분(mx)에 상수 항을 더한 함수를 아편 변환(affine transformation)이라고 합니다. $l(\\alpha x_{1} + \\beta x_{2}) = m(\\alpha x_{1} + \\beta x_{2}) + b \\neq m(\\alpha x_{1}) + b + m(\\beta x_{2}) + b = \\alpha l(x_{1}) + \\beta l(x_{2})$ 선형방정식 변수 $x_{1}, x_{2}, x_{3}$의 선형방정식은 다음과 같은 형태를 갖습니다. $a_{1}x_{1} + a_{2}x_{2} + a_{3}x_{3} = c$ " }, { "title": "ch8. Random Variables and Their Distributions", "url": "/posts/ch8_Random_Variables_and_Their_Distributions/", "categories": "Study, L-Statistics", "tags": "statistics, harbard, PMF, CDF", "date": "2022-07-17 14:21:58 +0900", "snippet": "Intro확률분포를 해석하는 세 가지 접근방식을 이해하고 적용할 수 있습니다. 이항분포, 초기하분포를 이해합니다. 이항분포 복습 Bin(n, p) 모두 n(양의 정수), p([0, 1] 사이의 값, 확률)에 의해서 분포가 결정됩니다. 이항분포를 해석하는 세 가지 방법이 있습니다. 이 중 첫 번째 방법은 가장 중요합니다. Story X is #successes in n independent Bern(p) 지시확률변수(indicator random variables) $X = X_{1} + X_{2} + … + X_{n}$ $X_{1}, X_{2}, …, X_{n} ~iid Bern(p)$ $X_{j}$ = 성공인 경우 1, 실패인 경우 0 확률질량함수(PMF) $P(X=k) = \\binom{n}{k} p^{k}(1-p)^{n-k}$ Random Variables조약돌 세계관에서 7번 조약돌은 하나의 사건이자 그 사건을 지칭하는 번호입니다.X=7, is an event. 누적분포함수(CDF)CDF(Cummulative distribution function)$X \\leqq x$ is an event.$F(x) = P(X \\leqq x)$일 때 F를 CDF of X라고 정의합니다.두 이항분포의 합에 대한 분포지난 시간 마지막 부분에서 다뤘던 두 이항분포의 합에 대한 분포를 위에서 정의한 세 가지 접근방식에 따라 알아봅니다.X~Bin(n,p), Y~Bin(m,p), X와 Y가 independent일 때 X+Y~Bin(n+m, p)를 따릅니다. Story Binomial 분포를 따르는 두 개의 확률변수 X, Y의 성공하는 횟수는 각 확률변수 X, Y에서 성공하는 횟수를 더한 것과 같습니다. 지시확률변수(indicator random variables) $X = X_{1} + X_{2} + … + X_{n}$ $Y = Y_{1} + Y_{2} + … + Y_{n}$ → $X + Y = \\sum_{j=1}^{n}X_{j} + \\sum_{j=1}^{m}Y_{j}$ n+m의 분포는 Bin(n+m, p)를 따릅니다. PMF $P(X+Y=k) = \\sum_{j=0}^{k}P(X+Y=k X=j)P(X=j)$ = $\\sum_{j=0}^{k}P(Y=k-j X=j) \\binom{n}{j}p^{j}q^{n-j}$ = $\\sum_{j=0}^{k} \\binom{m}{k-j}p^{k-j}q^{m-k+j} \\binom{n}{j}p^{j}q^{n-j}$ = $p^{k}q^{m+n-k} \\sum^{k}_{j=0} \\binom{n}{j}$ = $p^{k}q^{m+n-k} \\binom{m+n}{k}$ 초기하분포(Hypergeometric)이항분포으로 착각하기 쉬운 초기하분포를 예제 문제를 통해 살펴보겠습니다. 카드 문제 5장의 카드를 뽑았을 때 ACE 카드가 나올 확률 $P(X=k) k \\in {0, 1, 2, 3, 4}$ = $\\frac{\\binom{4}{k} \\binom{48}{5-k}}{\\binom{52}{5}}$ 카드 첫 장을 뽑았을 때 ACE라면 비복원추출이므로 다음 카드를 뽑았을 때 ACE가 나올 확률은 감소합니다. 따라서 각 시행이 독립인 이항분포와 다른 분포입니다. Elk 문제 산 속에 20마리의 elk가 있습니다. 5마리는 tag, 15마리는 untag 되어있습니다. 4마리를 잡았을 때 2마리가 tag되어 있을 확률은? 역시 카드 문제와 마찬가지로 초기하분포를 따릅니다. 구슬 문제 b개의 검정색 구슬과 w개의 흰색 구슬 중에서, n개의 표본을 무작위로 추출할 때 표본에 있는 흰색 구슬의 수는? 마찬가지로 초기하분포를 따릅니다. 초기하분포라도 표본공간이 충분히 커서(예를 들어 구슬 10억개 중 10개를 뽑는 시행) 복원/비복원 여부가 큰 차이가 나지 않을 때, 초기하분포는 이항분포에 근사합니다. IMO이항분포와 초기하분포를 살펴보고 그 차이점을 확인 했습니다." }, { "title": "(EDWITH-KOBIC) 전사체 데이터 분석", "url": "/posts/Certificate_Transcriptome/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, transcriptome, KOBIC", "date": "2022-07-14 08:11:54 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "Sequencing Technologies", "url": "/posts/Sequencing_Technologies/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, sanger sequencing, chip sequencing, next generation sequencing", "date": "2022-07-10 11:02:52 +0900", "snippet": "Sequencing 개요about DNA post에서 DNA의 화학구조와 특성을 확인 했습니다. Sequencing의 목적은 pentose sugar의 1’ carbon에 연결된 nitrogenous base의 순서를 확인하는 것임을 또한 확인 했습니다. Sequencing cost per megabases - 2021https://www.genome.gov/about-genomics/fact-sheets/DNA-Sequencing-Costs-DataSequencing cost per Human Genome data - 2021https://www.genome.gov/about-genomics/fact-sheets/DNA-Sequencing-Costs-DataTechnology는 단점을 보완하여 항상 발전합니다. Sequencing tech는 반도체 못지 않게 급격한 발전을 이룬 분야 중 하나입니다. 위 그림은 sequencing tech와 관련된 강의, 세미나의 첫 시간에 자주 언급되는 내용입니다. (마크로젠 PT 면접에서도 위 그림을 포함 했…) “Moore&#39;s Law”는 인텔의 Gordon Moore가 1965년 발표한 법칙으로, 반도체에 들어가는 transistor의 수가 24개월마다 2배 증가한다는 것입니다. 이와 비교해서 megabase당 sequencing 비용과 Human Genome seqeuncing 비용은 더 급격히 감소하고 있습니다. Y-axis가 log scale임을 감안할 때 가격의 하락폭은 훨씬 더 급격하다는 것을 알 수 있습니다. 대용량 sequencing capability를 가진 Illumina의 Novaseq이 2017년 출시하면서 비로소 1,000 dollars Human Genome era를 맞이하게 되었습니다. 1990년부터 2003년까지 진행된 The Human Genome Project가 13년의 시간, $3 bilion dollars(3조원)이 소요된 것과 비교하면 가히 놀라울 만한 발전이 아닐 수 없습니다.   1st Generation Sequencing: Sanger SequencingSanger SequencingSanger sequencing은 1977년 Frederick Sanger와 동료들에 의해 개발된 sequencing 입니다. ddNTP(Dideoxynucleotide TriPhosphate)의 선택적 결합에 의해 DNA 복제가 종료되는 원리를 사용하여 base sequence를 확인합니다.우선 baseq sequence를 알고자 하는 template(single strand) DNA를 준비합니다. DNA elongation에 필요한 DNA primer도 준비합니다. DNA polymerase와 함께 dNTP, ddNTP가 담긴 tube에 준비물들을 넣으면 랜덤하게 길이가 다른 DNA fragment가 생성됩니다. dNTP가 결합하면 elongation이 계속 진행되지만, ddNTP가 결합하면 elongation을 이어갈 hydroxyl group(-OH)이 없으므로 반응은 종결됩니다. 마지막으로 gel electrophoresis(전기영동)로 DNA fragment를 내려주면 길이에 따라 band가 뜨고 base sequence를 확인할 수 있습니다. Dideoxynucleotide TriPhosphatedNTP(Deoxynucleotide TriPhosphate)와 달리 ddNTP(Dideoxynucleotide TriPhosphate)는 3’ -H group만 있으므로 더이상 새로운 nucleotide와 결합하지 못하고 elongation 반응이 종결됩니다.Sanger sequencing은 확인하고자 하는 부위를 PCR 증폭해야 하고, 한 번 반응할 때 확인 가능한 base 길이에 한계가 있습니다. 이런 단점을 극복하기 위해 NGS가 개발되었으며, 그 전까지 약 25년 동안 가장 널리 사용된 DNA sequencing 기술입니다.오늘날 업계에서는 여전히 sanger sequencing을 사용합니다. 다만 전통적인 sanger sequencing에서 좀 더 개선된 automated sanger sequencing을 사용합니다. 원리는 똑같으나 base sequence 확인 과정을 자동화하여 소요 시간을 단축시킨 방식입니다. 주로 짧은 길이의 base seqeuence를 정확하게 확인하거나 NGS 결과를 검증할 목적으로 sanger sequencing을 사용합니다.   2nd Generation Sequencing: NGSNGS는 cloning이 필요없고 library fragment의 amplification과 sequencing이 동시다발적으로 진행되기 때문에 비용과 소요시간을 절감할 수 있습니다. 2세대 sequencing이라고도 불리는 NGS는 short DNA 가닥을 만들어 squencing 하는 것이 특징이며, Illumina의 HiSeq, NovaSeq과 Thermo Fisher Scientific의 Ion Torrent가 대표적인 기기입니다. 2010년 이후 비약적인 발전을 이루어 왔습니다. 2010년 이후 주요 NGS 회사의 플랫폼 변화‘Next Generation Sequencing 기반 유전자 검사의 이해(2019) -식품의약품안전처-NGS는 clonal template 생성 방식에 따라 SBL(sequencing by ligation)과 SBS(sequencing by synthesis)로 나눌 수 있습니다. SBL(sequencing by ligation) Ligase와 Fluorescentyl labeled probe를 사용하여 sequence를 알아내는 방식입니다. 1~2bp 길이의 known base로 구성된 fluorescently labeled probe가 target DNA fragment에 결합한 뒤 인접한 2~10bp 길이의 oligonucleotide가 연결됩니다. 이 결합으로 인해 fluorescently labeled probe가 특정 spectrum의 빛을 방출하는데 이를 분석하여 base를 확인합니다. Life Technologies의 SOLiD(Sequencing by Oligonucleotide Ligation and Detection)와 Complete Genomics의 cPAL(combinatorial Probe-Anchor Ligation)이 SBL 방식의 대표적인 사례입니다. Sequencing by ligation methodsGoodwin, S., McPherson, J. &amp;amp; McCombie, W. Coming of age: ten years of next-generation sequencing technologies. Nat Rev Genet 17, 333–351 (2016). https://doi.org/10.1038/nrg.2016.49 SBS(sequencing by synthesis) DNA polymerase와 Fluorescentyl labeled base를 사용하여 sequence를 알아내는 방식입니다. SBS는 다시 CRT(cyclic reversible termination)와 SNA(single-nucleotide addition)로 나눌 수 있습니다. CRT(cyclic reversible termination) Sanger sequencing과 마찬가지로 3’-OH group이 막힌 deoxyribose를 사용합니다. DNA template의 adapter region에 primer가 결합한 뒤 polymerase가 달라붙습니다. 네 가지 종류의 dNTPs(deoxynucleotides)가 투입되고 그 중 DNA template에 상보적인 한 개의 dNTP가 결합합니다. 결합하지 못한 나머지 dNTPs는 wash-out 시킵니다. 각각의 cluster에 결합한 한 개의 dNTP에 붙어있던 flurophore가 떨어지면서 빛을 방출하고 이를 분석하여 sequence를 확인합니다. Illumina와 Qiagen의 sequencer가 CRT 방식의 대표적인 사례입니다. Sequencing by synthesis: cycliv reversible termination approachesGoodwin, S., McPherson, J. &amp;amp; McCombie, W. Coming of age: ten years of next-generation sequencing technologies. Nat Rev Genet 17, 333–351 (2016). https://doi.org/10.1038/nrg.2016.49 SNA(single-nucleotide addition) CRT와 달리 한 번에 한 개의 dNTP를 투입하여 a single signal을 확인하는 방식입니다. 454 Life Sciences의 pyrosequencing과 Thermo Fisher Scientific의 Ion Torrent가 SNA 방식의 대표적인 사례입니다. Sequencing by synthesis: single-nucleotide addition approachesGoodwin, S., McPherson, J. &amp;amp; McCombie, W. Coming of age: ten years of next-generation sequencing technologies. Nat Rev Genet 17, 333–351 (2016). https://doi.org/10.1038/nrg.2016.49   3rd Generation Sequencing: Long-read Sequencing2nd generation sequencing의 단점인 short-read를 보완한 sequencer로 PCR amplification 없이 DNA strand의 real-time sequencing 방식을 통해 long-read를 한 번에 읽을 수 있습니다. Single base quality가 높지 않아서 한계가 있지만 점차 정확도를 높히면서 임상진단 분야로 확대하고 있습니다.크게 두 가지 종류로 나눌 수 있는데, SMRT(single-molecule real-time) sequencing과 synthetic 방식입니다. SMRT(Single-molecule long-read) sequencing 현재 SMRT를 널리 사용하는 회사는 Pacific Biosciences입니다. SMRT는 특별한 flow cell을 사용하는데, ZMW(zero-mode waveguides)로 불리는 transparent bottoms를 지닌 picolitre 단위의 수 천 개 well이 존재합니다. Short-read SBS technology는 polymerase가 DNA를 따라서 움직이며 elongation이 진행되는 반면, PacBio는 DNA polymerase가 well 바닥에 고정되어 있고 DNA strand가 ZMW를 통과하며 sequence를 확인하는 방식입니다. Well은 단 한 개의 DNA strand만 통과 가능하며, dNTP가 결합하면서 방출하는 빛을 laser와 camera가 계속 확인합니다. 길이가 3kb 이상인 DNA는 어렵지만 그 이하의 DNA fragment는 여러 차례 반복해서 sequencing 될 수 있으며 CCS(circular consensus seqeunce)로 알려진 consensus read of insert를 생성합니다. 2014년 Oxford Nanopore Technologies(ONT)에서 MinION을 발표했습니다. 다른 회사의 sequencer들은 빛, 색상, pH와 같은 secondary signal을 사용한 반면, nanopore는 naive ssDNA의 sequence를 직접 읽습니다. Synthetic long-reads 그동안 확인했던 다른 sequencing platforms와 달리 short-read seqeuncer로 생산한 read와 각 fragment에 부여된 barcode에 의존하여 synthetic long-read를 구현하는 방식입니다. Illumina의 synthetic long-read sequencing과 10X Genomics의 emulsio-based system이 대표적인 사례입니다. Sequencing by synthesis: single-nucleotide addition approachesGoodwin, S., McPherson, J. &amp;amp; McCombie, W. Coming of age: ten years of next-generation sequencing technologies. Nat Rev Genet 17, 333–351 (2016). https://doi.org/10.1038/nrg.2016.49   NGS 장비의 장단점NGS sequencer마다 원리가 다르기 때문에 서로 다른 장단점을 가지고 있습니다. Illumina, Thermo Fisher Scientific으로 대표되는 2nd generation sequencing은 read length가 짧아서 정확도가 높고 SNP 검출에 유리하지만, structural variants 검출에는 취약합니다.반면 PacBio, Oxford Nanopore Technologies로 대표되는 3rd generation sequencing은 long-read의 이점을 살려 de-novo assembly와 structural variants 검출에 유리하지만, 정확도가 낮고 SNV 검출에 취약합니다. NGS sequencer의 장단점‘Next Generation Sequencing 기반 유전자 검사의 이해(2019) -식품의약품안전처-Take Home MessageDNA와 RNA의 구조는 molecular biology와 organic chemistry 수업 시간에 배운 기억이 있습니다. 당시에는 외워야하는 딱딱한 지식으로 생각했지만 DNA, RNA에서 일어나는 모든 화학반응과 NGS, bioinformatics 목적을 이해하기 위해서는 기본 구조를 잘 알아야 한다는 것을 다시 한 번 느꼈습니다. 또한 DNA replication과 protein 발현까지 진행되는 central dogma 원리를 알아야 중간에 문제가 발생해서 질병으로 이어지는 현상도 이해할 수 있습니다.Sequencing technology는 발전속도가 굉장히 빠른 분야입니다. 머지 않아 ssDNA를 짧은 시간 안에 저렴한 비용으로 sequencing 할 수 있는 시대가 찾아오지 않을까요?" }, { "title": "about DNA", "url": "/posts/about_DNA/", "categories": "Bioinformatics, Biology", "tags": "BI, bioinformatics, DNA, RNA, nucleoside, nucleotide, pentose sugar, nitrogenous base, phosphate, replication, weight", "date": "2022-07-09 22:04:15 +0900", "snippet": "DNA가 무엇인가요?DNA는 Deoxyribo Nucleic Acid의 약자로 생물의 유전정보를 담고 있는 물질 입니다. DNA는 transcription 과정을 거쳐 RNA(mRNA)로 변환되고, translation 과정을 거쳐 Protein을 생성하는데, 이것은 근육과 결합 조직, 피부 등의 구성요소로 작용할 뿐만 아니라 각종 효소를 생성하여 신체기능을 유지하도록 작용합니다.따라서 DNA는 유전정보를 다음 세대로 전달하는 도면으로 볼 수 있습니다. NGS 기술을 사용하여 정확한 DNA 서열을 알아내는 최종 목적은 결국 이 유전물질 정보를 밝혀내기 위함입니다. DNA, RNA의 기본 구조DNA와 RNA 비교DNA와 RNA를 비교한 그림입니다. 가장 먼저 눈에 띄는 차이는 기본 구조입니다. DNA는 double-helix로 불리는 구조를 가지며 두 가닥의 strand가 서로 꼬여 있습니다. 그리고 A-T, C-G가 서로 연결된 상보적인 서열로 구성되어 있습니다. 반면 RNA는 한 가닥의 strand로 이루어진 구조를 가지고, T 대신 U를 사용하여 U, T, C, G로 구성되어 있습니다. DNA, RNA 구조를 좀 더 확대해서 자세히 들여다 볼까요?   DNA와 RNA 구조 비교DNA와 RNA 기본 구조DNA, RNA의 기본 구조입니다. 다섯 개의 탄소로 구성된 pentose sugar에서 1번 탄소에 nitrogenous base, 5번 탄소에 phosphate group이 연결되어 있습니다.   Pentose SugarDNA와 RNA의 차이는 pentose sugar의 2번 탄소에서 기인하는데, -OH가 붙으면 ribose로 불리는 RNA의 구조를 이루고, -H가 붙으면 deoxyribose로 불리는 DNA의 구조를 이룹니다. 보통 DNA에 비해 RNA가 불안정하다고 알려져 있는데 그 이유는 바로 -OH에 있습니다. 풍부한 전자를 가지고 있으므로 다른 원소와 화학반응을 잘 일으킵니다.   Phosphate GroupPhosphate group은 nucleotide와 nucleoside를 구분 짓습니다. Phosphate group은 energy를 가지고 있으며 체내에서 에너지원으로 사용되는 ATP, ADP, AMP의 구조도 phosphate group과 연관 있습니다. ATP, ADP, AMP  Nitrogenous BaseNitrogenous base1번 탄소와 연결된 nitrogenous base는 질소(nitrogen)을 가진 이중고리 혹은 단일고리로 이루어진 base입니다. NGS 기술을 사용하여 시퀀싱하고 염기서열을 찾을 때 바로 이 base의 서열을 확인하는 것입니다. DNA는 A(adenine), T(thymine), C(cytosine), G(guanine)로 구성되어 있으며, RNA는 T 대신 U(uracil)로 구성되어 있습니다.Purine은 이중고리로 구성되어 있으며 A, G가 해당됩니다.Pyrimidine은 단일고리로 구성되어 있으며 C, T, U가 해당됩니다. DNA Replication: 5’ → 3’DNA ReplicationDNA replication은 항상 5’에서 3’ 방향으로 진행합니다. 여기서 5’과 3’은 앞서 보셨던 DNA 구조에서 pentose sugar를 구성하는 carbon의 위치를 의미합니다. 즉, DNA는 항상 3번 탄소의 말단에서 template을 구성하는 base에 상보적인 nucleotide를 받아들여 새로운 결합을 형성하고 길이를 늘려갑니다.DNA polymerase는 DNA replication을 담당하는 enzyme입니다. 전자가 풍부한 3’ hydroxyl group(-OH)가 incoming nucleotide의 triphosphate group을 공격합니다. 이 때 새로운 phosphodiester 결합이 형성되고 pyrophosphage group이 떨어져 나갑니다.5’에 phosphate group, 3’에 hydroxyl group이 위치하고 있기 때문에 DNA replication은 항상 5’ → 3’의 방향성을 가집니다. DNA WeightDNA basepair의 평균 weight는 650 doltons 입니다. 참고로 1 dolton은 hydrogen 원소 1개의 weight를 의미하며 $1.67 \\times 10^{-24}$grams와 같습니다.Double-stranded DNA molecule의 weight는 전체 basepairs 숫자에 650 daltons를 곱한 결과입니다. DNA는 약 30억개 basepairs로 구성되므로$3.0 \\times 10^{9}bp \\times 650 Da = 1.95 \\times 10^{12} Da$이 됩니다. 1 Da은 $1/(6.02 \\times 10^{23})$g이므로,$1.95 \\times 10^{12} \\times 1/(6.02 \\times 10^{23}) = 3.24 \\times 10^{-12} grams$$= 3.24 pg (10^{-12} grams = a picoaram)$으로 계산할 수 있습니다.하나의 cell 안에 한 쌍의 염색체가 있으므로 total weight는 약 6.5pg입니다.그렇다면 1ng(a nanogram = 1,000 picogram)의 DNA에 들어있는 염색체 수는 몇 쌍일까요?1개 cell에 들어있는 염색체 weight는 6.5pg이므로,$1,000pg / 6.5pg = 153 cells$약 153개 cell과 그 안에 153쌍의 염색체가 들어있으므로 총 306개의 염색체가 있음을 역산할 수 있습니다. Take Home MessageDNA와 RNA의 구조는 molecular biology와 organic chemistry 수업 시간에 배운 기억이 있습니다. 당시에는 외워야하는 딱딱한 지식으로 생각했지만 DNA, RNA에서 일어나는 모든 화학반응과 NGS, bioinformatics 목적을 이해하기 위해서는 기본 구조를 잘 알아야 한다는 것을 다시 한 번 느꼈습니다. 또한 DNA replication과 protein 발현까지 진행되는 central dogma 원리를 알아야 중간에 문제가 발생해서 질병으로 이어지는 현상도 이해할 수 있습니다." }, { "title": "(EDWITH-KOBIC) NGS 데이터 변이 분석 기초편", "url": "/posts/Certificate_NGS_data_analysis/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, variant, KOBIC", "date": "2022-07-05 22:04:27 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "ch7. Gambler&#39;s Ruin and Random Variables", "url": "/posts/ch7_Gamblers_Ruin_and_Random_Variables/", "categories": "Study, L-Statistics", "tags": "statistics, harbard, gambler's ruin, differece equation, random variable, bernoulli, binomial", "date": "2022-06-28 21:25:30 +0900", "snippet": "IntroGambler’s Ruin 문제를 계차방정식을 이용해 풀고, 확률변수의 정의를 이해할 수 있습니다. Gambler’s RuinA, B 두 명의 gambler가 내기를 합니다. 매 round에서 1 dollar를 걸고 내기에서 이긴 사람이 가져갑니다. A는 i dollar, B는 (N-i) dollar를 가지고 시작합니다.p = A가 이길 확률q = B가 이길 확률 = 1-p Random Walk위 문제는 유형을 파악하는 것이 중요합니다. 이와 같은 유형의 문제는 random walk로 정의할 수 있습니다.p는 오른쪽으로 이동할 확률, q는 왼쪽으로 이동할 확률입니다. 0, N은 absorbing state로 갇힌 상태입니다. Strategy: Condition on first step$P_{i} = P(A wins game \\mid A starts at i dollar)$$P_{i} = pP_{i+1} + qP_{i-1}$, $(1 \\leq i \\leq N-1)$, $(p_{0}=0, p_{N}=1)$문제를 해결하는데 가장 중요한 식입니다. Difference qeuation(계차방정식)이라고 부르며 미분방정식의 이산 형태입니다.Guessing을 통한 풀이$P_{i} = x^{i}$$x^{i} = px^{i+1} + qx^{i-1}$$px^{2} - x + q = 0$$x = \\frac{1 \\pm \\sqrt{1 - 4pq}}{2p} \\in {1,\\frac{q}{p}}$ 두 해가 다른 경우($p \\neq q$) 두 해의 선형결합 식으로 표현할 수 있습니다. $p_{i} = A1^{i} + B(\\frac{q}{p})^{i}, (p \\neq q)$ 조건 $p_{0} = 0, p_{N} = 1$을 대입하면, $p_{0} = A + B = 0$$, B = -A$ $p_{N} = A + B(\\frac{q}{p})^{N} = A(1 - (\\frac{q}{p})^{N}) = 1$ $A = \\frac{1}{1 - (\\frac{q}{p})^{N}}$ $p_{i} = \\frac{1 - (\\frac{q}{p})^{i}}{1 - (\\frac{q}{p})^{N-1}}, (p \\neq q)$ 두 해가 같은 경우($p = q$) $x = \\frac{q}{p}$로 치환하고 $x \\to 1$의 극한을 살펴봅니다. $\\lim_{x \\to 1} \\frac{1-x^{i}}{1-x^{N}} = \\lim_{x \\to 1} \\frac{i(x^{i-1})}{N(x^{N-1})} = \\frac{i}{N}$ 카지노(A)와 gambler(B)가 같은 돈을 가지고 시작했을 때 카지노에게 1%라도 유리한 게임인 경우 gambler가 이길 확률은 매우 작아집니다.$i = N-i, p=0.49$ $N=20 \\to 0.40$ $N=100 \\to 0.12$ $N=200 \\to 0.02$Random Variables (확률변수)우선 확률변수의 정의를 알아봅시다. 확률변수는 function입니다. 이 function은 표본공간 S로부터 실수 체계 R로 mapping합니다.쉽고 중요한 예제들을 살펴봅니다. Bernoulli (베르누이) 확률분포 A random variable X is said to have Bernoulli(p) distribution, if X has only 2 possible values, 0 and 1 P(X=1) = p P(X=0) = 1-P Binomial (이항) 확률분포 (n,p) The distribution of #success X in n independent Bernoulli(p) trials is called Binomial(n,p), its distribution is given by $P(X=k) = \\binom{n}{k} p^{k}(1-p)^{n-k}$ 이 식은 PMF(확률질량변수)라고 합니다. X~Bin(n,p), Y~Bin(m,p), X와 Y가 independent일 때 X+Y~Bin(n+m, p)를 따릅니다. IMODifference equation(계차방정식)을 다루는 곳이 거의 없는데 중요한 개념으로 보입니다. 베르누이분포, 이항분포를 시작으로 확률변수 분포가 나오는데 잘 정리해야 겠습니다." }, { "title": "ch6. Monty Hall, Simpson&#39;s Paradox", "url": "/posts/ch6_Monty_Hall_and_Simpsons_Paradox/", "categories": "Study, L-Statistics", "tags": "statistics, harbard, monty hall, law of total probability, simpson's paradox", "date": "2022-06-26 11:42:10 +0900", "snippet": "IntroMonty Hall 문제를 이해하고 확장해 볼 수 있으며, 심슨의 역설을 이해합니다. Monty Hall ProblemMonty Hall 문제는 Monty가 사회를 맡은 유명한 퀴즈쇼 프로그램입니다. 1, 2, 3번 3개의 문이 있고 그 뒤에 자동차 한 대, 염소 두 마리가 있습니다. 참가자는 우선 문 1개를 선택합니다. Monty는 나머지 2개 문 중 염소가 들어있는 한 개의 문을 엽니다. 그리고 참가자에게 선택을 변경할 수 있는 기회를 줍니다. 이 때 참가자는 선택을 변경하는 것이 유리할까요, 아니면 처음 선택을 유지하는 것이 유리할까요? Monty Hall 풀이1: 수형도수형도를 그려서 확률을 계산해 볼 수 있습니다.참가자가 1번 문을 선택했다고 가정합시다. Monty는 염소가 들어있는 2번 문을 엽니다. 이 때 참가자가 선택을 변경하지 않으면 자동차가 있는 문을 고를 확률은 1/6(표준화하여 1/3)이 됩니다. 반대로 선택을 변경하면 확률은 1/3(표준화하여 2/3)이 됩니다. 선택을 변경하는 것이 자동차를 선택할 확률이 더 높습니다. Monty Hall 풀이2: LOTP(Law of Total Probability)마찬가지로 참가자는 어떤 문 뒤에 자동차가 있는지 알기 원합니다. S는 참가자가 자동차가 있는 문을 선택하는 경우를 의미하며 Monty의 물음에 따라 항상 선택한 문을 변경한다고 가정합니다. $D_{j}, j \\in 1,2,3$는 자동차가 존재하는 문 번호입니다. $P(S)$는 아래와 같이 계산할 수 있습니다.$P(S) = P(S \\mid D_{1})\\frac{1}{3} + P(S \\mid D_{2})\\frac{1}{3} + P(S \\mid D_{3})\\frac{1}{3}$자동차가 1번 문에 있다고 가정하면, $= 0 + 1\\frac{1}{3} + 1\\frac{1}{3} = \\frac{2}{3}$ Simpson’s Paradox일부 부분에서 성립하는 대소관계는 전체로 보았을 때 역전될 수 있다는 역설입니다.심슨 가족이 사는 스프링필드에 Dr.Hibbert와 Dr.Nick 두 명의 의사가 있습니다. 이들은 심장수술과 반창고 시술 두 가지 서비스를 제공합니다. 100번을 시도했을 때 성공, 실패 횟수는 아래와 같습니다.| Header | Heart | Band aid || Success | 70 | 10 || Failure | 20 | 0 | | Header | Heart | Band aid || Success | 2 | 81 || Failure | 8 | 9 | Dr.Hibbert는 성공률이 80%이고 Dr.Nick은 83%로 전체 성공률은 더 높습니다. 하지만 난이도가 높은 심장 수술의 성공률을 보면 Dr.Hibbert가 더 높습니다. 위 상황을 수식으로 표현해 봅니다. A: 수술 성공 B: Dr.Nick이 수술한 경우 C: 심장 수술 $P(A \\mid B, C) &amp;lt; P(A \\mid B^{c}, C)$ $P(A \\mid B, C^{c}) &amp;lt; P(A \\mid B, C^{c})$ $P(A \\mid B) &amp;gt; P(A \\mid B^{c})$ 수술의 종류(심장 수술($C$), 반찬고 시술($C^{c}$)를 고려했을 때, 모두 Dr.Hibbert가 시행한 경우($B^{c}$) 성공률이 더 높습니다. 하지만 수술의 종류를 고려하지 않은 경우 Dr.Nick이 시행한 경우 성공률이 더 높습니다. 여기에서 심장 수술($C$)을 confounder(교란변수)라고 합니다. 적절한 confounder에 의한 conditional probability를 확인하지 않으면 상황에 대한 그릇된 판단을 내릴 수도 있습니다. Simpson&#39;s paradox는 모두 위 식으로 표현할 수 있습니다. ## IMO*** Monty hall 문제는 볼 때마다 헷갈렸는데 수형도를 통해 푸는 방법을 잘 기억해 두어야 겠습니다. Simpson&#39;s paradox의 개념도 잘 알아 두어야 겠습니다." }, { "title": "ch5. Conditioning Continued, Law of Total Probability", "url": "/posts/ch5_Conditioning_Continued_Law_of_Total_Probability/", "categories": "Study, L-Statistics", "tags": "statistics, harbard, law of total probability, conditional probability, prior, posterior, conditional independence", "date": "2022-06-23 12:05:32 +0900", "snippet": "Intro전체 확률의 법칙을 이해하고 문제풀이에 적용할 수 있으며, 조건부 독립의 개념을 이해합니다. How to Solve the Problem어떤 문제를 풀 때 다음 두 가지 방법을 적용해 볼 수 있습니다. 간단한 케이스와 극단적인 케이스에 적용해보기 문제를 작은 문제들로 쪼개서 생각해보기 Law of Total Probability (전체 확률의 법칙) law of Total Probability$P(B \\mid S)$를 구할 때, S를 서로소 관계에 있는 $A_{1}, A_{2}, A_{3}, A_{4}$로 쪼개서 계산하면 쉽게 구할 수 있습니다. 이것을 low of total probability (전체 확률의 법칙) 이라고 합니다.$P(B) = P(B \\cap A_{1}) + P(B \\cap A_{2}) +, …, + P(B \\cap A_{n})$$ = P(B \\mid A_{1})P(A_{1}) + P(B \\mid A_{2})P(A_{2}), …, + P(B \\mid A_{n})P(A_{n})$ Conditional Probability가 중요한 이유 It’s own right!조건부 확률은 어떤 단서가 있을 때 이 단서를 기반으로 확률을 업데이트 하는 것입니다. 이 자체가 굉장히 중요한 개념입니다. Unconditional probability를 구하기 위해 이를 작은 조각들로 쪼갤 때 conditional probability가 필요합니다. 예를 들어 Unconditional probability인 P(B)를 구하기 위해서 $P(B \\mid A_{1})P(A_{1}) + P(B \\mid A_{2})P(A_{2}), …, + P(B \\mid A_{n})P(A_{n})$와 같이 conditional probability인 $P(B \\mid A_{n})$이 필요합니다. Conditional Probability 예제 문제 카드 뽑기: 52장의 카드 중 2장의 카드를 뽑는 경우, 다음 두 가지 case를 생각해 봅니다. $P(both aces \\mid have an ace)$ $= \\frac{P(both aces)}{P(have ace)}$ $= \\frac{\\binom{4}{2}/\\binom{52}{2}}{1 - \\binom{48}{2}/\\binom{52}{2}}$$= \\frac{1}{33}$ $P(both aces \\mid have an ace of spade)$ $= \\frac{3}{51}$ $= \\frac{1}{17}$ 한 장의 카드는 spade ace로 정해져 있으므로, 나머지 한 장의 카드를 남은 ace 세 장 중 하나를 뽑을 확률입니다. 환자가 병에 걸렸을 확률: 인구의 1%가 걸리는 병이 있습니다. 이 병을 검사하는 방법 정확도가 95%라고 가정합니다. 검사가 양성으로 나왔을 때 환자가 병에 걸렸을 case를 생각해 봅니다. D: 환자가 병을 가지는 경우 T: 환자의 검사 결과가 양성인 경우 $P(T \\mid D) = 0.95$ $P(T^{c} \\mid D^{c})$ 하지만 환자가 알고자 원하는 것은 무엇일까요? 바로 $P(D \\mid T)$입니다. $P(D \\mid T) = \\frac{P(T \\mid D)P(D)}{P(T)}$ $\\frac{P(T \\mid D)P(D)}{P(T \\mid D)P(D) + P(T \\mid D^{c})P(D^{c})}$ $\\approx 0.16$ Conditional Probability에서 자주 하는 실수들 Prosecutor’s fallacy: $P(A \\mid B)$와 $P(B \\mid A)$를 혼동하는 case입니다. 법정 사례를 한 가지 살펴봅니다. Sally Clark case: 영국인 Sally Clark의 두 아이가 영아돌연사증후군(SIDS)로 돌연 사망합니다. 검찰측 전문가는 아이가 설명하기 힘든 이유로 사망할 확률은 $\\frac{1}{8500}$이라 설명했고 두 명의 아이가 사망했으니 $\\frac{1}{8500}\\frac{1}{8500} \\approx \\frac{1}{73*10^6}$의 확률로 그녀가 결백하다고 주장했습니다. 하지만 우리가 알아야 할 값은 $P(innocence \\mid evidence)$이며 위 주장에서는 $P(innocence)$ 항목을 고려치 않고 있습니다. 또한 두 아이의 죽음이 유전적 결함 등으로 연결될 수 있으나 검찰측 전문가는 독립사건으로 가정하고 있습니다. 결국 Sally Clark는 몇 년 후 무죄로 판정되어 출소했으나 얼마 지나지 않아 사망했습니다. 사전확률(prior)과 사후확률(posterior) 혼동: 사전확률(prior)은 $P(A)$, 사후확률(posterior)은 $P(A \\mid B)$입니다. Conditional independent와 Independent 혼동: Conditional independent의 정의는 다음과 같습니다. $P(A \\cap B \\mid C) = P(A \\mid C)P(B \\mid C)$ 그렇다면 conditional independent하면 independent 할까요? 정답은 ‘아니오’ 입니다. 체스 게임을 예로 들어봅시다. 실력을 알 수 없는 만나본 적 없는 상대와 체스 게임을 합니다. 상대방이 얼마나 체스를 잘 하는지 아무런 정보가 없습니다. 이렇게 상대방의 실력을 모르는 상태에서 체스 게임을 한다고 가정할 때 체스 게임들은 conditional independent 합니다. 하지만 이것이 independent를 의미하지 않습니다. 체스 게임을 반복할 수록 상대방의 실력을 가늠할 수 있는 척도가 마련되지 때문입니다. 반대로 independent하면 conditional independent 할까요? 정답은 ‘아니오’ 입니다. 화재경보기 예제를 생각해 봅시다. 화재경보기가 울리는 사건을 A, 화재가 난 사건을 F, 팝콘을 튀기는 사건을 C라고 합니다. A는 F 혹은 C에 의해 일어나며 F, C는 independent 하다고 가정합니다. 여기서 $P(F \\mid A, C^{c}) = 1$이라고 할 수 있습니다. 화재경보기가 작동한 조건에서 팝콘을 튀기지 않았다면 화재가 났음을 알 수 있습니다. 따라서 A 조건하에서 F, C는 dependent하다고 볼 수 있습니다. IMOConditional Probability를 확실하게 체득하지 못했으나 반복해서 강의를 듣고 다른 도서 내용도 참고해봐야 겠습니다." }, { "title": "(EDWITH-KOBIC) NGS 데이터 분석 기초편", "url": "/posts/Certificate_NGS_analysis/", "categories": "Study, L-Certificate", "tags": "certificate, NGS, KOBIC", "date": "2022-06-22 22:20:10 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "ch4. Conditional Probability", "url": "/posts/ch4_Conditional_Probability/", "categories": "Study, L-Statistics", "tags": "statistics, harbard, probability, independence, newton-pepys problem, conditional probability, bayes' theorem", "date": "2022-06-19 12:52:12 +0900", "snippet": "Intro사건의 독립(independence)과 조건부 확률(conditional probability)의 개념을 이해하고 적용할 수 있습니다. Independence독립의 정의는 다음과 같습니다. Events A, B are independnet if $P(A \\cap B) = P(A)P(B)$Note: completely different from disjointness(서로소)사건 A, B가 독립이라면 사건 A의 발생은 B의 발생 여부에 어떤 영향도 끼치지 않습니다.혼동하기 쉬운 개념으로 서로소(disjoint)가 있습니다. 사건 A, B가 서로소라면 A가 발생했을 때 B는 발생할 수 없는 경우입니다. 독립과 완전히 다른 개념입니다. Newton-Pepys Problem (1963)Samuel Pepys는 유명한 작가입니다. 어느 날 도박에 관한 한 가지 문제에 대한 답을 얻기 위해 Newton에게 편지를 썼습니다.여섯 개의 면이 나올 확률이 동일한 정육면체 주사위가 있습니다. 다음 세 가지 경우 중 가장 확률이 높은 것은 무엇일까요? A. at least one 6 with 6 dice B. at least two 6&#39;s with 12 dice C. at least three 6&#39;s with 18 dice‘at least’라는 표현이 나오면 합집합을 떠올립니다. 또한 합집합의 여집합은 교집합니다. 모든 사건이 독립이므로 교집합은 각 사건 확률의 곱셈으로 계산할 수 있습니다. $P(A) = 1 - (\\frac{5}{6})^6 \\approx 0.665$ $P(B)$ = 1 - (6이 한 번도 안 나올 확률 + 6이 딱 한 번 나올 확률) $= 1 - {(\\frac{5}{6})^{12} + \\frac{1}{6} * (\\frac{5}{6})^{11} * 12} \\approx 0.619$ $P(C) = 1 - \\Sigma_{k=0}^{2}(\\frac{18}{k})(\\frac{1}{6})^k(\\frac{5}{6})^{18-k} \\approx 0.597$따라서 A가 발생할 확률이 가장 높습니다. Conditional Probability Conditioning is the soul of statistics.How should you update probability/beliefs/uncertainty based on new evidence? Contional probability는 새로운 정보를 얻었을 때, 기존에 가지고 있던 probability/beliefs/uncertainty를 어떻게 업데이트 하는가? 에 대한 답을 찾는 과정입니다.정의는 아래와 같습니다. $P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, if P(B)&amp;gt;0$정의를 이해하기 위해 두 가지 다른 직관적 접근을 알아보겠습니다.직관적 접근 1) 조약돌 세계관 조약돌 세계관S 안에 q개의 조약돌이 있습니다. q개 조약돌들이 질량의 합은 1이라고 가정합니다. 조약돌 세계관$P(A \\cup B) = P(A \\mid B)P(B)$ 경우를 생각해 봅니다. $P(A \\mid B)$의 의미는, $B^{c}$에 있는 모든 조약돌을 무시하고 B가 새로운 조약돌 세계라고 가정할 때 B 안에서 A도 발생할 확률입니다. 그런데 B에 있는 조약돌들의 질량의 합이 1이 안되기 때문에 재규격화(renormalize, 어떤 상수를 곱하여 전체 질량의 합이 다시 1이 되도록 하는 것)합니다. 따라서 $P(A \\cap B)$를 P(B)로 나누어 줍니다.$P(A \\mid B) = \\frac{P(A \\cap B)}{P(B)}, if P(B)&amp;gt;0$직관적 접근 2) 빈도학파(Frequentist) 세계관같은 실험을 계속 반복하여 수 많은 시행 끝에 얻어낸 사건이 일어나는 비율을 확률로 보는 세계관 입니다. 따라서 왜 확률을 $\\frac{P(A \\cap B)}{P(B)}$ 식에 따라 계산하는지 알 수 있습니다. B 사건 하에서 A 사건이 발생할 확률은, A와 B가 함께 일어날 확률을 B가 일어날 확률로 나눠주는 것입니다.직관적 접근의 결과를 아래와 같이 정리할 수 있습니다.정리 1) $P(A \\cap B) = P(B)P(A \\mid B) = P(A)P(B \\mid A)$정리 2) $P(A_{1}, A_{2}, …, A_{n}) = P(A_{1})P(A_{2} \\mid A_{1})P(A_{3} \\mid A_{1},A_{2}) … P(A_{n} \\mid A_{1}, …, A_{n-1})$정리 3) $P(A \\mid B) = \\frac{P(B \\mid A)P(A)}{P(B)}$, Bayes’ Theorem (베이즈 정리)IMO확률론에서 중요한 이론 중 하나로 자주 등장하는 Bayes’ theorem(베이즈 정리)의 정의와 의미를 배웠습니다." }, { "title": "Phred Score (Base Call Quality Score)", "url": "/posts/Phred_Score/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, fastq, phred score, NGS", "date": "2022-06-18 11:05:40 +0900", "snippet": "DefinitionSequencing 결과로 나온 base call이 얼마나 정확한지 나타내는 수치입니다. Fastq 파일 내 각 read의 네 번 째 line을 구성합니다. Phred+33 encoding과 ASCII 표기법을 사용합니다. 아래와 같은 계산식으로 score를 산출합니다.$ Q = -10log_{10}^{(e)} $e는 base call 결과가 틀렸을 확률을 의미합니다.결과값을 음수로 변환하기 때문에 x축(e)이 증가하면 y축(phred score)은 감소합니다. 그리고 y축은 log scale에 따라 변화하기 때문에 x축 값이 $10^{n}$ 단위로 증가/감소하면 y축 값은 n 단위로 증가/감소 합니다.Phred score 20은 e가 0.01임을 의미합니다. 곧, base call error 확률이 1%이며, 100개 base call 중에서 1개의 error base를 포함하고 있음을 나타냅니다. 동시에 call accuracy가 99%임을 뜻합니다.Phred score 10 = probability of error 10% = call accuracy 90%Phred score 20 = probability of error 1% = call accuracy 99%Phred score 30 = probability of error 0.1% = call accuracy 99.9% Phred+33 encoding과 ASCII 표기법Phred score는 왜 +33 encoding과 ASCII 표기법을 사용할까요?Illumina sequencer 데이터는 일반적으로 phred score 0~40 범위 안에서 출력됩니다. 0~9는 1byte를 사용하지만, 10 이상부터는 2byte를 사용합니다. 수 백 만 개의 read가 포함된 fastq 파일에서 quality score를 효율적으로 저장하기 위해서는 2byte보다 1byte 정보로 quality를 표현하는 것이 현명한 선택입니다. 또한 base와 quality score는 1:1 match이므로 반드시 한 자리수로 표현해야 fastq 파일에서 정확히 사용할 수 있습니다. ASCII 표기법은 하나의 character가 1byte를 차지하므로 위 두 가지 목적에 적합합니다.ASCII(American Standard Code for Information Interchange, 미국 정보 교환 표준 부호) 표기법은 1963년 미국 ANSI에서 표준화한 정보교환용 7bit(8bit=1byte) 부호체계 입니다. 1byte 중 7bit만 사용하도록 만든 이유는 나머지 1bit를 통신 에러 검출 용도로 비워두었기 때문입니다. 000(0x00)부터 127(0x7F)까지 총 128개 부호가 사용됩니다. Dec Hx Oct Char 0 0 000 NUL(null) 1 1 001 SOH(start of heading) 2 2 002 STX (start of text) 3 3 003 ETX(end of text) 4 4 004 EOT(end of transmission) 5 5 005 ENQ(enquiry) 6 6 006 ACK(acknowledge) 7 7 007 BEL(bell) 8 8 010 BS(backspace) 9 9 011 TAB(horizontal tab) 10 A 012 LF(NL line feed, new line) 11 B 013 VT(vertical tab) 12 C 014 FF(NP from feed, new page) 13 D 015 CR(carriage return) 14 E 016 SO(shift out) 15 F 017 SI(shift in) 16 10 020 DLE(data link escape) 17 11 021 DC1(device control 1) 18 12 022 DC2(device control 2) 19 13 023 DC3(device control 3) 20 14 024 DC4(device control 4) 21 15 025 NAK(negative acknoledge) 22 16 026 SYN(synchronous idle) 23 17 027 ETB(end of trans. block) 24 18 030 CAN(cancel) 25 19 031 EM(end of medium) 26 1A 032 SUB(substitute) 27 1B 033 ESC(escape) 28 1C 034 FS(file separator) 29 1D 035 FS(group separator) 30 1E 036 RS(record separator) 31 1F 037 US(unit separator) 32 20 040 Space Dec 기준 0~32는 print가 불가능한 제어 문자입니다. 9~13, 32는 공백이 포함된 문자입니다. 따라서 quality score로 사용 불가한 위 문자를 제외하고 33부터 표기합니다.(Phred+33) Dec Hx Oct Char 33 21 041 ! 34 22 042 ” 35 23 043 # 36 24 044 $ 37 25 045 % 38 26 046 &amp;amp; 39 27 047 ’ 40 28 050 ( 41 29 051 ) 42 2A 052 * 43 2B 053 + 44 2C 054 , 45 2D 055 - 46 2E 056 . 47 2F 057 / 48 30 060 0 49 31 061 1 50 32 062 2 51 33 063 3 52 34 064 4 53 35 065 5 54 36 066 6 55 37 067 7 56 38 070 8 57 39 071 9 58 3A 072 : 59 3B 073 ; 60 3C 074 &amp;lt; 61 3D 075 = 62 3E 076 &amp;gt; 63 3F 077 ? 64 40 100 @ 65 41 101 A 66 42 102 B 67 43 103 C 68 44 104 D 69 45 105 E 70 46 106 F 71 47 107 G 72 48 110 H 73 49 111 I 앞서 설명드린 내용처럼 illumina sequencer 데이터는 일반적으로 phred score 0~40 범위 안에서 출력됩니다. 즉, 위 !(33=0+33)부터 I(73=40+33)까지 ASCII 문자가 quality score로 사용됩니다. 물론 아래 문자도 사용될 수 있습니다. Dec Hx Oct Char 74 4A 112 J 75 4B 113 K 76 4C 114 L 77 4D 115 M 78 4E 116 N 79 4F 117 O 80 50 120 P 81 51 121 Q 82 52 122 R 83 53 123 S 84 54 124 T 85 55 125 U 86 56 126 V 87 57 127 W 88 58 128 X 89 59 129 Y 90 5A 132 Z 91 5B 133 [ 92 5C 134 / 93 5D 135 ] 94 5E 136 ^ 95 5F 137 _ 96 60 140 ` 97 61 141 a 98 62 142 b 99 63 143 c 100 64 144 d 101 65 145 e 102 66 146 f 103 67 147 g 104 68 148 h 105 69 149 i 106 6A 152 j 107 6B 153 k 108 6C 154 l 109 6D 155 m 110 6E 156 n 111 6F 157 o 112 70 160 p 113 71 161 q 114 72 162 r 115 73 163 s 116 74 164 t 117 75 165 u 118 76 166 v 119 77 167 w 120 78 170 x 121 79 171 y 122 7A 172 z 123 7B 173 { 124 7C 174 | 125 7D 175 } 126 7E 176 ~ 127 7F 177 DEL Phred score와 ASCII 문자표를 사용하는 이유, 방식까지 살펴봤습니다." }, { "title": "Fastq", "url": "/posts/Fastq/", "categories": "Bioinformatics, NGS", "tags": "BI, bioinformatics, fastq, NGS", "date": "2022-06-16 12:10:02 +0900", "snippet": "DefinitionFastq는 NGS 결과로 생성된 sequence data와 이에 상응하는 quality score 정보를 담고 있는 text 파일입니다.Bioinformatics 분야의 standard data format이기 때문에 대부분 분석 tool에서 input으로 사용합니다. Fastq Format Fastq formatFastq는 한 개 read당 네 개 lines로 구성되어 있습니다. Line1 (sequence identifier): ‘@’ 기호로 시작합니다. Sequencing run과 cluster 관련 정보를 담고 있습니다. Value Description @ sequence identifier start character NG501674 uniqe instrument id 510 run id HTVWKAFX3 flowcell id 1 flocell lane 11101 tile number within the flowcell lane 11906 x-coordinate of the cluster within the tile 1035 y-coordinate of the cluster within the tile 1 read number [1, 2 (if paired-end or mate-pair reads only)] N N means this read is NOT filtered (=passed), Y otherwise 0 0 when none of the control bits are on, otherwise it is an even number GAATCTGA index sequence Line2 (sequence): Read의 sequence 정보를 담고 있습니다. Line3 (separator): ‘+’ 기호로 시작합니다. Sequence와 quality를 분리하는 구분자 입니다. Line4 (base call quality score): Line2의 각각 sequence에 대한 quality 값 정보를 담고 있습니다. Phred+33 encoding 방식을 따르며 quality score 표기는 ASCII 문자로 합니다. Open FastqFastq 파일은 보통 몇 백 만개 단위의 reads 정보를 담고 있으며 파일 size 또한 Gb 단위입니다. 윈도우 OS 환경에서 이렇게 큰 파일을 열고 작업하는 것은 무리입니다. 그럼에도 불구하고 단순히 fastq 파일을 열어보고 싶다거나 작은 size의 fastq 파일을 다룰 때는 NotePad++, Sublime Text와 같은 text editor를 사용할 수 있습니다." }, { "title": "ch3. Birthday Problem, Properties of Probability", "url": "/posts/ch3_Birthday_Problem_Properties_of_Probability/", "categories": "Study, L-Statistics", "tags": "statistics, harbard, probability, birthday problem, Inclusion-Exclusion Principle", "date": "2022-06-12 13:02:46 +0900", "snippet": "Intro확률의 non-naive한 정의의 공리를 이용하여 확률의 특성을 증명할 수 있습니다. 포함-배제의 원리를 이해합니다. Birthday ProblemK명의 사람이 있을 때 2명의 생일이 같을 확률을 생각해 봅니다. 1년은 365일이고 모든 날이 생일일 확률은 같다고 가정합니다. 또한 모든 생일은 독립이라고 가정합니다. K &amp;gt; 365: 확률은 1입니다. 365개의 상자가 있고 각각 Jan1, Jan2, …, Dec31로 labeling 합니다. K가 365보다 클 경우 모든 box에 dot이 1개 이상 들어갑니다. (Pigeon hole principle) 확률은 1입니다. K ≤ 365: 여사건을 생각해 봅니다. $P(no match) = \\frac{365364363…(365-k+1)}{365^{k}}$ P(match)를 계산하면, 50.6%, if k=23 97%, if k=50 99.999%, if k=100 가 나옵니다. 이 문제를 좀 더 직관적으로 살펴볼까요? 여기에서 중요한 것은 k명에서 2명을 뽑는 경우의 수 입니다. 이를 수식으로 표현하면, $\\binom{k}{2}$ = $\\frac{k(k-1)}{2}$ $\\binom{23}{2}$ = $\\frac{23*22}{2}$ = 253 253쌍의 경우의 수가 나옵니다. 충분히 같은 수를 가진 쌍이 나올 수 있습니다. 확률의 특성ch2. Story Proofs Axioms of Probability에서 확률의 non-naive 정의와 두 가지 정리를 살펴봤습니다. $P(\\emptyset)=0, p(S)=1$ $P(\\cup_{n=1}^{\\infty}A_{n}) = \\sum_{n=1}^{\\infty}P(A_{n})$ if $A_{1}, A_{2}$, … are disjoint (non-overlapping) 이 두 가지 정리로 모든 확률 특성을 설명할 수 있습니다. $P(A^c) = 1 - P(A)$ 증명: $1 = P(S) = P(A\\cup A^c) = P(A) + P(A^c)$ since $A \\cap A^c = \\varnothing$ if $A \\subseteq B, then P(A) \\subseteq P(B)$ 증명: $B = A \\cup (B \\cap A^c), disjoint$ $P(B) = P(A) + P(B \\cap A^c) ≥ P(A)$ 확률은 항상 0보다 크거나 같으므로 P(A)보다 크거나 같습니다. $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$ 증명: $P(A \\cup B) = P(A \\cup (B \\cap A^c)) = P(A) + P(B \\cap A^c)$ Inclusion-Exclusion Principle$P(A_{1} \\cup A_{2} \\cup … \\cup A_{n}) = \\sum_{j=1}^{n} P(A_{j}) - \\sum_{i&amp;lt;j} P(A_{i} \\cap A_{j}) + \\sum_{i&amp;lt;j&amp;lt;k} P(A_{i} \\cap A_{j} \\cap A_{k}), …, (-1)^{n+1} P(A_{1} \\cap A_{2}, …, \\cap A_{n})$Inclusion-Exclusion Principle을 활용한 문제를 살펴 보겠습니다. deMontmort’s Problem(1713)은 matching problem으로도 부릅니다. 카드를 순서대로 배열한 뒤 카드 번호와 순서가 일치하면 승리하는 게임입니다. 이 확률을 수식으로 표현해 봅니다.$P(A_{j}) = \\frac{1}{n}$랜덤으로 섞인 카드 1, 2, …, n 중에서 카드 j가 j번째 순서로 놓이는 사건을 A라고 할 때 확률입니다.$P(A_{1} \\cap A_{2}) = \\frac{(n-2)!}{n!} = \\frac{1}{n(n-1)}$카드1, 카드2가 1번, 2번 위치에 존재하고 나머지 카드들은 임의 배치될 확률입니다.$P(A_{1} \\cap A_{2}, …, \\cap A_{k}) = \\frac{(n-k)!}{n!}$모든 카드가 순서대로 배치될 확률입니다. 그러므로 구하고자 하는 확률은, $P(A_{1} \\cup A_{2}, …, \\cup A_{n})$ = $n\\frac{1}{n} - \\frac{n(n-1)}{2!}\\frac{1}{n(n-1)} + \\frac{n(n-1)(n-2)}{3!}\\frac{1}{n(n-1)(n-2)} …$ = $1 - \\frac{1}{2!} + \\frac{1}{3!} … + (-1)^{n+1}\\frac{1}{n!}$ 테일러 급수 $\\approx 1 - \\frac{1}{e}$ 에 근사합니다. IMOBirthday problem을 보며 사람의 직관과 실제 확률의 차이가 커서 놀랐습니다." }, { "title": "ch2. Story Proofs, Axioms of Probability", "url": "/posts/ch2_Story_Proofs_Axioms_of_Probability/", "categories": "Study, L-Statistics", "tags": "statistics, harbard, probability, story proofs", "date": "2022-06-10 08:12:50 +0900", "snippet": "Intro확률의 naive한 정의로 접근하기 어려운 경우를 알아내고, story proof를 통한 접근을 학습합니다. 또한 확률의 non-naive한 정의를 위한 공리 2가지를 이해하고 적용할 수 있습니다. Tips for Solving Problems (header) order matter order doesn’t matter replace $n^{k}$ $\\binom{n+k-1}{k}$ doesn’t replace n(n-1)(n-2)…(n-k+1) $\\binom{n}{k}$ Sampling table에서 대부분 multiplication rule에 따라 설명되지만, ‘replace-order doesn’t matter’인 경우 그렇지 않습니다.정답을 확인할 때 다음과 같은 방법을 사용할 수 있습니다. Labeling: Data에 사람, 구슬 등 object를 labeling하고 풀어봅니다. 숫자 대입: 정답에 실제 숫자를 대입하여 성립하는지 확인합니다. 위 sampling table 예시를 들어보면, 일반적인 경우: k=1을 대입합니다. → $\\binom{n}{1}$ 극단적인 경우: k=0을 대입합니다. → $\\binom{n-1}{0}$ 계산하기 간단하지만 당연하지 않은 경우: n=2를 대입합니다. → $\\binom{n+1}{k}$ = $\\binom{k+1}{1}$ = $k+1$ 두 개의 상자가 있다고 가정합니다.(n=2) 상자를 선택할 때마다 상자 안에 dot으로 표시합니다. 총 7번을 선택합니다.(k=7) 이 때 첫 번째 상자에 dot을 표시할 수 있는 경우의 수는 0, 1, 2, …, k개로 총 k+1가지 입니다. Example 일반화: n개의 상자에 k개의 구별 불가능한 object를 넣을 수 있는 경우의 수로 확장해 봅니다. Example 위 그림은 n개의 구슬을 k개의 상자에 넣는 경우의 수는 몇 가지인가?라는 물음에 대한 예시입니다. 구슬과 같이 실물이 있는 물체는 labeling이 가능하며 서로 구별이 가능합니다. 따라서 확률의 naive한 정의로 접근 가능합니다. 하지만 물리학과 같은 경우 object들이 항상 구별 가능한 것이 아니므로 이와 같은 접근이 어렵습니다. 따라서 아래 그림과 같은 경우로 변경하여 생각할 수 있습니다. 아래 그림은, n개의 원 사이에 k-1개의 구분선을 넣는 경우의 수는 몇 가지인가?라는 물음에 대한 예시입니다. n+k-1개의 위치에 구슬과 구분선을 배열하는 것과 같습니다. 원의 위치를 먼저 정하면 구분선의 위치가 결정됩니다. 구분선의 위치를 먼저 정하면 원의 위치가 결정됩니다. 따라서 다음 등식이 성립합니다. $\\binom{n+k-1}{n-1}$ = $\\binom{n+k-1}{k}$ Story Proof상황 해석을 통한 증명입니다.(Proof by interpretation) 다음과 같은 예시를 생각해 볼 수 있습니다. $\\binom{n}{k} = \\binom{n}{n-k}$ 앞서 증명한 내용과 같습니다. n개 중 k개를 선택하는 경우의 수는 n개 중 n-k개를 선택하는 경우의 수와 같습니다. $n\\binom{n-1}{k-1} = k\\binom{n}{k}$ n명 중 동아리에 들어갈 k명을 선발하고 그 중 한 명을 대표로 선정하는 경우를 생각해 봅니다. 좌변은 대표를 한 명 선정합니다. 이후 n-1명 중 동아리에 들어갈 k-1명을 선발합니다. 우변은 n명 중 동아리에 들어갈 k명을 선발합니다. 이후 k명 중 대표 한 명을 선정합니다. 두 수식이 같다는 것이 증명 되었습니다. $\\binom{m+n}{k} = \\sum_{j=0}^{k}\\binom{m}{j}\\binom{n}{k-j}$ 이 수식은 Vandermonde 항등식으로도 부릅니다. 대수를 이용해 증명하는 것은 매우 복잡합니다. 이항정리로 증명하는 것도 매우 복잡합니다. Story proof를 통해 증명해 봅니다. 두 개의 그룹 m, n에서 각각 사람을 뽑아 총 k명을 뽑는 경우의 수를 생각합니다. 그룹 m에서 j명을 선택한 경우 그룹 n에서는 k-j명을 선택합니다. 중복으로 counting한 경우가 없으므로 multiplication rule에 따라 두 개 그룹에서 선별한 경우를 곱하고 j는 0~k명 까지 모든 경우의 수를 더해줍니다. 확률의 non-naive한 정의의 공의Sample space S와 function P가 있습니다. Event A는 S의 부분집합이며 P는 A를 input으로 받아서 $P(A)\\in[0,1]$을 output으로 내놓습니다.이 정의를 만족시키기 위해서는 다음 두 가지 정리가 필요합니다. $P(\\emptyset)=0, p(S)=1$ $P(\\cup_{n=1}^{\\infin}A_{n}) = \\sum_{n=1}^{\\infin}P(A_{n})$ if $A_{1}, A_{2}$, … are disjoint (non-overlapping) IMO기억나는 재생만 헤아려도 4회 이상입니다. 재생할 때마다 새로운 내용이 들립니다. 간단한 내용처럼 보였지만 반복해서 들으니 놓쳤거나 이해하지 못했던 내용이 많았습니다. Story proof 방식이 아직 익숙하지 않지만 대수적으로 증명/해결하려는 시도보다 적극적으로 활용해야 겠다고 생각합니다." }, { "title": "(EDWITH-KOBIC) Python 기초", "url": "/posts/Certificate_PYTHON_inter/", "categories": "Study, L-Certificate", "tags": "certificate, python, KOBIC", "date": "2022-06-07 23:15:40 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "ch1. Probability and Counting", "url": "/posts/ch1_Probability_and_Counting/", "categories": "Study, L-Statistics", "tags": "statistics, harbard, sample space, event, probability, counting, binomial coefficient", "date": "2022-06-06 21:03:21 +0900", "snippet": "Intro확률의 기초 용어(표본공간과 사건, 셈 원리)를 이해하고 적용할 수 있습니다. Statistics (통계학)Statistics is the logic of uncertainty.확률은 불확실성을 계량화하는 것을 가능하게 해줍니다. Sample Space (S, 표본공간)A sample space is the set of all possible outcomes of an experiment.표본공간은 어떤 실험에서 가능한 모든 경우의 집합을 의미합니다. Event (A, 사건)An event is a subset of the sample space. Probability (P, 확률)확률의 간단한 정의는 아래와 같습니다.$P(A) = \\frac{count of favorable outcomes}{count of possible outcomes}$여기서 내포하고 있는 두 가지 가정이 있습니다. 항상 이 가정이 만족되는 것은 아니므로 적용 불가한 경우가 있습니다. 모든 evenet가 발생할 probability는 같습니다. Sample space는 유한합니다.여기서 possible outcomes를 매번 일일히 counting 하는 것은 불가능합니다. 어떻게 counting 해야할까요? Counting Multiplication Rule 만약 첫 번째 experiment가 $n_{1}$개의 possible outcomes를 가지고 두 번째 experiment가 $n_{2}$개를 가지고, …, r 번째 experiment가 $n_{r}$개를 가진다면, overall possible outcomes = $n_{1} * n_{2} *, … *, n_{r}$ Binomial coefficient(이항계수) $\\binom{n}{k} = \\frac{n!}{(n-k)!k!}$ (if k&amp;gt;n) multiplication rule을 적용할 수 있습니다. n명 중 한 명을 뽑는 경우의 수는 n, 다음 한 명을 뽑는 경우의 수는 (n-1), …, k번째 한 명을 뽑는 경우의 수는 (n-k+1)입니다. 뽑는 순서는 상관 없으므로 k!로 나눠줍니다. 좌변의 분모와 분자를 소거하면 우변과 같습니다. $\\frac{n(n-1)(n-2)…(n-k+1)}{k!} = \\frac{n!}{(n-k)!k!}$ Sampling Table전체 n개의 sample 중 k개의 sample을 선택할 때 고려해야 할 사항과 그 결과값에 관한 table 입니다. (header) order matter order doesn’t matter replace $n^{k}$ $\\binom{n+k-1}{k}$ doesn’t replace n(n-1)(n-2)…(n-k+1) $\\binom{n}{k}$ " }, { "title": "ch1. Basic Mathmatics", "url": "/posts/ch1_Basic_Mathmatics/", "categories": "Study, B-Guide_to_Linear_Algebra", "tags": "linear algebra, study, math", "date": "2022-06-04 16:02:38 +0900", "snippet": "이 책을 시작하며현대 과학과 엔지니어링 분야에서 실제 현상을 이해하고 실험 결과를 예측하며 유용한 기술을 개발할 수 있는 고급 모델을 고안합니다. 이러한 학문 분야에서는 수학적 모델이 활용되므로 수학 학습이 필요합니다.이 책에서 배울 수 있는 선형대수학 기법은 현존하는 수학적 모델링 도구 중 가장 강력합니다. 선형대수학의 핵심은 선형성(linearity)이라는 아주 간단한 개념입니다. 어떤 함수 f가 다음 방벚ㅇ식을 만족하면 선형입니다.$f(ax_1 + bx_2) = af(x_1) + bf(x_2)$각 변수 x에 상수 a, b를 곱하고 그 결과를 더함으로써 변수들의 집합을 구성하는데, 이 표현식을 선형결합(linear combination)이라는 용어로 설명합니다.선형대수학의 모든 것을 살펴봤습니다. 이 책의 나머지 부분에서는 그저 더 자세하게 설명할 뿐입니다.선형모델을 사용하는 몇 가지 특별한 이유가 있습니다. 선형모델이 실제 현상을 근사하는 데 매우 뛰어납니다. 비선형 현상이 나타내는 선형모델을 선형근사법(linear approximation)이라고 합니다. 선형모델을 그 모델의 입력 또는 출력의 비선형 변환과 결합하여 비선형 현상을 설명할 수 있습니다. 머린러닝에서 종종 사용됩니다. 커널 기법은 선형모델의 입력에 대한 임의의 비선형 변환입니다. 시그모이드 활성화 곡선(sifmoid activation curve)은 부드럽게 변화하는 선형모델의 출력을 딱딱한 예/아니오 결정, on/off 명령, 혹은 0/1 값 등으로 변환하는 데 사용됩니다. 선형변환은 ‘벡터 함수’로 생각하고 익숙한 정규 함수의 성질과 유사하게 이해할 수 잇습니다. 방정식 풀이 (1.1) 등호(=)는 좌변과 우변의 값이 같다는 의미입니다. 이 등식이 계속 성립하기 위해서는 방정식의 좌변에 적용하는 모든 변경 사항을 방정식의 우변에도 동일하게 적용해야 합니다. 수 (1.2) 수는 물건을 세고, 측정하고, 정량화하고, 계산하는 데 사용하는 기본적인 수단입니다. 수의 범주는 다음과 같습니다. 자연수: N = {0, 1, 2, 3, 4, 5, …} 정수: Z = {…, -2, -1, 0, 1, 2, …} 유리수: $\\mathbb{Q} = {5/3, 22/7, 1.5, 0.125, -7, …}$ 실수: $\\mathbb{R} = {-1, 0, \\sqrt{2}, \\pi, 4.94, …}$ 복소수: $\\mathbb{C} = {-1, 0, 1, i, 1+i, 2+3i, …}$ 이차 방정식 풀이 (1.6) 근의 공식 방정식 $ax^2 + bx + c = 0$의 해는 다음과 같습니다. $x_1 = \\frac{-b + \\sqrt{b^2 - 4ac}}{2a}$, $x_2 = \\frac{-b - \\sqrt{b^2 - 4ac}}{2a}$ 근의 공식에 대한 증명 이차 방정식 $ax^2 + bx + c - 0$에서 시작합니다. 양변을 a로 나눕니다. $x^2 + \\frac{b}{a}x + \\frac{c}{a} = 0$ 완전제곱 꼴로 만들어서 방정식을 만족하는 h와 k를 찾습니다. $(x - h)^2 + k = x^2 + \\frac{b}{a}x + \\frac{c}{a}$ h와 k를 찾기 위해 좌변의 괄호를 전개해서 다음을 얻습니다. $x^2 - 2hx + h^2 + k = x^2 + \\frac{b}{a}x + \\frac{c}{a}$ 방정식의 양변에 있는 x의 계수를 보면 h를 구할 수 있습니다. $-2h = \\frac{b}{a}$이므로 $h = -\\frac{b}{2a}$입니다. 위 방정식에 대입합니다. $x^2 - \\frac{b}{a}x + \\frac{b^2}{4a^2} + k = x^2 + \\frac{b}{a}x + \\frac{c}{a}$ k값을 구하기 위해, 방정식 양변의 같은 항을 소거하고 k를 분리합니다. $\\frac{b^2}{4a^2} + k = \\frac{c}{a}$ $k = \\frac{c}{a} - \\frac{b^2}{4a^2}$ h와 k를 찾은 후, 방정식 $ax^2 + bx + c - 0$을 다음과 같이 $(x - h)^2 + k = 0$ 형태의 방정식으로 쓸 수 있습니다. $(x + \\frac{b}{2a})^2 + \\frac{c}{a} - \\frac{b^2}{4a^2} = 0$ 모든 상수를 우변으로 이동시킵니다. $(x + \\frac{b}{2a})^2 = \\frac{c}{a} - \\frac{b^2}{4a^2}$ 양변에 제곱근을 취합니다. 제곱 함수는 양수와 음수가 같은 결과값이 되기 때문에 두 가지 해를 생성합니다. $x + \\frac{b}{2a} = \\pm\\sqrt{-\\frac{c}{a} + \\frac{b^2}{4a^2}}$ 제곱근 안을 정리한 뒤 해를 구합니다. $x + \\frac{b}{2a} = \\pm\\frac{\\sqrt{b^2 - 4ac}}{2a}$ $x = \\frac{-b}{2a} \\pm\\frac{\\sqrt{b^2 - 4ac}}{2a}$ = $\\frac{-b \\pm\\sqrt{b^2 - 4ac}}{2a}$ 함수 (1.8)함수(function)는 변수들 사이의 관계를 규정하는 규칙으로 이해할 수 있습니다. 특히, 함수는 한 변수에 따라 다른 변수가 어떻게 변화하는지 설명합니다.$f : A \\to B$ 정의역(domain): 허용된 입력값들의 집합입니다. 치역(range), 상(image): 가능한 모든 출력값들의 집합입니다. 공역(codomain): 함수의 치역을 포함하는 집합으로 출력값의 형태를 나타내는 집합입니다. 함수는 수에서 수로의 사상(mapping)입니다. 임의의 입력값 x에 대해, 그 입력에 대한 f의 출력값은 f(x)로 표시됩니다.역함수는 함수 f의 연산을 실행 취소하는 함수입니다. 전단사함수 $f : A \\to B$가 주어지면, f의 역사상을 수행하는 역함수 $f^{-1} : B \\to A$가 존재합니다. 어떤 x에서 시작하여 f를 적용한 다음 $f^{-1}$를 적용하면 원래 입력 x가 됩니다. $f^{-1}(f(x)) \\equiv f^{-1} \\circ f(x) = x$ 벡터 (1.14)벡터는 다차원 대상을 다루는 방법으로 공간에서의 방향을 나타내는 정확한 방법입니다. 실수의 순서쌍으로 표시하고 각각의 실수를 성분(component)이라고 합니다. 물리량, 컴퓨터 그래픽, 확률론, 머시러닝, 기타 과학과 수학 분야의 연구에서 광범위하게 사용됩니다. 벡터 표기법 성분 표기법: x축, t축에 대한 순서쌍으로 나타냅니다. $\\vec{v} = (v_{x}, v_{y})$ 단위벡터 표기법: 단위벡터 $\\hat{i} = (1,0)$, $\\hat{j} = (0,1)$를 사용하여 표현합니다. $\\vec{v} = v_{x}\\hat{i}, v_{y}\\hat{j}$ 길이-방향 표기법: 벡터의 길이 $\\vert\\vert\\vec{v}\\vert\\vert$와 벡터가 x축과 이루는 각 $\\theta$로 표현합니다. $\\vec{v} = \\vert\\vert\\vec{v}\\vert\\vert \\angle\\theta$ 기저(basis) 기저(basis)는 벡터를 학습할 때 가장 중요한 개념 중 하나입니다. 3차원 벡터공간 $\\mathbb{R}^3$의 기저가 $\\hat{e}_1, \\hat{e}_2, \\hat{e}_3$이고 기저에 대한 계수가 $(v_1, v_2, v_3)$라면 벡터를 다음과 같이 표현할 수 있습니다. $\\vec{v} = v_1\\hat{e}_1 + v_2\\hat{e}_2 + v_3\\hat{e}_3$ 기저에 대한 실사용 예로 RGB code가 있습니다. RGB code는 색상을 만들기 위해 필요한 Red, Green, Blue 색의 양을 나타내는 세 가지 값으로 표현합니다. 예를 들어 노랑색은 (255,255,0)의 RGB code로 표현합니다. " }, { "title": "ch11. Evaluation of Model", "url": "/posts/ch11_Evaluation_of_Model/", "categories": "Study, B-ML_with_Python_Cookbook", "tags": "ml, python, study, sklearn, dataframe", "date": "2022-06-03 22:12:20 +0900", "snippet": "SummaryModel은 예측성능이 높아야 유용합니다. 근본적인 목적은 고품질의 model을 만드는 것입니다. Algorithm이 만드는 model의 평가 방법을 알아봅니다. 교차검증 model 만들기 (11.1)# Model을 훈련하고 어떤 성능지표(정확도, 제곱오차 등)를 사용하여 얼마나 잘 동작하는지 계산합니다.# Training set에 한정해서 잘 동작하는 model이 아니라 새로운 data에 대해서 잘 동작하길 기대합니다.# KFCV(K-Fold Cross-Validation)를 사용하여 최종 성능을 산출합니다. 기본 regreesion model 만들기 (11.2)# Regression model 평가는 결정계수(R^2)를 사용합니다.$ R^2 = 1 - \\\\frac{\\\\sum_{i} (y_{i}-\\\\hat{y}_{i})^2}{\\\\sum_{i} (y_{i}-\\\\bar{y}_{i})^2} $ 기본 classification model 만들기 (11.3)# Classification model의 성능을 측적하는 일반적인 방법은 random 추측보다 얼마나 더 나은지 비교하는 것입니다. 이진 분류기의 예측 평가하기 (11.4)# sklearn의 cross_val_score 함수 사용: 훈련된 classification model의 품질을 평가합니다. 교차검증을 수행할 때 scoring 매개변수에 성능지표 중 하나를 선택합니다.# Accuracy(정확도), Precision(정밀도), Recall(재현률), F-1이 있습니다.Practice" }, { "title": "ch10. Dimension Reduction Using Feature Selection", "url": "/posts/ch10_Dimension_Reduction_Using_Feature_Selection/", "categories": "Study, B-ML_with_Python_Cookbook", "tags": "ml, python, study, sklearn, dataframe", "date": "2022-06-02 22:41:09 +0900", "snippet": "SummaryFeature selection은 고품질의 정보가 많은 feature를 선택하고 덜 유용한 feature는 버리는 방식입니다. Filter: 통계적 속성을 조사하여 가장 뛰어난 feature를 선택합니다. Wrapper: 시행착오를 통해 가장 고품질의 예측을 만드는 feature의 부분조합을 찾습니다. Embedded: Learning algorithm의 훈련 단계를 확장하거나 그 일부로 구성하여 가장 좋은 feature의 부분조합을 선택합니다. Variance 기준으로 numeric feature 선택하기 (10.1) # sklearn의 feature_selection.VarianceThreshold 사용: Numeric feature 중 variance가 낮은 feature(즉, 정보가 거의 없는 feature)를 삭제합니다. Variance 기준으로 binary feature 선택하기 (10.2)# sklearn의 feature_selection.VarianceThreshold 사용: Binary categoric feature 중 variance가 낮은 feature (즉, 정보가 거의 없는 feature)를 삭제합니다. 베르누이 확률 변수의 variance가 threshold 이상인 feature를 선택합니다. Correlation이 큰 feature 다루기 (10.3)# Correlation matrix 사용하여 correlation이 큰 feature를 확인하고 삭제: 두 가지 feature의 correlation이 크다면 서로 담고 있는 정보가 매우 비슷하므로 중복된 feature를 포함하는 것과 같습니다. Classification에 관련 없는 feature 삭제하기 (10.4)# Chi-square statistics 사용: Categoric target vector에서 관련 없는 feature를 삭제합니다.# Chi-square statistics는 두 categoric vector의 독립성을 평가합니다.# Feature가 numeric인 경우 각 feature와 target vector 사이에서 ANOVA의 F-값을 사용합니다.Practice" }, { "title": "(COURSERA-DeepLearning.AI) AI For Everyone", "url": "/posts/Certificate_AI/", "categories": "Study, L-Certificate", "tags": "certificate, ai, DeepLearning.AI", "date": "2022-06-01 17:43:10 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "ch9. Dimension Reduction Using Feature Extraction", "url": "/posts/ch9_Dimension_Reduction_Using_Feature_Extraction/", "categories": "Study, B-ML_with_Python_Cookbook", "tags": "ml, python, study, sklearn, dataframe", "date": "2022-06-01 10:47:12 +0900", "snippet": "SummaryDimension reduction을 위한 feature extraction의 목적은 feature에 내제된 정보는 최대한 유지하면서 feature set \\(\\rho_{original}\\)을 새로운 set \\(\\rho_{new}\\)로 변환하는 것입니다. Feature extraction의 한 가지 단점은 새로운 set \\(\\rho_{new}\\)를 사람이 이해하지 못한다는 것입니다. 해석 가능한 model을 유지하고 싶다면 feature selection 사용이 더 나은 방법입니다. PCA 사용 feature 줄이기 (9.1)# sklearn의 PCA: data의 variance 유지하면서 feature 수를 줄입니다. PCA는 unsupervised learning으로 target vector 정보를 사용하지 않고 feature matrix만 사용합니다.pca = sklearn.decomposition.PCA(n_components=0.99, wthien=True)# Data가 선형적으로 구분되면 (즉, 다른 class 사이에 line이나 hyperplane을 그릴 수 있다면) PCA가 잘 동작합니다. 선형적으로 구분되지 않는 data dimension reduction (9.2)# Kernel trick 사용하는 PCA 확장을 사용하여 non-linear dimension reduction을 수행합니다.kpca = sklearn.decomposition.KernelPCA(kernel=&#39;rbf&#39;, gamma=15, n_components=1)# Kernel이란 data를 projection하는 한 가지 방법입니다. Kernel function은 선형적으로 구분되지 않는 data를 고차원으로 projection 시킵니다. Class 분리 최대화하여 feature 줄이기 (9.3)# LDA(Linear Discriminant Analysis) 사용: Classification model에 사용될 feature를 줄입니다. LDA 사용하여 class를 최대한 분리하는 성분 축으로 feature를 projection 합니다.# LDA는 classification algorithm이지만 dimension reduction에도 자주 사용됩니다.# PAC와 유사하지만, PCA는 data에서 variance가 최대인 성분 축에만 관심이 있습니다.# 반면 LDA는 class간 차이를 최대화하는 추가적인 목적에도 관심이 있습니다. 또한 target vector를 사용합니다. Matrix 분해를 사용하여 feature 줄이기 (9.4)# NMF(Non-negative Matrix Factorization) 사용: 음수가 아닌 feature matrix의 dimension reduction을 합니다.nmf = sklearn.decomposition.NMF(n_components=10, random_state=1)# NMF는 linear dimension reduction을 위한 unsupervised learning 기법입니다.# 원하는 feature 개수 r이 주어지면 NMF는 다음과 같이 feature matrix를 분해합니다.V $\\approx$ WHW는 n*r matrixH는 r*d matrix# r값을 조정하여 필요한 dimension reduction 양을 정할 수 있습니다. Sparse data의 feature 줄이기 (9.5)# TSVD(Truncated Singular Value Decomposition) 사용: Sparse feature matrix의 dimension reduction을 합니다.# TSVD는 PCA와 비슷하지만 sparse feature matrix에 사용할 수 있다는 장점이 있습니다.# Natural language process에서 TSVD는 LSA(Latent Semantic Analysis)로도 부릅니다.Practice" }, { "title": "ch5. Category Data", "url": "/posts/ch5_Category_Data/", "categories": "Study, B-ML_with_Python_Cookbook", "tags": "ml, python, study, sklearn, dataframe", "date": "2022-06-01 10:15:55 +0900", "snippet": "SummaryCategory data를 machine learning에 알맞은 feature로 변환하는 다양한 전략을 알아봅니다. Category Data Encoding# sklearn의 LabelBinarizer 사용 one-hot encoding: 순서가 없는 category data feature를 encoding 합니다. (5.1)one_hot = LabelBinarizer()one_hot.fit_transform(feature)# dataframe의 replace 사용: 순서가 있는 category data feature를 encoding 합니다. String label을 numeric type으로 변환합니다. (5.2)scale_mapper = {&#39;Low&#39;: 1, &#39;Medium&#39;: 2, &#39;High&#39;:3}dataframe[&#39;Score&#39;].replace(scale_mapper)# sklearn의 DictVectorizer 사용: Feature dictionary를 encoding 합니다. Sparse matrix를 return 합니다. (5.3)dictvectorizer.fit_transform(dictionary) Null Value 대체하기 (5.4)# KNN classifier 사용: ML classification algorithm을 훈련하여 null value를 예측합니다.# sklearn의 SimpleImputer 사용: null value를 feature에서 가장 자주 등장하는 value로 채웁니다. Class Imvalence 다루기 (5.5)# 더 많은 data를 수집합니다.# 불가능하다면 model evaluation 지표를 변경합니다. Accuracy보다 precision, recall, F1-measutr, ROC curve 등이 있습니다.# 잘 동작하지 않으면 class weight를 사용합니다.# 혹은 down-sampling or up-sampling을 고려합니다.Practice" }, { "title": "(EDWITH-KOBIC) Linux 기초편", "url": "/posts/Certificate_Linux_inter/", "categories": "Study, L-Certificate", "tags": "certificate, linux, KOBIC", "date": "2022-05-29 22:16:31 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(EDWITH-KOBIC) R 기초편", "url": "/posts/Certificate_R_inter/", "categories": "Study, L-Certificate", "tags": "certificate, R, KOBIC", "date": "2022-05-29 22:12:15 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(COURSERA_Specialization-UMICH) Python3 Programming", "url": "/posts/Certificate_Python3_Programming/", "categories": "Study, L-Certificate", "tags": "certificate, python, UMICH", "date": "2022-05-28 22:41:20 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(COURSERA-UMICH) Python Project - pillow, tesseract, and opencv", "url": "/posts/Certificate_Python_Project/", "categories": "Study, L-Certificate", "tags": "certificate, python, project, UMICH", "date": "2022-05-28 22:32:19 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(COURSERA-UMICH) Python Classes and Inheritance", "url": "/posts/Certificate_Python_Classes/", "categories": "Study, L-Certificate", "tags": "certificate, python, class, UMICH", "date": "2022-05-28 22:19:05 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(COURSERA-UMICH) Data Collection and Processing with Python", "url": "/posts/Certificate_Data_Collection_Python/", "categories": "Study, L-Certificate", "tags": "certificate, python, data, UMICH", "date": "2022-05-28 22:17:32 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(COURSERA-UMICH) Python Functions, Files, and Dictionaries", "url": "/posts/Certificate_Python_Functions/", "categories": "Study, L-Certificate", "tags": "certificate, python, UMICH", "date": "2022-05-28 22:15:29 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(COURSERA-UMICH) Python Basics", "url": "/posts/Certificate_Python_Basics/", "categories": "Study, L-Certificate", "tags": "certificate, python, UMICH", "date": "2022-05-28 22:14:10 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(COURSERA-UMICH) Introduction to Data Science in Python", "url": "/posts/Certificate_Python_Datascience/", "categories": "Study, L-Certificate", "tags": "certificate, python, datascience, UMICH", "date": "2022-05-28 22:12:48 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(COURSERA-Google) Python Crash Course", "url": "/posts/Certificate_Intensive_Python/", "categories": "Study, L-Certificate", "tags": "certificate, python, Google", "date": "2022-05-28 22:05:02 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 인공지능의 기초", "url": "/posts/Certificate_AI2/", "categories": "Study, L-Certificate", "tags": "certificate, AI, SNU", "date": "2022-05-28 21:19:12 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 인공지능 만들기", "url": "/posts/Certificate_AI1/", "categories": "Study, L-Certificate", "tags": "certificate, AI, SNU", "date": "2022-05-28 21:17:40 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 데이터 마이닝", "url": "/posts/Certificate_Data_Mining/", "categories": "Study, L-Certificate", "tags": "certificate, bigdata, SNU", "date": "2022-05-28 21:15:22 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 파이썬 기반 빅데이터 처리 및 분석 기술", "url": "/posts/Certificate_Python_Bigdata/", "categories": "Study, L-Certificate", "tags": "certificate, python, bigdata, DCU", "date": "2022-05-28 21:12:07 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 오픈소스를 활용한 DevOps 환경 이해", "url": "/posts/Certificate_Software2/", "categories": "Study, L-Certificate", "tags": "certificate, software, KAIST", "date": "2022-05-28 21:09:58 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 파이썬 프로그래밍", "url": "/posts/Certificate_Python/", "categories": "Study, L-Certificate", "tags": "certificate, python, HGU", "date": "2022-05-28 21:09:58 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 쉽게 시작하는 기초선형대수학", "url": "/posts/Certificate_Linear_Algebra/", "categories": "Study, L-Certificate", "tags": "certificate, linearalgebra, UOS", "date": "2022-05-28 21:08:51 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 소프트웨어 공학", "url": "/posts/Certificate_Software1/", "categories": "Study, L-Certificate", "tags": "certificate, software, KAIST", "date": "2022-05-28 21:08:49 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 빅데이터의 세계, 원리와 응용", "url": "/posts/Certificate_Bigdata_World/", "categories": "Study, L-Certificate", "tags": "certificate, bigdata, EWHA", "date": "2022-05-28 21:07:05 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) R을 활용한 통계학개론", "url": "/posts/Certificate_RStatistics/", "categories": "Study, L-Certificate", "tags": "certificate, statistics, PNU", "date": "2022-05-28 21:06:23 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) 생명정보개론", "url": "/posts/Certificate_Bioinformatics/", "categories": "Study, L-Certificate", "tags": "certificate, biology, SSU", "date": "2022-05-28 21:05:17 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) Bioenergetics", "url": "/posts/Certificate_Bioegergetics/", "categories": "Study, L-Certificate", "tags": "certificate, biology, KAIST", "date": "2022-05-28 21:03:02 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "(K-MOOC) Introduction to Economics", "url": "/posts/Certificate_Introduction_to_Economics/", "categories": "Study, L-Certificate", "tags": "certificate, economics, SNU", "date": "2022-05-28 21:02:34 +0900", "snippet": "Lecture InfoCertificate" }, { "title": "ch4. Numeric Data", "url": "/posts/ch4_Numeric_Data/", "categories": "Study, B-ML_with_Python_Cookbook", "tags": "ml, python, study, sklearn, dataframe, outlier, standardization, normalization", "date": "2022-05-28 10:31:20 +0900", "snippet": "SummaryNumeric data를 machine learning에 알맞은 feature로 변환하는 다양한 전략을 알아봅니다. Scaling (4.1)# scale 조정: sklearn의 MinMaxScaler method를 사용합니다. 보통 0~1이나 -1~+1 range로 조정합니다.# fit: feature의 min, max를 계산합니다.# transform: feature의 scale을 조정합니다.minmax_scale = sklearn.preprocessing.MinMaxScaler(feature_range=(0, 1))minmax_scale.fit_transform(feature)# Training set과 test set의 scale을 따로 조정하면 안됩니다. Scale 조정을 위해 구한 min, max의 동일한 값을 사용해야 합니다.# Neural network는 min-max scaling을 권장합니다. Standardization# sklearn의 StandardScaler: feature의 mean 0, std 1이 되도록 변환합니다.# 변환된 feature는 원본 값이 mean에서 몇 std만큼 떨어져 있는지 z-score로 표현합니다.# PCA 분석은 standardization 방식이 잘 맞습니다.scaler = sklearn.preprocessing.StandardScaler()standardized = scaler.fit_transform(feature)# Data에 Outlier가 많다면 mean과 std에 영향을 미치므로 standardization에 부정적인 영향을 미칩니다.# 이 경우 median과 IQR을 사용하여 scale을 변환합니다. sklearn의 RobustScaler method를 사용합니다. Data에서 median을 빼고 IQR로 나누는 방식입니다.robust_scaler = sklearn.preprocessing.RobustScaler()robust_standardized = robust_scaler.fit_transform(feature) Normalization (4.3)# Normalizer + norm 매개변수: feature 전체 길이가 1인 unit norm이 되도록 변환합니다.normalizer = sklearn.preprocessing.Normalizer(norm=&#39;l2&#39;)normalizer.transform(feature)# 각 단어나 n개의 단어 그룹이 feature인 text classification처럼, 유사한 feature가 많을 때 사용합니다.# Normalizer는 세 가지 norm 옵션을 제공합니다.## L2(Euclidean norm): default. 두 지점 사이를 잇는 직선 거리입니다.## L1(Manhattan norm): taxi norm. 두 지점 사이를 사람이 도보로 걷는 것과 같습니다.## max: 각 row의 max 값으로 row의 값들을 나눕니다. Polynominal과 Interaction feature (4.4)# Polynominal: feature와 target 사이 non-linear 관계가 있다는 가정을 추가할 때 사용합니다. Feature에 변동 효과를 주입합니다. 예를 들어 주요 질병에 걸릴 확률에서 나이가 미치는 영향# Interaction: feature의 효과가 다른 feature에 dependent하는 경우 사용합니다. 예를 들어 커피의 달달함에서 설탕을 넣었는지, 커피를 저었는지 여부# sklearn의 PolynominalFeatures class를 사용합니다. Feature Transformation (4.5)# FunctionTransformer: 하나 이상의 features에 사용자 정의 transformation을 적용합니다.new_transformer = FunctionTransformer(new_function)new_transformer.transform(features)# pandas의 apply도 동일한 기능을 합니다.df.apply(new_function) Outlier (4.6)# 정의: 1사분위보다 1.5 IQR 이상 작은 값, 3사분위보다 1.5 IQR 이상 큰 값으로 정의합니다.# 처리하는 방법## 1. 삭제houses[houses[&#39;kitchen&#39;] &amp;lt;3]## 2. outlier로 flagging 하고 feature의 하나로 포함시키기houses[&#39;outlier&#39;] = np.where(houses[&#39;kitchen&#39;] &amp;lt; 3, 0, 1)## 3. outlier 영향이 줄어들도록 feature 변환하기houses[&#39;log_of_square_feet&#39;] = [np.log(x) for x in houses[&#39;square_feet&#39;]] Feature Binarization (4.8)# Binarizer: threshold에 따라 feature를 두 개로 나눕니다.binarizer = Binarizer(18)binarizer.fit_transform(age)# digitize: numeric feature를 여러 threshold에 따라 나눕니다.np.digitize(age, bins=[20, 30, 64])Practice" }, { "title": "Search Algorithm - BFS (Breadth-First Search)", "url": "/posts/Algorithm_Search_BFS/", "categories": "Programming, Algorithm", "tags": "algorithm, search, python", "date": "2022-05-27 07:52:29 +0900", "snippet": "BFS (Breadth-First Search)(DFS에 이어 작성한 post 입니다. 먼저 DFS를 읽고 오시는 것을 권장합니다.)BFS (Breadth-First Search)는 search algorithm 종류 중 하나입니다. DFS의 단점 중 하나는 항상 optimal solution을 찾는 것이 아니라는 것입니다. BFS는 이런 점을 보완한 search alogirithm 입니다. 전반적으로 DFS와 유사하므로 동일한 부분은 생략하고 차이나는 부분 위주로 살펴보겠습니다.BFS process는 다음과 같습니다. Frontier는 initial state(A)를 포함한 상태, explored set은 empty 상태로 시작합니다. Frontier에 search할 next node 확인: Frontier에 search할 next node가 존재하는지 확인합니다. 만약 없다면 solution이 없음을 의미하며 DFS process를 종료합니다. 참고로 여기서 언급한 node는 state, parent node, action, path cost 정보를 담고 있는 data structure입니다. Next node 가져오기: Frontier에서 first node를 추출합니다. (queue structure) Solution 확인과 return: 2번의 node가 goal test를 통과하면 search process를 종료하고 explored set을 solution으로 정의한 뒤 return합니다. Explored set에 node 추가: 2번의 node가 goal test를 통과하지 못하면 explored set에 node를 추가합니다. Frontier expansion: Frontier에 child node를 추가 합니다. 이 때 child node가 frontier와 explore set에 이미 존재하는지 확인합니다. BFS processDFS와 차이점을 찾으셨나요? DFS는 search 과정에서 goal node(F)를 만날 때까지 계속 child node를 찾아갑니다. 하지만 BFS는 같은 depth의 모든 node(C, D)를 우선 찾아갑니다.   BFS 공간 복잡도, 시간 복잡도Node의 수를 V(Vertex), 연결선의 수를 E(Edge)라고 할 때,BFS의 공간 복잡도는 다음과 같습니다. 인접 행렬인 경우: O($V^2$) 인접 리스트인 경우: O(V+E) 시간 복잡도는 다음과 같습니다. 인접 행렬인 경우: O($V^2$) 인접 리스트인 경우: O(V+E)   DFS 장/단점BFS의 장점은 다음과 같습니다. 여러 개의 solution이 존재할 경우 optimal solution을 찾을 수 있습니다.BFS의 단점은 다음과 같습니다. Search 해야 할 node가 많은 경우 필요 없는 node까지 모두 저장해야 하므로 DFS보다 큰 저장공간이 필요합니다. Node의 수가 많을 수록 search 시간이 오래 걸립니다.   BFS 적용BFS를 미로 문제에 적용해 보겠습니다.‘QueueFrontier’ class는 ‘StackFrontier’ class를 상속 받습니다. 다만 DFS와 차이점은 BFS가 queue structure를 사용하기 때문에 ‘remove’ function이 frontier에서 node를 가져올 때 가장 첫 번째 위치에 존재하는 node를 가져온다는 점입니다. 그 외 code는 DFS와 동일합니다.node = self.frontier[0]  BFS 예제미로 문제를 입력받아 solution을 찾아내는 과정입니다. 전체 code와 예제 파일은 이 곳에서 확인할 수 있습니다. BFS 미로 문제 예제DFS 방식으로 미로 문제를 풀 때 optimal solution이 아닌 멀리 돌아가는 solution을 return한 case가 있었습니다. BFS 방식을 적용하면 optimal solution을 return 합니다." }, { "title": "ch3. Data Wrangling", "url": "/posts/ch3_Data_Wrangling/", "categories": "Study, B-ML_with_Python_Cookbook", "tags": "ml, python, study, sklearn, dataframe", "date": "2022-05-26 21:47:51 +0900", "snippet": "SummaryData wrangling은 original data를 정제하고 사용 가능한 형태로 변환하는 과정을 광범위하게 의미하는 비공식 용어입니다. 가장 일반적인 structure는 dataframe입니다. Dataframe 만들기 (3.1)# pandas에 dataframe을 만드는 다양한 방법이 존재합니다.import pandas as pd# class 사용pd.DataFrame()# numpy array 사용pd.DataFrame(np.array(data), columns=[&#39;a&#39;, &#39;b&#39;])# dictionary 사용pd.DataFrame(dict) Data 설명 (3.2)import pandas as pd# dimension 확인dataframe.shape# column count 확인 (3.7)dataframe.count()# numeric column statistics 확인dataframe.describe()# numeric column correlation 확인 (3.7)dataframe.corr()# numeric column covariance 확인 (3.7)dataframe.cov() Dataframe 탐색 (3.3)import pandas as pd# loc: index가 label(string, etc)일 때 사용dataframe.loc[&#39;hubert&#39;]# iloc: dataframe의 위치 참조dataframe.iloc[0] # loc, iloc method의 slicing은 python slicing과 달리 마지막 index를 포함합니다. Dataframe 수정import pandas as pd# replace: 값 치환. (3.5)dataframe[&#39;column&#39;].replace(&#39;hubert&#39;, &#39;ashley&#39;)# rename: column name 변경 (3.6)dataframe.rename(columns={&#39;Name&#39;: &#39;Nickname&#39;})# drop + column name: column 삭제 1 (3.10)dataframe.drop(&#39;Name&#39;, axis=1)# drop + column index: column 삭제 2 (3.10)dataframe.drop(dataframe.columns[0], axis=1)# boolean: row 삭제 1 (3.11)dataframe[dataframe[&#39;Name&#39;] != False]# row index (3.11)dataframe[dataframe.index != 0]# drop_duplicates: duplicate line 삭제 (3.12) Dataframe Unique 값 처리 (3.8)import pandas as pd# unique: column 내부 unique 값 찾기dataframe[&#39;Name&#39;].unique()# value_counts: column 내부 unique 값 countdataframe[&#39;Name&#39;].value_counts()# nunique: dataframe 전체 unique 값 countdataframe.nunique() Dataframe null 값 (3.9)import pandas as pd# isnull/notnull: null 값 확인dataframe[&#39;Name&#39;].isnull() Dataframe groupingimport pandas as pd# groupby: 값에 따라 row grouping (3.13)dataframe.groupby([&#39;Name&#39;])[&#39;Age&#39;].mean()# resample: index를 time range(datetime format)로 변경한 뒤 시간에 따라 row grouping (3.14)dataframe.resample(&#39;W&#39;).sum()# groupby로 row grouping한 뒤 각 group에 apply method 연결: group에 function 적용 (3.17)dataframe.groupbu(&#39;Name&#39;).apply(lambda x: x.count()) Dataframe 모든 column element에 function 적용 (3.16)import pandas as pd# apply: column의 모든 element에 built-in/custom function 적용. argument를 지정할 수 있음dataframe[&#39;Name&#39;].apply(uppercase)dataframe[&#39;Name&#39;].apply(lambda x, age: x &amp;lt; age, age=40)# map: apply와 비슷하지만 dictionary 사용 가능dataframe[&#39;Name&#39;].map({True: 1, False: 0}) Dataframe 연결 (3.18)import pandas as pd# row 방향 연결: concat + axis=0pd.concat([dataframe_a, dataframe_b], axis=0)# column 방향 연결: concat + axis=1pd.concat([dataframe_a, dataframe_b], axis=1) Dataframe merge (3.19)import pandas as pd# inner join: merge + on=&#39;column_name&#39;pd.merge(dataframe_a, dataframe_b, on=&#39;Name&#39;)# outer/left/right join: merge + how=&#39;outer/left/right&#39;pd.merge(dataframe_a, dataframe_b, on=&#39;Name&#39;, how=&#39;outer&#39;)# left_on/right_on: 각각 dataframe에서 병합하기 위한 column name 지정pd.merge(dataframe_a, dataframe_b, left_on=&#39;Name&#39;, right_on=&#39;Age&#39;)# left_index/right_index: column 대신 index 기준으로 병합pd.merge(dataframe_a, dataframe_b, left_index=True, right_index=True) Summary in Summary merge 위한 세 가지 사항 결정 merge 할 두 개의 dataframe 지정 merge 할 column 지정 ‘how’ 매개변수로 merge 종류 지정 inner: 양 쪽 dataframe 동시에 존재하는 row return outer: 두 dataframe의 모든 row return left: left dataframe의 모든 row return right: right dataframe의 모든 row return Practice" }, { "title": "ch2. Data Load", "url": "/posts/ch2_Data_Load/", "categories": "Study, B-ML_with_Python_Cookbook", "tags": "ml, python, study, sklearn", "date": "2022-05-25 19:21:10 +0900", "snippet": "SummaryMachine learning의 첫 단계는 data를 불러 오는 것입니다. CSV, SQL DB 등 다양한 source에서 data load 방법을 알아봅니다. pandas library 도구를 사용합니다. Toy data set은 scikit-learn을 사용합니다. Toy Data Set (2.1) load_boston: Boston house cose에 대한 503개 data set 입니다. (Regression) load_iris: Iris sample size에 대한 150개 data set 입니다. (Classification) load_digits: 손 글씨 숫자 이미지 1,979개 data set 입니다. (Image clustering) scikit-learn을 사용한 Mock Data Set (2.2) make_regression: regression을 위한 실수 feature matrix와 target vector return make_classification: classification을 위한 실수 feature matrix와 정수 target vector return make_blobs: clustering을 위한 실수 feature matrix와 정수 target vector return Pandas를 사용한 Data Load read_csv: csv file (2.3) read_excel: excel file (2.4) read_json: json file (2.5) read_sql_query: SQL database (2.6) Practice" }, { "title": "ch1. Vector Matrix Array", "url": "/posts/ch1_Vector_Matrix_Array/", "categories": "Study, B-ML_with_Python_Cookbook", "tags": "ml, python, study, vector, matrix, array", "date": "2022-05-25 19:21:10 +0900", "snippet": "SummaryVector, matrix, array는 machine learning data를 다루기 위한 기본 도구입니다. Vector: 1d array로 만듭니다. (1.1) Numpy로 Matrix 다루기 empty: Initial value 대신 크기만 지정하여 임의의 값이 채워진 array를 만듭니다. (1.2) zeros: 0으로 채운 array를 만듭니다. (1.2) ones: 1로 채운 array를 만듭니다. (1.2) full: 특정 값으로 채운 array를 만듭니다. (1.2) shape, size, ndim: matrix의 크기, 원소 개수, 차원을 알고 싶을 때 사용합니다. (1.5) Numpy로 Array 다루기 vectorize class: vectorized operation을 적용합니다. (1.6) broadcasing: 차원이 달라도 array 사이 연산을 수행합니다. (1.6) reshape: Array 크기만 변경하고 싶을 때 사용합니다. (1.9) Transpose vector or matrix T or transpose method를 사용합니다. Matrix rank 구하기 (1.12) Matrix rank는 row or column이 만든 vector 공간의 차원입니다. Linear independent row or column의 개수입니다. matrix_rank function을 사용합니다. linalg module의 svd function으로 eigenvalues를 구한 다음 0이 아닌 값의 수를 헤아리는 방법으로 구할 수 있습니다. Determinant (1.13) det를 사용합니다. Diagonal elements (1.14) diagonal을 사용합니다. Trace (1.15) trace를 사용합니다. Eigenvalue, Eigenvector (1.16) eig를 사용합니다. Inverse matrix (1.20) inv를 사용합니다. Practice" }, { "title": "(Video) Baby Driver with Bliss", "url": "/posts/Video_Baby_Driver_with_Bliss/", "categories": "Moment, Video", "tags": "wondersharefilmora, video", "date": "2022-05-25 12:29:16 +0900", "snippet": "Video clip: Baby Driver (2017, Edgar Wright)BGM: bliss (2001, Muse)" }, { "title": "(A6000/30.4) Piazzale Michelangelo 6", "url": "/posts/A6000_30.4_Piazzale_Michelangelo6/", "categories": "Moment, Photo", "tags": "A6000, 30.4, photo", "date": "2022-05-25 12:22:10 +0900", "snippet": " 2019.03 from Piazzale Michelangelo, Florence, ItalySony A6000 + Sigma 30mm f1.4" }, { "title": "(A6000/30.4) Piazzale Michelangelo 5", "url": "/posts/A6000_30.4_Piazzale_Michelangelo5/", "categories": "Moment, Photo", "tags": "A6000, 30.4, photo", "date": "2022-05-25 12:15:20 +0900", "snippet": " 2019.03 from Piazzale Michelangelo, Florence, ItalySony A6000 + Sigma 30mm f1.4" }, { "title": "(A6000/30.4) Piazzale Michelangelo 4", "url": "/posts/A6000_30.4_Piazzale_Michelangelo4/", "categories": "Moment, Photo", "tags": "A6000, 30.4, photo", "date": "2022-05-25 12:08:19 +0900", "snippet": " 2019.03 from Piazzale Michelangelo, Florence, ItalySony A6000 + Sigma 30mm f1.4" }, { "title": "(A6000/30.4) Piazzale Michelangelo 3", "url": "/posts/A6000_30.4_Piazzale_Michelangelo3/", "categories": "Moment, Photo", "tags": "A6000, 30.4, photo", "date": "2022-05-25 12:02:41 +0900", "snippet": " 2019.03 from Piazzale Michelangelo, Florence, ItalySony A6000 + Sigma 30mm f1.4" }, { "title": "(A6000/30.4) Piazzale Michelangelo 2", "url": "/posts/A6000_30.4_Piazzale_Michelangelo2/", "categories": "Moment, Photo", "tags": "A6000, 30.4, photo", "date": "2022-05-25 11:58:21 +0900", "snippet": " 2019.03 from Piazzale Michelangelo, Florence, ItalySony A6000 + Sigma 30mm f1.4" }, { "title": "(A6000/30.4) Piazzale Michelangelo 1", "url": "/posts/A6000_30.4_Piazzale_Michelangelo1/", "categories": "Moment, Photo", "tags": "A6000, 30.4, photo", "date": "2022-05-25 11:54:15 +0900", "snippet": " 2019.03 from Piazzale Michelangelo, Florence, ItalySony A6000 + Sigma 30mm f1.4" }, { "title": "(A6000/30.4) Battistero di San Giovanni", "url": "/posts/A6000_30.4_Battistero_di_San_Giovanni/", "categories": "Moment, Photo", "tags": "A6000, 30.4, photo", "date": "2022-05-25 11:49:50 +0900", "snippet": " 2019.03 from Battistero di San Giovanni, Florence, ItalySony A6000 + Sigma 30mm f1.4" }, { "title": "(A6000/30.4) Ponte Vecchio", "url": "/posts/A6000_30.4_Ponte_Vecchio/", "categories": "Moment, Photo", "tags": "A6000, 30.4, photo", "date": "2022-05-25 11:45:02 +0900", "snippet": " 2019.02 from Ponte Vecchio, Florence, ItalySony A6000 + Sigma 30mm f1.4" }, { "title": "(A6000/30.4) Ttukseom Hangang Park 5", "url": "/posts/A6000_30.4_Ttukseom_Hangang_Park_5/", "categories": "Moment, Photo", "tags": "A6000, 30.4, photo", "date": "2022-05-25 11:45:02 +0900", "snippet": " 2018.06 from Ttukseom Hangang Park, Seoul, South KoreaSony A6000 + Sigma 30mm f1.4" }, { "title": "(A6000/30.4) Ttukseom Hangang Park 4", "url": "/posts/A6000_30.4_Ttukseom_Hangang_Park_4/", "categories": "Moment, Photo", "tags": "A6000, 30.4, photo", "date": "2022-05-25 11:42:26 +0900", "snippet": " 2018.06 from Ttukseom Hangang Park, Seoul, South KoreaSony A6000 + Sigma 30mm f1.4" }, { "title": "(A6000/30.4) Ttukseom Hangang Park 3", "url": "/posts/A6000_30.4_Ttukseom_Hangang_Park_3/", "categories": "Moment, Photo", "tags": "A6000, 30.4, photo", "date": "2022-05-25 02:38:12 +0900", "snippet": " 2018.06 from Ttukseom Hangang Park, Seoul, South KoreaSony A6000 + Sigma 30mm f1.4" }, { "title": "(A6000/30.4) Ttukseom Hangang Park 2", "url": "/posts/A6000_30.4_Ttukseom_Hangang_Park_2/", "categories": "Moment, Photo", "tags": "A6000, 30.4, photo", "date": "2022-05-25 02:35:05 +0900", "snippet": " 2018.06 from Ttukseom Hangang Park, Seoul, South KoreaSony A6000 + Sigma 30mm f1.4" }, { "title": "(A6000/30.4) Ttukseom Hangang Park 1", "url": "/posts/A6000_30.4_Ttukseom_Hangang_Park_1/", "categories": "Moment, Photo", "tags": "A6000, 30.4, photo", "date": "2022-05-25 02:31:05 +0900", "snippet": " 2018.06 from Ttukseom Hangang Park, Seoul, South KoreaSony A6000 + Sigma 30mm f1.4" }, { "title": "Dataframe in Pandas", "url": "/posts/DataframeinPandas/", "categories": "Programming, Python", "tags": "python, pandas, dataframe", "date": "2022-05-24 21:58:27 +0900", "snippet": "IntroPandas는 data analysis에 유용한 python package 입니다. Pandas는 쉽고 편리하게 data를 다룰 수 있도록 유연한 structure를 제공하는데, 그 중 하나가 바로 Dataframe 입니다.이 post는 pandas 공식 가이드 내 10 minutes to pandas를 참고 했습니다. Dataframe이란?Dataframe은 data를 직사각형 모양 table에 저장한 구조입니다. Row는 숫자, 문자, 논리 등 여러 가지 data type이 들어갈 수 있습니다. Column은 동일한 data type이 들어갈 수 있습니다. 즉, 각 column에 아마도 서로 다른 data type을 지닌 2d array data 구조로 요약할 수 있습니다. 참고로 1d array data 구조는 Series 입니다.R 언어를 알고 계시는 분들은 data.frame이 친숙할 것입니다. Pandas의 dataframe과 유사한 구조입니다.Dataframe의 주요 요소입니다. Data: Dataframe 자체가 들어갈 수 있고 그 외 series, numpy의 ndarray, 2d ndarray, dictionary가 들어갈 수 있습니다. Index: Numpy의 array나 2d array와 비슷하지만, dataframe에는 index가 존재한다는 차이가 있습니다. Column: Column의 index도 존재하여 data를 손쉽게 다룰 수 있도록 도와줍니다. Dataframe 주요 요소 Manipulating Dataframe  Object creationDataframe을 생성합니다.  Viewing data생성한 dataframe을 확인합니다. 간단한 statistics summary, 행렬변환, 정렬 등을 시도해 보겠습니다.  SelectionData를 선택하고 변경하는 방법입니다.  Missing data결측치를 확인하고 처리하는 방법입니다.  Operations본격적으로 data를 다뤄봅니다. Statistics를 구하고 사칙연산 function을 적용합니다.  Merge서로 다른 구조의 data를 합치거나 나누는 방법입니다.  GroupingData를 특정 기준에 따라 분류하여 처리합니다.  ReshapingDataframe을 다른 형태로 변환합니다.  Time seriesTime series data를 다루는 방법입니다.  CategoricalsCategorical data를 다뤄보지 않을 수 없겠죠?  PlottingData analysis의 정점! plotting 입니다.  Getting data in/out생성/분석에 사용하는 data를 파일로 쓰거나 불러오는 방법입니다." }, { "title": "Stack vs Queue", "url": "/posts/Stack-Queue/", "categories": "Programming, Database", "tags": "database, LIFO, FIFO", "date": "2022-05-24 07:57:42 +0900", "snippet": "Stack A pile of things arranged one on top of anotherStack의 사전적 의미로 어떤 물체를 다른 것 위에 차곡차곡 쌓아 놓은 더미를 뜻합니다. 흔히 게임에서 자신의 캐릭터가 능력을 발휘하기 위해 특정 동작을 여러 번 반복하는 행위를 두고 ‘stack을 쌓는다’라고 표현합니다. 이와 같이 차곡차곡 쌓아 올린 data structure가 stack입니다.Stack은 data를 다룰 때 LIFO(Last-in, First-out) approach를 사용합니다. 가장 마지막에 들어간 data가 가장 먼저 나오는 방식입니다. 아래 그림은 밑이 막혀 있는 상자 안에 data A, B, C, D를 넣고 빼는 과정입니다. 가장 마지막에 들어간(LI) data D가 가장 먼저 나오고(FO) 있습니다. Stack structure &amp;amp; LIFO approach 우리는 이미 일상 생할에서 stack을 사용하고 있습니다. 실행 취소(ctrl+z): 취소 단축키를 사용하면 가장 마지막에 실행된 동작부터 순서대로 취소합니다. 접시 꺼내기: 찬장 안 쌓여 있는 접시를 꺼낼 때 가장 위에서부터 하나씩 꺼낼 수 있습니다. 뒤로 가기: 웹 브라우저의 뒤로 가기 버튼은 가장 마지막에 열린 페이지로 되돌아 갑니다. DFS(Deep-first Search) 구현: 가장 깊은 단계 node까지 확장하며 search하는 방식입니다. DFS post를 참고하세요. Queue A line of people, usually standing or in cars, waitin for somethingQueue의 사전적 의미로 사람들이 줄 서있는 모습을 연상할 수 있습니다. 커피를 구입하기 위해 줄을 서면 가장 먼저 온 사람부터 차례대로 주문을 받습니다. 이처럼 data가 들어가는 입구와 출구가 다른 data structure가 queue입니다.Queue는 data를 다룰 때 FIFO(First-in, First-out) approach를 사용합니다. 가장 먼저 들어간 data가 가장 먼저 나오는 방식입니다. 아래 그림은 밑이 뚫려 있는 상자 안에 data A, B, C, D를 넣고 빼는 과정입니다. 가장 먼저 들어간(FI) data A가 가장 먼저 나오고(FO) 있습니다. Queue structure &amp;amp; FIFO approach 우리는 이미 이상 생활에서 queue를 사용하고 있습니다. 스타벅스 DT: 자동차를 타고 줄을 서면 먼저 온 순서대로 커피를 주문하고 받아갑니다. Sungrid engine: qsub command를 실행하면 queue 대기열에 들어간 job 순서대로 실행됩니다. BFS(Breathe-first Search) 구현: 매 단계 같은 깊이의 node들을 순서대로 대기열에 넣고 들어온 순서대로 search하는 방식입니다. BFS post를 참고하세요. 마지막으로 Stack vs Queue 비교화면을 보며 post를 마칩니다. Stack vs Queue" }, { "title": "Search Algorithm - DFS (Depth-First Search)", "url": "/posts/Algorithm_Search_DFS/", "categories": "Programming, Algorithm", "tags": "algorithm, search, python", "date": "2022-05-22 21:31:00 +0900", "snippet": "Intro몇 가지 문제로 시작해 보겠습니다. Mazes at Hever Castle, UK영국은 유구한 역사를 지닌 나라답게 웅장한 크기를 자랑하는 castle과 오래된 건축물을 쉽게 찾아볼 수 있습니다. 사진은 영국 Hever Castle과 내부에 있는 미로입니다. 미로는 입구에서 출발하여 출구로 나가는 길을 찾아야 합니다. 갈림길이 나오면 어떤 길로 갈 것인지 선택하고, 막다른 길을 만나면 되돌아가야 합니다. 이것은 미로 문제입니다. Hubert’s commute path매일 오고가는 출퇴근 경로입니다. 1.5시간이 소요되는 버스+지하철 조합을 이용합니다. 우리는 목적지까지 도달하는데 버스, 지하철, 택시, 자가용 등 다양한 교통수단을 사용할 수 있고 직통, 환승 등 조합에 따라 소요 시간은 천차만별 입니다. 대부분 가장 빠른 경로를 원하겠지요? 이것은 최적경로 찾기 문제입니다.미로 문제와 최적경로 찾기 문제, 어떻게 논리적으로 해결할 수 있을까요? Algorithm: SearchSearch algorithm으로 문제를 해결할 수 있습니다. 연속 변수나 이산 변수를 사용하여 일부 데이터 구조 안에 저장된 정보를 search하는 algorithm입니다.Search algorithm 구성 요소는 다음과 같습니다. Agent: 주변 환경을 인식하고 상호작용하는 주체입니다. State: 환경 내에서 agent가 배치된 모양입니다. Agent가 action을 시작하기 전 초기 위치를 initial state라고 합니다. Actions: 특정 환경 안에서 문제가 주어졌을 때 agent가 선택 가능한 행동들을 의미합니다. ACTIONS(s)는 state s에서 실행가능한 모든 action을 반환합니다. Transition model: 특정 state에서 가능한 action을 취한 결과 나타나는 states를 설명하는 model입니다. RESULT(s, a)는 state s에서 action a를 수행한 result state를 반환합니다. Simulation: Agent는 곧바로 action을 취하지 않습니다. 사전에 어떤 action이 가장 효율적인지 model을 사용하여 simulation을 진행합니다. Goal test: action 결과로 얻은 state가 처음 목표로 했던 state인지 평가하는 것입니다. Path cost function: Path를 따라 goal state에 도달하기 까지 소요된 비용을 산출하는 함수입니다. Solution: Simulation을 통해 얻은 일종의 정답입니다. 다양한 solution 중 가장 비용이 적게 드는 것을 Optimal Solution이라고 합니다. DFS (Deep-First Search)DFS (Deep-First Search)는 search algorithm 종류 중 하나입니다. Goal test를 만족할 때까지 가장 깊은 단계 node까지 확장하며 search하는 방식입니다. DFS가 작동하는 process를 살펴보면 이해가 쉽습니다.DFS는 stack structure를 사용하여 아래 process에 따라 진행합니다. Frontier와 explored set이 존재합니다. Frontier는 initial state(A)를 포함한 state입니다. Explored set는 empty state로 시작합니다. Process가 종료될 때까지 반복합니다. Frontier에 search할 next node 확인: Frontier에 search할 next node가 존재하는지 확인합니다. 만약 없다면 solution이 없음을 의미하며 DFS process를 종료합니다. 참고로 여기서 언급한 node는 state, parent node, action, path cost 정보를 담고 있는 data structure입니다. Next node 가져오기: Frontier에서 last node를 추출합니다. (stack structure) Solution 확인과 return: 2번의 node가 goal test를 통과하면 search process를 종료하고 explored set을 solution으로 정의한 뒤 return합니다. Explored set에 node 추가: 2번의 node가 goal test를 통과하지 못하면 explored set에 node를 추가합니다. Frontier expansion: Frontier에 child node를 추가 합니다. 이 때 child node가 frontier와 explore set에 이미 존재하는지 확인합니다. DFS process위 예시 과정에서 goal state는 node(E)입니다. DFS process에서 last node(F)에 다다르면 goal state인 node(E)와 일치하는지 확인합니다. 일치하지 않으므로 마지막 분기 node(B)로 돌아가서 같은 방식으로 process를 이어갑니다. 다시 last node(E)에 다다르면 goal state인 node(E)와 비교하고 일치하므로 explored set을 solution으로 return하고 DFS process를 종료합니다.   DFS 공간 복잡도, 시간 복잡도Node의 수를 V(Vertex), 연결선의 수를 E(Edge)라고 할 때,DFS의 공간 복잡도는 다음과 같습니다. 인접 행렬인 경우: O($V^2$) 인접 리스트인 경우: O(V+E) 시간 복잡도는 다음과 같습니다. 인접 행렬인 경우: O($V^2$) 인접 리스트인 경우: O(V+E)   DFS 장/단점DFS의 장점은 다음과 같습니다. BFS(Breath-First Search)보다 작은 저장공간이 필요합니다. 지나간 모든 node를 저장할 필요 없이 분기점의 node들만 저장합니다. Goal state인 node가 깊은 단계에 존재할수록 BFS보다 빠릅니다. DFS의 단점은 다음과 같습니다. Goal state인 node가 아닌 다른 last node들의 깊이가 깊을수록 많은 시간을 소비합니다. 항상 optimal solution을 찾는 것은 아닙니다. DFS는 goal state인 node를 만나는 순간 종료되기 때문입니다.   DFS 적용DFS를 미로 문제에 적용해 보겠습니다.Node class는 node 객체를 생성합니다. Node는 앞서 언급한 것처럼 agent state, parent node, 그리고 action에 대한 정보를 가지고 있습니다. DFS는 stack structure를 사용하여 node를 search 합니다. Maze() class: 미로 문제가 담긴 파일을 읽습니다. 시작 위치(S), 종료 위치(E), 벽, 그리고 길을 파악하여 row * column 크기의 행렬로 정리합니다. StackFrontier() class: 비어있는 list 형태의 frontier 객체를 생성 합니다. print_out function: 미로와 solution을 출력합니다. neighbors function: 현재 node에서 이동 가능한 node로의 방향과 좌표를 확인하고 모두 return 합니다. solve function: Solution을 발견하거나 더 이상 frontier에 search할 node가 남아있지 않을 때까지 search 과정을 반복 수행합니다. output_image function: 미로와 발견한 solution을 image 파일로 출력합니다. add function: Frontier에 다음 단계 child node를 추가 합니다. contains_state function: Node가 이미 frontier에 들어 있는지 search 합니다. empty function: Frontier에 담긴 node count가 0인지 확인 합니다. Frontier에 더 이상 가져올 node가 없는지 확인하는 function 입니다. remove function (116 line): 본 class의 핵심 function 입니다. DFS는 stack structure를 사용하므로 가장 마지막 위치의 node를 가져옵니다.   DFS 예제미로 문제를 입력받아 solution을 찾아내는 과정입니다. 전체 code와 예제 파일은 이 곳에서 확인할 수 있습니다. DFS 미로 문제 예제하지만 앞서 언급한 것처럼 DFS의 단점 중 하나는 항상 optimal solution을 찾는 것이 아니라는 것입니다. 위 예제 화면에서도 가까운 길을 두고 먼 길을 돌아 찾아 갔습니다. 이런 경우 optimal solution을 어떻게 찾을 수 있을까요? 바로 BFS(Breath-First Search)를 사용하는 것입니다." }, { "title": "Style Guide for Shell - Google", "url": "/posts/GoogleShellStyleGuide/", "categories": "Programming, Linux", "tags": "linux, shell", "date": "2022-04-15 12:31:12 +0900", "snippet": "What is the Shell and Shell Script? the hard outer covering of some creaturesShell의 사전적 의미 입니다. 컴퓨터에서의 shell도 비슷한 역할을 하는데 OS의 kernel(OS의 일부로서 컴퓨터의 메모리에 상주하는 프로그램)을 감싸고 있습니다. 더 나아가 사용자와 kernel을 연결하는 다리 역할까지 합니다. Shell은 대화창 형태의 interface를 제공하며 사용자가 command를 내리면 OS로 전달하고 OS는 hardware가 이해할 수 있는 언어로 번역합니다. Shell script의 기본 컨셉은 사용자의 command를 실행 순서대로 나열해 놓은 list 입니다. Shell Types?Linux에는 다음과 같은 여러 가지 shell이 존재합니다. Shell Completepath-name Prompt forroot user Prompt fornon-root user Bourne shell(sh) /bin/sh/sbin/sh # $ GNU Bourne-Again shell(bash) /bin/bash bash-VersionNumber# bash-VersionNumber$ C shell(csh) /bin/csh # % Korn shell(ksh) /bin/ksh # $ Z shell(zsh) /bin/zsh &amp;lt;hostname&amp;gt;# &amp;lt;hostname&amp;gt;% Bourne shell (sh): 1977년 AT&amp;amp;T사의 Bell 연구소에서 Stephen Bourne이 개발 했습니다. 최초의 bourne shell 입니다. Bourne Again shell (bash): 1989년 Brian Fox가 GNU project를 위해 개발 했습니다. 현재 linux standard shell로 사용합니다. Google Shell Style Guide (Revision 2.02)많은 Googler에 의해 Google Shell Style Guide가 작성, 수정, 유지되고 있습니다. Background  Which Shell to UseBash는 실행파일에 사용이 허용된 유일한 shell scripting language 입니다. 실행파일은 반드시 “#!/bin/bash“로 시작하고 최소한의 flag를 사용합니다. “set“으로 shell 옵션을 설정하여 “bash script name“으로 script를 실행할 수 있도록 합니다. 모든 실행가능한 shell scripts는 일관성을 위해 “bash“로 한정합니다.   When to use ShellShell은 small utilities나 간단한 wrapper scripts의 목적으로만 사용합니다. Shell script는 개발언어가 아니므로 Google에서는 다양한 utility script 작성 목적으로 사용됩니다. 만약 대부분 다른 utilities를 부르거나 적은 data를 다룬다면, shell이 적합합니다. 작업의 퍼포먼스가 중요하다면 shell이 아닌 다른 language를 사용하세요. 만약 100 lines 이상 긴 script나 직관적이지 않은 로직을 사용한다면, 지금 당장 정형화된 구조로 다시 작성하세요. Code의 복잡성을 평가할 때 (예를 들어 다른 language로 변경을 결정할 때), code 작성자가 아닌 다른 사람들에 의해 손쉽게 유지될 수 있는지 고려하세요. Shell Files and Interpreter Invocation  File Extensions실행파일은 (강력하게 권장하는 바) 확장자를 사용하지 않거나, “.sh” 확장자를 사용합니다. Libraries는 반드시 “.sh” 확장자를 사용하며 실행가능한 상태가 아니어야 합니다. 프로그램이 실행될 때 어떤 language가 사용되었는지 알아야 할 필요가 없으므로 확장자도 사용할 필요가 없습니다. 하지만 libraries는 비슷한 기능을 하는 다른 language로 작성된 library가 필요한 경우가 종종 있으므로 어떤 language로 작성되었는지 아는 것이 중요하며 확장자를 사용합니다.   SUID/SGIDSUID와 SGID는 shell scripts에서 사용을 금지합니다. Shell은 보안 관련 issue가 너무 많으며 SUID/SGID를 허용할만큼 보안이 지켜질 수 없습니다. Environment  STDOUT vs STDERR모든 error messages는 “STDERR“로 보내야 합니다. 그렇게해야 일반적인 상태와 실제 issue를 구분하기 쉽습니다. 다른 상태 정보와 함께 error messages를 출력하는 기능이 권장됩니다.err() { echo &quot;[$(date + &#39;%Y-%m-%dT%H:%M:%S%z&#39;)]: $*&quot; &amp;gt;&amp;amp;2}if ! do_something; then err &quot;Unable to do_something&quot; exit 1fiComments  File HeaderScript는 내용에 대한 설명으로 시작하세요. 모든 script는 반드시 전반적인 내용에 대한 간략한 요약을 top-level comment 형태로 가져야 합니다. Copyright와 작성자 정보 작성은 옵션입니다.#!/bin/bash##Perform hot backups of Oracle databases.  Function Comments명확하지 않고 간략하지도 않은 function은 반드시 comment를 가져야 합니다. Library 내 모든 function은 길이나 복잡도와 상관없이 반드시 comment를 가져야 합니다. 누군가가 code를 읽지 않고 comment를 읽는 것 만으로도 program을 어떻게 사용하는지, library 내 function을 어떻게 사용하는지 알 수 있어야 합니다. Function에 대한 설명 Globals: List of global variables used and modified Arguments: Arguments taken Outputs: Output to STDOUT or STDERR Returns: Returned values other than the default exit status of the last command run 예를 들어,######################################## Cleanup files from the backup directory.# Globals:# BACKUP_DIR# ORACLE_SID# Arguments:# None#######################################function cleanup() { …}######################################## Get configuration directory.# Globals:# SOMEDIR# Arguments:# None# Outputs:# Writes location to stdout#######################################function get_dir() { echo &quot;${SOMEDIR}&quot;}######################################## Delete a file in a sophisticated manner.# Arguments:# File to delete, a path.# Returns:# 0 if thing was deleted, non-zero on error.#######################################function del_thing() { rm &quot;$1&quot;}  Implementation CommentsCode에서 까다롭거나 명확하지 않은 부분, 혹은 흥미롭거나 중요한 부분에 comment를 사용하세요. 모든 내용을 comment에 담지 말고 간단히 적으세요.   TODO CommentsCode의 임시내용, 단기적인 해결책, 충분하지만 완벽하지 않은 부분에 TODO comment를 사용합니다. C++ 가이드를 준수합니다. ‘TODO’ 단어 자체는 모두 대문자를 표기하며, 문제에 대한 설명 내용과 함께 이름, e-mail 주소, 혹은 작성자를 대표하는 다른 표식자를 사용합니다. 이러한 형태의 주요 목적은 일관성 있는 ‘TODO’를 작성함으로써 추후 요청에 대한 자세한 내용을 검색할 수 있도록 하는데 있습니다. ‘TODO’에서 언급한 작성자가 꼭 미래에 해당 문제를 해결해야 하는 것은 아니므로 항상 작성자 정보를 함께 기재합니다.예를 들어,# TODO(mrmonkey): Handle the unlikely edge cases (bug ####)Formatting  IndentationIndent는 2-spaces를 사용합니다. Tab은 사용하지 않습니다. 가독성을 높이기 위해 block 사이에는 blank lines를 사용합니다.   Line Length and Long StringsLine의 최대 글자수는 80자 입니다. 그 이상의 문자가 들어간다면 “here document”나 “개행문자”를 사용합니다.# DO use &#39;here document&#39;scat &amp;lt;&amp;lt;ENDI am an exceptionally longstring.END# Embedded newlines are ok toolong_string=&quot;I am an exceptionallylong string.&quot;  PipelinesPipeline은 하나의 line에 모두 들어가지 않으면 line당 하나로 분리해서 사용합니다. 이 때 새로운 line에 들어가는 pipeline은 2-spaces indent를 사용합니다. 이 규칙은 command 결합에 사용하는 ‘|’, logical 결합에 사용하는 ‘||’와 ‘&amp;amp;&amp;amp;’에 적용됩니다.# All fits on one linecommand1 | command2# Long commandscommand1 \\ | command2 \\ | command3 \\ | command4  Loops‘; do‘와 ‘; then‘은 ‘while’, ‘for’, ‘if’와 동일한 line에 사용하세요.예를 들어,# If inside a function, consider declaring the Loop variable as# a Local to avoid it Leaking into the global environment:# Local dirfor dir in &quot;#{dirs_to_cleanup[@]}&quot;; do if [[ -d &quot;${dir}/${ORACLE_SID}&quot; ]]; then log_date &quot;Cleaning up old files in ${dir}/${ORACLE_SID}&quot; rm &quot;${dir}/${ORACLE_SID}/&quot;* if (( $? != 0 )); then error_message fi else mkdir -p &quot;${dir}/${ORACLE_SID}&quot; if (( $? != 0 )); then error_message fi fidone  Case statement 2-spaces indent를 사용합니다. One-line alternative는 닫는 부호 이후 “;;” 부호 이전에 space 한 개가 필요합니다. Long or multi-command alternatives는 pattern, actions, 그리고 “;;” 기호와 함께 복수 개의 lines로 나뉘어져야 합니다. Matching expressions는 “case”와 “esac”로부터 한 단계 indent를 사용합니다. Multiline actions는 이로부터 한 단계 더 indent를 사용합니다. “;&amp;amp;”와 “;;&amp;amp;” notations는 사용하지 않습니다.case &quot;${expression}&quot; in a) variable=&quot;...&quot; some_command &quot;${variable}&quot; &quot;${other_expr}&quot; ... ;; absolute) actions=&quot;relative&quot; another_command &quot;${ations}&quot; &quot;${other_expr}&quot; ... ;; *) error &quot;Inexpected expression &#39;${expression}&#39;&quot; ;; esac간단한 commands는 가독성이 떨어지지 않는한 pattern, “;;” 기호와 동일한 line에 놓습니다.vervose=&#39;false&#39;aflag=&#39;&#39;bflag=&#39;&#39;files=&#39;&#39;while getopts &#39;abf:v&#39; flag; do case &quot;${flag}&quot; in a) aflag=&#39;true&#39; ;; b) bflag=&#39;true&#39; ;; f) files=&quot;${OPTARG}&quot; ;; v) verbose=&#39;true&#39; ;; *) error &quot;Unexpected option ${flag}&quot; ;; esacdone  Variable expansionVariable quote에서 선호되는 방식은 “$var”보다는 “${var}” 입니다. 하지만 script에서 원래 사용하던 방식을 준수하세요.# Section of *recommended* cases.# Preferred style for &#39;special&#39; variables:echo &quot;Positional: $1&quot; &quot;$5&quot; &quot;$3&quot;echo &quot;Specials: !=$1, -=$-, _=$+. ?=$?, #=$# *=$* @=$@ \\$=$$ ...&quot;# Braces necessary:echo &quot;many parameters: ${10}&quot;# Braces avoiding confusion:# Output is &quot;a0b0c0&quot;set -- a b cecho &quot;${1}0${2}0${3}0&quot;# Preferred style for other variables:echo &quot;PATH=${PATH}, PWD=${PWD}, mine=${some_var}&quot;while read -r f; do echo &quot;file=${f}&quot;done &amp;lt; &amp;lt; (find /tmp)# Section of *discouraged* cases# Unquoted vars, unbraced vars, brace-delimited single letter# shell specials.echo a=$avar &quot;b=$bvar&quot; &quot;PID=${$}&quot; &quot;${1}&quot;# Confusing use: this is expanded as &quot;${1}0${2}0${3}0&quot;,# not &quot;${10}${20}${30}set -- a b cecho &quot;$10$20$30&quot;  Quoting Variables, command substitutions, spaces, 혹은 shell meta characters를 포함하는 문자열은 항상 quote를 사용합니다. Lists of elements의 안전한 quote를 위해서 array를 사용합니다. 정수로 정의된 shell-internal, readonly special variables는 선택적으로 quote를 사용합니다: “$?”, “$#”, “$$”, “$!” Command options이나 path name이 아닌 “words”는 quote를 사용합니다. Literal 정수는 quote를 사용하지 않습니다. ”$*“를 사용해야하는 특별한 이유가 있지 않다면 “$@“를 사용하세요. # &#39;Single&#39; quotes indicate that no substitution is desired.# &quot;Double&quot; quotes indicate that substitution is required/tolerated.# Simple examples# &quot;quote command substitutions&quot;# Note that quotes nested inside &quot;$()&quot; don&#39;t need escaping.flag=&quot;$(some_command and its args &quot;$@&quot; &#39;quoted separately&#39;)&quot;# &quot;quote variables&quot;echo &quot;${flag}&quot;# Use arrays with quoted expansion for lists.declare -a FLAGSFLAGS=( --foo --bar=&#39;baz&#39; )readonly FLAGSmybinary &quot;${FLAGS[@]}&quot;# It&#39;s ok to not quote internal integer variables.if (( $# &amp;gt; 3 )); then echo &quot;ppid=${PPID}&quot;fi# &quot;never quote literal integers&quot;value=32# &quot;quote command substitutions&quot;, even when you expect integersnumber=&quot;$(generate_number)&quot;# &quot;prefer quoting words&quot;, not compulsoryreadonly USE_INTEGER=&#39;true&#39;# &quot;quote shell meta characters&quot;echo &#39;Hello stranger, and well met. Earn lots of $$$&#39;echo &quot;Process $$: Done making \\$\\$\\$.&quot;# &quot;command options or path names&quot;# ($1 is assumed to contain a value here)grep -li Hugo /dev/null &quot;$1&quot;# Less simple examples# &quot;quote variables, unless proven false&quot;: ccs might be emptygit send-email --to &quot;${reviewers}&quot; ${ccs:+&quot;--cc&quot; &quot;${ccs}&quot;}# For passing on arguments,# &quot;$@&quot; is right almost every time, and# $* is wrong almost every time:# * $* and $@ will split on spaces, clobbering up arguments# that contain spaces and dropping empty strings;# * &quot;$@&quot; will retain arguments as-is, so no args# provided will result in no args being passed on;# This is in most cases what you want to use for passing# on arguments.# * &quot;$*&quot; expands to one argument, with all args joined# by (usually) spaces,# so no args provided will result in one empty string# being passed on.# (Consult `man bash` for the nit-grits ;-)(set -- 1 &quot;2 two&quot; &quot;3 three tres&quot;; echo $#; set -- &quot;$*&quot;; echo &quot;$#, $@&quot;)(set -- 1 &quot;2 two&quot; &quot;3 three tres&quot;; echo $#; set -- &quot;$@&quot;; echo &quot;$#, $@&quot;)Features and Bugs  ShellCheckShellCheck Project는 입력한 shell scripts의 일반적인 bugs와 warnings를 확인해 주는 사이트 입니다.   Command SubstitutionBackticks 대신 “$(command)“를 사용합니다. Nested backticks는 내부에 escaping 문자로 “&quot;를 사용해야 합니다. 이에 반해 “#(command)” 형식은 읽기 쉽고 escaping도 필요하지 않습니다.예를 들어,# This is preferred:var=&quot;$(command &quot;$(commdna1)&quot;)&quot;# This is not:var=&quot;`command \\`command1\\``&quot;  Test, [ … ], and [[ … ]]”[ … ]”, “test”, “/usr/bin/[” 보다 “[[ … ]]“가 선호되는 방식입니다. 후자 방식이 errors를 줄이고 정규표현식 사용이 가능하기 때문입니다.# This ensures the string on the left is made up of characters in# the alnum character class followed by the string name.# Note that the RHS should not be quoted here.if [[ &quot;filename&quot; =~ &amp;amp;[[:alnum:]]+name ]]; then echo &quot;Match&quot;fi# This matches the exact pattern &quot;f*&quot; (Does not match in this case)if [[ &quot;filename&quot; == &quot;f*&quot; ]]; then echo &quot;Match&quot;fi# This gives a &quot;too many arguments&quot; error as f* is expanded to the# contents of the current directoryif [ &quot;filename&quot; == f* ]; then echo &quot;Match&quot;fi  Testing Strings가능하면 filter characters 방식보다 quote를 사용하세요.# Do this:if [[ &quot;${mu_var}&quot; == &quot;some_string&quot; ]]; then do_somethingfi# -z (string length is zero) and -n (string length is not zero) are# preffered over testing for an empty stringif [[ -z &quot;${my_var}&quot; ]]; then do_somethingfi# This is OK (ensure quotes on the empty side), but not preferred:if [[ &quot;${my_var}&quot; == &quot;&quot; ]]; then do_somethingfi# Not this:if [[ &quot;${my_var}X&quot; == &quot;some_stringX&quot; ]]; then do_somethingfi혼란을 피하기 위해서 “-z”나 “-n” 옵션을 사용합니다.# Use thisif [[ -n &quot;${my_var}&quot; ]]; then do_somethingfi# Instead of thisif [[ &quot;${my_var}&quot; ]]; then do_somethingfiEquality 표현은 “=” 대신 “==“을 사용합니다. 숫자를 비교할 때는 “(( … ))” 혹은 “-lt”, “-gt” 방식을 사용합니다.# Use thisif [[ &quot;${my_var}&quot; == &quot;val&quot; ]]; then do_somethingfiif (( my_var &amp;gt; 3 )); then do_somethingfiif [[ &quot;${my_var}&quot; -gt 3 ]]; then do_somethingfi# Instead of thisif [[ &quot;${my_var}&quot; = &quot;val&quot; ]]; then do_somethingfi# Probably unintended lexicographical comparison.if [[ &quot;${my_var}&quot; &amp;gt; 3 ]]; then # True for 4, false for 22. do_somethingfi  Wildcard Expansion of FilenamesWildcard를 사용한 파일명을 확장할 때는 명시적인 경로명을 사용합니다. 파일명이 “-“로 시작할 수도 있고, “*” 대신 “./*“가 훨씬 안전합니다.# Here&#39;s the contents of the directory:# -f -r somedir somefile# Incorrectly deletes almost everything in the directory by forcepsa@bilby$ rm -v *removed directory: `somedir&#39;removed `somefile&#39;# As opposed to:psa@bilby$ rm -v ./*removed `./-f&#39;removed `./-r&#39;rm: cannot remove `./somedir&#39;: Is a directoryremoved `./somefile&#39;  Eval“eval“은 사용하지 않아야 합니다. Eval은 variable을 할당할 때 input을 삭제하고, 해당 변수들이 과거에 무엇이었는지 확인하지 않고도 할당할 수 있습니다.# What does this set?# Did it succeed? In part or whole?eval $(set_my_variables)# What happens if one of the returned values has a space in it?variable=&quot;$(eval some_function)&quot;  ArraysBash array는 lists of elements를 저장하고 quoting complications를 피하기 위해 사용합니다. 특히 argument lists에 적용됩니다. Array는 정렬된 strings collection을 저장하고 command나 loop문의 각각 elements로 안전하게 확장할 수 있습니다.# An array is assigned using parentheses, and can be appended to# with +=( ... ).declare -a flagsflags=(--foo --bar=&#39;baz&#39;)flags+=(--greeting=&quot;Hello ${name}&quot;)mybinary &quot;${flags[@]}&quot;# Don&#39;t use strings for sequences.flags=&#39;--foo --bar=baz&#39;flags+=&#39; --greeting=&quot;Hello world&quot;&#39; # This won&#39;t work as intended.mybinary ${flags}# Command expansions return single strings, not arrays. Avoid# unquoted expansion in array assignments because it won&#39;t# work correctly if the command output contains special# characters or whitespace.# This expands the listing output into a string, then does special keyword# expansion, and then whitespace splitting. Only then is it turned into a# list of words. The ls command may also change behavior based on the user&#39;s# active environment!declare -a files=($(ls /directory))# The get_arguments writes everything to STDOUT, but then goes through the# some expansion process above before turning into a list of arguments.mybinary $(get_arguments)  Pipes to WhilePipe로 while을 연결하는 대신 process substitution이나 bash4+ builtin readarray를 사용하세요. Pipe는 subshell을 생성하는데 이 곳에서 수정되는 모든 variables는 parent shell에 공유되지 않기 때문입니다.last_line=&#39;NULL&#39;your_command | while read -r line; do if [[ -n &quot;{line}&quot; ]]; then last_line=&quot;${line}&quot; fidone# This will always output &#39;NULL&#39;!echo &quot;{last_line}&quot;Process substitution도 마찬가지로 subshell을 생성하지만, subshell 내에서 while이나 다른 command 없이 while로 reditecting을 허용합니다.last_line=&#39;NULL&#39;while read line; do if [[ -n &quot;${line}&quot; ]]; then last_line=&quot;${line}&quot; fidone &amp;lt; &amp;lt;(your_command)# This will output the last non-empth line from your_commandecho &quot;${last_line}&quot;또는 내장된 readarray를 사용하세요. 위와 같은 이유로 pipe 대신 readarray와 함께 process substitution 방식을 사용합니다.last_line=&#39;NULL&#39;readarray -t lines &amp;lt; &amp;lt;(your_command)for line in &quot;${lines[#]}&quot;; do if [[ -n &quot;${line}&quot; ]]; then last_line=&quot;${line}&quot; fidoneecho &quot;${last_line}&quot;  Arithmetic“let”, “$[ … ]”, “expr” 대신 “(( … ))”, “$(( … ))“를 사용하세요.# Simple calculation used as text - note the use of $(( ... )) within# a string.echo &quot;$(( 2 + 2 )) is 4&quot;# When performing arithmetic comparisons for testingif (( a &amp;lt; b )); then ...fi# Some calculation assigned to a variable.(( i = 10 * j + 400 ))# This form is non-portable and deprecatedi=$[2 * 10]# Despite appearances, &#39;let&#39; isn&#39;t one of the declarative keywords,# so unquoted assignments are subject to globbing wordsplitting.# For the sake of simplicity, avoid &#39;let&#39; and use (( ... ))let i=&quot;2 + 2&quot;# The expr utility is an externak program and not a shell builtin.i=$( expr 4 + 4 )# Quoting can be error prone when using expr too.i=$( expr 4 &#39;*&#39; 4 )또한 “expr”보다 shell의 built-in arithmetic이 몇 배 더 빠릅니다. Variables를 사용할 때 “$(( … ))” 안에서 “${var}” (그리고 “$var”)) 형태가 필요하지 않습니다.# N. B.: Remember to declare your variables as integers when# possible, and to prefer local variables over glovals.local -i hundred=$(( 10 * 10 ))declare -i five=$(( 10 / 2 ))# Increment the variable &quot;i&quot; by three.# Note that:# - We do not write ${i} or $i.# - We put a aspace after the (( and before the )).(( i += 3 ))# To decrement the variable &quot;i&quot; by five:(( i -= 5 ))# Do some complicated computations.# Note that normal ariithmetic operator precedence is observed.hr=2min=5sec=30echo $(( hr * 3600 + min * 60 + sec )) # prints 7530 as expectedNaming Conventions  Function Names소문자를 사용하고 두 개 이상 단어를 분리할 때 underscore를 사용합니다. 복수 개의 library는 “::” 기호로 분리합니다. Function name 다음에는 parentheses를 사용합니다.# Single functionmy_func() { ...}# Part of a packagemypackage::my_func() { ...}  Variable NamesFunctiona names와 동일한 규칙을 따릅니다. 반복문 내 looping variable name은 서로 유사한 name을 사용합니다.for zone in &quot;${zones[@]}&quot;; do something_with &quot;${zone}&quot;done  Constants and Environment Variable Names모두 대문자를 사용하고 두 개 이상 단어를 분리할 때 underscore를 사용합니다. 파일의 최상단에 선언합니다.# Constantreadonly PATH_TO_FILES=&#39;/some/path&#39;# Both constant and environmentdeclare -xr ORACLE_SID=&#39;PROD&#39;명확성을 위해 “declare”보다 “readonly“나 “export” 사용을 권장합니다.VERBOSE=&#39;false&#39;while getopts &#39;v&#39; flag; do case &quot;${flag}&quot; in v) VERBOSE=&#39;true&#39; ;; esacdonereadonly VERBOSE  Source Filenames소문자를 사용하고 두 개 이상 단어를 분리할 때 underscore를 사용합니다.  Read-only VariablesRead-only임을 확실히 하기 위해 “reaonly“나 “declare -r“을 사용합니다.zip_version=&quot;$(dpkg --status zip | grep Version: | cut -d &#39; &#39; -f 2)&quot;if [[ -z &quot;${zip_version}&quot; ]]; then eooro_messageelse readonly zip_versionfi  Use Local VariablesFunction-specific variables는 “local“과 함께 선언합니다. 선언과 assignment는 서로 다른 lines로 구분해야 합니다.my_func2() { local name=&quot;$1&quot; # Separate lines for declaration and assignment: local my_var my_var=&quot;$(my_func)&quot; (( $? == 0 )) || return ...}my_func2() { # DO NOT do this: # $? will always be zero, as it contains the exit code of &#39;local&#39;, not my_func local my_var=&quot;$(my_func)&quot; (( $? == 0 )) || return ...}  Function Location모든 function은 파일의 constants 바로 아래 함께 놓아두세요. Functions 사이에 executable code를 숨겨 놓지 않습니다.   main“main” function은 적어도 한 개 이상의 다른 function을 포함하며 파일의 제일 아래에 위치합니다. 가장 마지막 non-comment line은 “main” function calling을 합니다. Calling Commands  Checking Return Values항상 return values를 체크하고 관련 정보를 제공합니다. Unpiped commands에서는 “$?”를 사용하거나 “if”문을 통해서 확인합니다.if ! mb &quot;${file_list[@]}&quot; &quot;${dest_dir}/&quot;; then echo &quot;Unable to move ${file_list[*]} to ${dest_dir}&quot; &amp;gt;&amp;amp;2 exit 1fi# Ormv &quot;${file_list[@]}&quot; &quot;${dest_dir}/&quot; echo &quot;Unable to move ${file_list[*]} to ${dest_dir}&quot; &amp;gt;&amp;amp;2 exit 1fiBash는 또한 “PIPESTATUS” 변수를 가지고 있는데 모든 pipe의 return values를 체크하도록 허용합니다.tar -cf - ./* | ( cd &quot;${dir}&quot; &amp;amp;&amp;amp; tar -xf - )if (( PIPESTATUS[0] != 0 || PIPESTATUS[1] != 0 )); then echo &quot;Unable to rat files to ${dir}&quot; &amp;gt;&amp;amp;2fi하지만 “PIPESTATUS“는 다른 command를 사용하면 이를 덮어쓰기 때문에, pipe마다 발생하는 errors에 대해 서로 다른 대처가 필요한 경우 command를 실행한 이후 “PIPESTATUS“를 다른 변수에 할당해야 합니다.tar -cf - ./* | ( cd &quot;${DIR}&quot; &amp;amp;&amp;amp; tar -xf - )return_codes=( &quot;${PIPESTATUS[@]}&quot; )if (( return_codes[0] != 0 )); then do_somethingfiif (( return_codes[1] != 0 )); then do_something_elsefi  Builtin Commands vs. External CommandsShell builtin commands와 분리된 프로세스 commands를 사용 가능하다면 shell builtin commands를 사용합니다.# Prefer this:addition=$(( X + Y ))substitution=&quot;${string/#foo/bar}&quot;# Instead of this:addition=&quot;$(expr &quot;${X}&quot; + &quot;${Y}&quot;)&quot;substitution=&quot;$(echo &quot;${string}&quot; | sed -e &#39;s/^foo/bar/&#39;)&quot;ConclusionUse common sense and BE CONSISTENT.Revision 2.02" }, { "title": "Style Guide for Python Code - PEP8", "url": "/posts/PEP8/", "categories": "Programming, Python", "tags": "python", "date": "2022-03-27 12:15:00 +0900", "snippet": "Python Language 생각이나 느낌을 나타내거나 전달하기 위하여 사용하는 음성, 문자, 몸짓 등의 수단 또는 그 사회관습적 체계언어의 사전적 정의입니다. 언어란 한 사회의 구성원 사이에 약속된 의사소통 규칙이자 오랜 세월 특유의 문화와 역사가 담긴 사회관습적 체계입니다.여러분은 외국어를 공부한 경험이 있을 것입니다. 처음에 어떤 방식으로 접근하셨나요? 누군가는 단어와 문법을 공부하며 언어에 대한 지식을 쌓아갑니다. 누군가는 외국에서 현지인들과 소통하며 자연스럽게 외국어를 익힙니다. 어떤 방식을 사용하던지 최종 목표는 그 언어에 담긴 철학을 이해하고 자유롭게 구사하여 의사 소통 하는 것입니다.Programming language도 마찬가지입니다. Python을 사용해서 code를 작성하고 다른 개발자와 의사 소통 하려면 우선 python을 이해해야 합니다. Python Philosophy Readability counts.Python의 철학은 PEP20: The Zen of Python에서 19개 문장으로 설명합니다. 한 마디로 요약하면 readability! Python은 누가 봐도 읽기 쉽고 간결한 code를 지향합니다. PEP8은 무엇일까요?PEP(Python Enhancement Proposals)는 ‘Python 제안 사항’ 정도로 이해할 수 있습니다. Python의 새로운 기능이나 적용사항을 안내하고 사용 가이드라인과 정보를 제공합니다.PEP8은 python을 만든 Guido van Rossum을 포함하여 세 명의 저자가 작성한 문서로 python code에 대한 style guide 내용을 담고 있습니다. 일종의 code 규칙을 제안하는 문서로 이해할 수 있습니다. 이 외에도 다양한 python style guide가 존재하는데 대부분 PEP8을 기반으로 만들어졌기 때문에 알아두는 것이 좋습니다. 상세한 내용은 PEP8 공식문서를 참고하세요. 이제부터 PEP8을 하나씩 알아보겠습니다. A Foolish Consistency is the Hobgoblin of Little Minds미국의 철학자이자 시인으로 활동한 Ralph Waldo Emerson의 ‘Self-Reliance’에 나오는 문구입니다. 원문은 아래와 같습니다. “A foolish consistency is the hobgoblin of little mindes, adored by little statesment and philosophers and divines.” “어리석은 일관성은 별 볼 일 없는 정치가와 철학자, 그리고 신학자들이 사랑하는, 편협한 마음을 가진 홉고블린이다.”문구의 앞/뒤 문맥을 살펴보면 오늘과 내일 하는 말이 모순될 지언정, 다른 사람의 시선에 휘둘리지 않고 자신을 신뢰하는 자세가 사회를 지탱하고 더 나은 방향으로 나아가도록 만든다고 이야기 합니다. 사회의 정해진 규칙과 타인이 옳다고 여기는 기준에 맞춰 바보같이 사는 것은 소인배 홉고블린에 지나지 않다는 의미이기도 합니다. 이 사상은 오늘날 미국을 지탱하는 개인주의 정신의 근간이 되었습니다.Python code에서 가독성은 매우 중요합니다. 따라서 PEP8이 제시하는 style guide에 얽매일 필요없이 더 나은 방식이 있다면 반드시 사용하시기 바랍니다. Code Lay-out    Indentation하나의 indentation 레벨은 4개의 spaces를 사용합니다. 연속된 line은 괄호/중괄호/대괄호 내부에서 python의 implicit line joining을 사용하여 수직선 상에 맞추거나 hanging indent를 사용합니다. 이 때 첫 번째 line에 arguments를 넣지 않습니다. 또한 2-spaces로 대체함으로써 예외적으로 4-spaces 규칙을 벗어날 수 있습니다.## Correct:# Aligned with opening delimiter.foo = long_function_name(var_one, var_two, var_three, var_foue) # Add 4-spaces (an extra level of indentation) to distinguish arguments from the rest.def long_function_name( var_one, var_two, var_three, var_four): print(var_one)# Hanging indents should add a level.foo = long_function_name( var_one, var_two, var_three, var_four)## Wrong:# Arguments on first line forbidden when not using vertical alignment.foo = long_function_name(var_one, var_two,var_three, var_four)# Further indentation required as indentation is not distinguishable.def long_function_name( var_one, var_two, var_three, var_four): print(var_one)if문 같은 조건문의 조건이 길어지는 경우, 괄호를 사용하여 multiline으로 작성합니다. 마찬가지로 4-spaces 규칙이 기본 적용되며 경우에 따라 추가 indent를 사용합니다.# No extra indentation.if (this_is_one_thing and that_is_another_thing): do_something()# Add a comment, which will provide some distinction in editors# supporting syntax highlighting.if (this_is_one_thing and that_is_another_thing): # Since both conditions are true, we can frobnicate. do_something()# Add some extra indentation on the conditional continuation line.if (this_is_one_thing and that_is_another_thing): do_something()닫는 괄호/중괄호/대괄호는 multiline 중 마지막 line의 첫 번째 글자와 동일선상에 맞추거나, 첫 번째 line의 시작과 동일선상에 맞춥니다.# Closing brace/bracker/parenthesis on multiline constructs# line up under the first non-whitespace character of the last line of listmy_list = [ 1, 2, 3, 4, 5, 6, ]result = some_function_that_takes_arguments( &#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;, ) # or line up under the first character of the line that starts the multiline constructmy_list = [ 1, 2, 3, 4, 5, 6,]result = some_function_that_takes_arguments( &#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39;,)    Tabs or Spaces?Space가 더 선호되는 방식입니다. Tab은 이미 작성된 code에서 indent가 tab으로 작성되어 있는 경우 사용합니다. Python3에서는 space와 tab 혼용을 금지합니다. Python2에서는 혼용이 가능하지만 tab을 space로 변환하도록 강력히 권고합니다.     Maximum Line Length모든 line은 최대 79자 이내로 제한합니다. Docstrings나 comments 같은 몇몇 구조는 최대 72자로 제한합니다. Line의 글자수를 제한하면 두 개 이상 code를 editor로 열어서 동시에 작업할 수 있습니다. 또한 더 깔끔한 code를 작성할 수 있습니다. Multiline으로 작성할 경우 앞서 언급한 indent 규칙을 준수하고 backslash를 사용합니다.with open(&#39;/path/to/some/file/you/want/to/read&#39;) as file_1, \\ open(&#39;/path/to/some/file/being/written&#39;) as file_2: file_2.write(file_1.read())    Should a Line Break Before or Agter a Binary Operator?사칙연산 기호와 line break의 위치에 관한 내용입니다. 과거에는 사칙연산 기호 이후에 line break가 위치하는 style을 권장했습니다. 하지만 다음 두 가지 이유로 가독성을 떨어뜨립니다. 연산기호가 line마다 다른 위치로 흩어집니다. 연산기호의 대상을 명확하게 파악하기 어렵습니다.## Wrong:# operators sit far away from their operandsincome = (gross_wages + taxable_interest + (dividents - qualified_dividents) - ira_deduction - student_loan_interest)하지만 수학에서는 전통적으로 사칙연산 기호 이전에 line break가 위치하는 style을 사용합니다. 가독성이 더 좋은 이 방식을 python에서도 권장합니다.## Correct:# easy to match operators with operandsincome = (gross_wages + taxable_interest + (dividents - qualified_dividents) - ira_deduction - student_loan_interest)    Blank LinesTop-level function과 class는 두 개의 blank lines로 감쌉니다. class 내 method는 한 개의 blank line으로 감쌉니다. 서로 연관된 functions 그룹을 구분하거나 논리적 섹션을 구분하기 위해서 추가 blank line을 사용할 수 있습니다.     Source File EncodingCore python 배포판 code는 UTF-8을 사용합니다. 모든 python standard library의 식별자는 반드시 ASCII 식별자와 영어 단어를 사용합니다.     ImportsImports는 line을 분리하여 수행합니다.## Correct:import osimport sysfrom subprocess import Popen, PIPE## Wrong:import sys, osImports는 항상 파일의 최상단에 위치합니다. Module comments와 docstrings 다음에, 그리고 module globals와 constants 이전에 위치합니다.Wildcard imports(from ‘module’ import *)는 다른 개발자와 automated tools에 혼동을 주기 때문에 사용하지 않습니다.     Module Level Dunder NamesModule level “dunders”(두 개의 underscore로 시작하고 끝나는 명칭입니다. 예를 들어, all, author, version, etc) module docstring 다음에, 그리고 ‘from future’ import를 제외한 import문 이전에 위치합니다.&quot;&quot;&quot;This is the example module.This module does stuff.&quot;&quot;&quot;from __future__ import barry_as_FLUFL__all__ = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]__version__ = &#39;0.1&#39;__author__ = &#39;Cardinal Biggles&#39;import osimport sysString QuotesPython에서 single-quoted strings(‘)와 double-quoted strings(“)를 동일하게 작동합니다. 둘 중 하나를 선택하면 계속 동일한 방식을 사용합니다. 다만 triple-quoted strings는 PEP257의 docstring convention에 따라 double quote characters(“”“)를 사용합니다. Whitespace in Expressions and Statements    Pet Peeves‘Pet Peeves’ 의미를 우선 알아보겠습니다. 사전적 의미는 ‘Something that a particular person finds especially annoying’ 입니다. 한 사람이 지극히 싫어하고 기피하는 총체적인 것들을 의미합니다. ‘Pet’은 보통 귀엽고 돌봐줘야 하는 존재로 많이 사용되지만 아이러니하게 19세기 혐오하거나 아주 싫은 부정적인 의미로 동시에 사용되기 시작했다고 합니다. ‘Peeve’는 훨씬 더 오래된 단어 ‘peevish’에서 파생되었는데 ‘easily irritated’ 의미를 가지고 있습니다. 두 개의 단어가 합쳐져 위와 같은 의미를 지니게 되었다고 합니다. 자세한 내용은 링크를 참고하세요.PEP8에서도 아래 상황에서 과도한 whitespace 사용을 싫어합니다. 괄호, 중괄호, 대괄호 바로 안## Correct:spam(ham[1], {eggs: 2})## Wrong:spam( ham[ 1 ], { eggs: 2 } ) 뒤에 따라오는 comma와 닫는 괄호 사이## Correct:foo = (0,)## Wrong:foo = (0, ) comma, semicolon, colon 바로 앞## Correct:if x == 4: print(x, y); x, y = y, x## Wrong:if x == 4 : print(x , y) ; x , y = y , x 그러나 slice 안에서 colon이 binary operator처럼 작동할 때는 양쪽에 동일한 숫자의 whitespace를 추가로 사용가능## Correct:ham[1:9], ham[1:9:3], ham[:9:3], ham[1::3], ham[1:9:]ham[lower:upper], ham[lower:upper:], ham[lower::step]ham[lower+offset : upper+offset]ham[: upper_fn(x) : step_fn(x)], ham[:: step_fn(x)]ham[lower + offset : upper + offset]## Wrong:ham[lower + offset:upper + offset]ham[1: 9], ham[1 :9], ham[1:9 :3]ham[lower : : upper]ham[ : upper] function 에서 arguments를 시작하는 여는 괄호 바로 앞## Correct:spam(1)## Wrong:spam (1) Indexing or slicing을 시작하는 여는 괄호 바로 앞## Correct:dct[&#39;key&#39;] = lst[index]## Wring:dct[&#39;key&#39;] = lst [index] 동일선상에 맞추기 위해 variable assignment시 한 개 이상의 whitespace 사용## Correct:x = 1y = 2long_variable = 3## Wrong:x = 1y = 2long_variable = 3    Other Recommendations 뒤에 따라오는 whitespace는 잘 보이지 않아 혼란을 줄 수 있으므로 사용하지 않습니다. 다음 binary operators는 양쪽에 각각 single whitespace를 넣습니다.: assignment(=), augmented assignment (+=, -=, etc), comparisons (==, &amp;lt;, &amp;gt;, !=, &amp;lt;&amp;gt;, &amp;lt;=, &amp;gt;=, in, not in, is, is not), Booleans (and, or, not) 만약 다른 우선도를 가진 operators가 사용된다면 가장 낮은 우선도를 가진 operators 주변에 한 개의 whitespace 사용을 고려할 수 있습니다. ## Correct:i = i + 1submitted += 1x = x*2 - 1hypot2 = x*x + y*yc = (a+b) * (a-b)## Wrong:i=i+1submitted +=1x = x * 2 - 1hypot2 = x * x + y * yc = (a + b) * (a - b) Function annotation은 만약 arrow가 존재한다면 주변에 whitespace를 사용합니다.## Correct:def munge(input: AnyStr): ...def munge() -&amp;gt; PosInt: ...## Wrong:def munge(input:AnyStr): ...def munge()-&amp;gt;PosInt: ... Keyword argument를 나타내거나 unannotated function parameter의 기본 값을 나타낼 때 사용하는 ‘=’ sign 주변에는 whitespace를 사용하지 않습니다.## Correct:def complex(real, imag=0.0): return magic(r=real, i=imag)## Wrong:def complex(real, imag = 0.0): return magic(r = real, i = imag) Compound statements (multiple statements on the same line)은 보통 사용하지 않습니다.## Correct:if foo == &#39;blah&#39;: do_blah_thing()do_one()do_two()do_three()When to Use Trailing Commas 뒤에 따라오는 comma의 사용은 보통 옵션입니다만, tuple에서 한 개의 element만 들어있는 경우 꼭 사용해야 합니다. 그리고 version control system, list of values, arguments 혹은 imported items가 추후 확장될 가능성이 있다면 사용하는 것이 좋습니다.## Correct:FILES = (&#39;setup.cfg&#39;,)FILES = [ &#39;setup.cfg&#39;, &#39;tox.ini&#39;, ]initialize(FILES, error=True, )## Wrong:FILES = &#39;setup.cfg&#39;,FILES = [&#39;setup.cfg&#39;, &#39;tox.ini&#39;]initialize(FILES, error=True,)Comments모순된 comment는 차라리 없는 것만 못 합니다. Code가 바뀌면 comment를 꼭 업데이트 합니다. Comment는 항상 완전한 문장으로 기록합니다. 첫 번째 문자는 항상 대문자를 사용합니다.Block comment는 한 두 개의 paragraph로 구성되고, 각 문장은 마침표로 끝맺음 합니다. Multi-sentence comment인 경우 가장 마지막 문장을 제외하고 각 마침표 이후에 두 개의 whitespace를 사용합니다.Comment는 항상 명확하고 이해하기 쉽게 기록합니다. 비영어권 coder도 반드시 영어로 comment를 기록하세요.     Block CommentsBlock comment는 code와 동일선상에 맞춰 기록합니다. Comment 각 line은 ‘#’과 single space로 시작합니다.     Inline CommentsInline comment는 가급적 사용하지 않습니다. 만약 사용한다면 code에서 두 개 이상의 space를 넣은 뒤 inline comment를 기록합니다. Block comment와 마찬가지로 comment는 ‘#’과 single space로 시작합니다. Code 내용이 명확하다면 comment를 사용하지 않습니다.     Documentation Strings훌륭한 documentation strings(docstrings)를 기록하는 규칙은 PEP257에 뿌리를 둡니다. 모든 public modules, functions, classes, 그리고 methods에 docstrings를 작성합니다. Multi-lines docstrings 작성에 가장 중요한 것은 끝맺음하는 ‘”””’ 기호를 독립된 마지막 line에 위치시키는 것입니다. 단, one line docstings는 ‘”””’ 기호를 같은 line에 위치시킵니다. ## Correct:&quot;&quot;&quot;Return a foobangOptional plotz says to frobnicate the bizbaz first.&quot;&quot;&quot;&quot;&quot;&quot;Return an ex-parrot.&quot;&quot;&quot;Naming Conventions이미 배포된 python library의 naming convention은 완벽한 일관성을 보이지 않고 어지러운 편입니다. 그럼에도 불구하고 앞으로 안내하는 규칙에 따라 작성하기를 권장합니다.     Overriding Principle사용자에게 보이는 API의 공개적인 파트는 사용법을 반영한 conventions를 따릅니다.     Descriptive: Naming Styles다양한 naming style이 존재하며 어떤 종류가 있는지 인지하는 것이 도움이 될 수 있습니다. b (single lowercase letter) B (single uppercase letter) lowercase lower_case_with_underscores UPPERCASE UPPER_CASE_WITH_UNDERSCORES CapitalizedWords (or CapWords, or CamelCase) mixedCase Capitalized_Words_With_Underscores (ugly!) _single_leading_underscore single_trailing_underscore_ __double_leading_underscore __double_leading_and_trailing_underscore__     Prescriptive: Naming Styles        Names to Avoid다음 single character를 variable명으로 사용하지 않습니다. 일부 font에서 character와 number, lowercase와 uppercase 구분이 불가능하기 때문입니다. ‘l’ (lowercase letter el) ‘O’ (uppercase letter oh) ‘I’ (uppercase letter eye)         ASCII CompatibilityPEP3131에서 언급하는바와 같이 standard library에 사용하는 identifier는 반드시 ASCII와 호환되어야 합니다.         Package and Module NamesModule명은 짧게, 모두 lowercase로 명명합니다. 가독성이 좋아진다면 module명 내부에 underscore를 넣을 수 있습니다.Python package명도 짧게, 모두 lowercase로 명명합니다. 하지만 underscore 사용은 권장하지 않습니다.         Class NamesClass명은 보통 CapWords convention을 사용합니다.         Type Variable NamesPEP484에서 소개하는 type variable명은 보통 짧은 CapWords를 사용합니다.예) T, AnyStr, Num         Exception NamesException은 class이기 때문에 class naming convention을 따르며 반드시 suffix로 “Error”를 사용합니다.         Global Variable NamesFunction naming convention과 동일합니다.         Function and Variable NamesFunction명과 Variable명은 lowercase를 사용하며 가독성을 높힐 수 있다면 word 사이에 underscore를 사용할 수 있습니다.         Method Names and Instance VariablesFunction naming convention과 동일합니다.         ConstantsConstant는 module level에서 정의됩니다. 모두 capital letter로 작성하고 word 사이에 underscore를 사용합니다.예) MAX_OVEFLOW, TOTAL         Designing for Inheritance(생략)         Public and Internal Interfaces(생략) Programming Recommendations Code는 다른 파이썬 (PyPy, Jython, IronPython, Cython, Psyco, and such) 실행에 방해를 주는 방식으로 작성하면 안됩니다. ‘None’과 같은 singleton과 비교할 때는 ‘is’ or ‘is not’을 사용합니다. Equality operator를 사용하지 않습니다. ‘is not’을 사용합니다. ‘not … is’는 사용하지 않습니다. 동일한 기능을 하지만 전자의 가독성이 더 좋고 선호되는 방식입니다. ## Correct:if foo is not None:## Wrong:if not foo is None: Lambda 표현식을 활용한 assignment statement 대신에 항상 def statement를 사용합니다.## Correct:def f(x): return 2*x## Wrong:f = lambda x: 2*x Return statements는 일관성을 유지합니다. Function 내 모든 return statements가 expression을 내보내거나 혹은 모두 아무것도 내보내지 않습니다.## Correct:def foo(x): if x &amp;gt;= 0: return math.sqrt(x) else: return Nonedef bar(x): if x &amp;lt; 0: return None return math.sqrt(x)## Wrong:def foo(x): if x &amp;gt;= 0: return math.sqrt(x)def bar(x): if x &amp;lt; 0: return return math.sqrt(x) Prefix나 suffixe를 확인할 때 string slicing 대신 ‘ ‘.startswith()와 ‘ ‘.endswith()를 사용합니다. 더 명확하고 error 발생 가능성도 적습니다.## Correct:if foo.startswith(&#39;bar&#39;):## Wrong:if foo[:3] == &#39;bar&#39;: Type을 비교할 때는 isinstance()를 사용합니다. 직접 비교하지 않습니다.## Correct:if isinstance(obj, int):## Wrong:if type(obj) is type(1): Sequence(strings, lists, tuples)를 확인할 때는 비어있는 상태가 false라는 사실을 사용합니다.## Correct:if not seq:if seq:## Wrong:if len(seq):if not len(seq): Boolean 값을 ‘==’ operator를 사용하요 True or False와 비교하지 않습니다.## Correct:if greeting:## Wrong:if greeting == True:## Wrose:if greeting is True:    Function AnnotationsFunction annotation은 PEP484 규칙을 따릅니다.     Variable AnnotationsVariable annotation은 PEP526 에 소개되어 있습니다. Style은 위에서 설명한 function annotations와 유사합니다. Module level의 variables, class, instance variables, 그리고 local variables의 annotations는 colon 다음에 single space를 사용해야 합니다. Colon 전에는 space를 사용하지 않습니다. Assignment가 오른쪽 정렬인 경우, equality sign은 양 쪽에 single space를 각각 사용합니다. ## Correct:code: intclass Point: coords: Tuple[int, int] label: str = &#39;&amp;lt;unknown&amp;gt;&#39;## Wrong:code:int # No space after coloncode : int # Space before colonclass Test: retuls: int=0 # No spaces around equality sign" }, { "title": "VS code", "url": "/posts/VScode/", "categories": "Programming, Tool", "tags": "tool, python", "date": "2022-03-27 00:05:00 +0900", "snippet": "IDE란 무엇인가요?IDE(Intergrated Development Environment)는 software 개발에 필요한 theme와 plugin을 제공하고 각종 programming language로 code를 구현할 수 있는 통합 개발 환경입니다. ‘VS code’, ‘Sublime Text’, ‘Eclipse’, ‘Atom’, ‘Notepae++’ 등 다양한 IDE가 있습니다.저는 부문 내 ‘체외진단용의료기기 CE/IVD 인증 프로젝트’에 참여하면서 IDE 사용을 시작합니다. 다양한 IDE 중 VS code를 선택합니다.왜 VS code를 선택했나요?이유는 단순합니다. 가장 많은 개발자가 사용하는 IDE가 VS code이기 때문입니다. Stackoverflow는 매년 사이트 이용자 대상으로 각종 설문조사를 실시하고 발표합니다. VS code는 출시한 2016년 이후 매년 IDE 부분에서 1등을 차지하고 있습니다. IDE survey result of stackoverflow, 2021VS code(VisualStudio Code)는 2016년 4월에 마이크로소프트에서 출시했습니다. 사용하기에 비교적 가볍고 개발에 필요한 다양한 확장 기능을 제공합니다. 저는 개발서버, git과 연동하여 코딩하고 lint 기능을 활용하여 coding convention를 준수하기 위해 노력합니다.VS code 설치와 사용VS code 홈페이지에서 OS에 맞는 버전을 다운로드 받고 설치합니다. VS code interfaceVS code 기본 인터페이스 입니다. 상세내용은 VS code manual를 참고해 주시기 바랍니다. A(Activity Bar): 스크립트 구조 탐색, search, git, debugging, extensions 화면으로 전환 가능한 tab입니다. B(Side Bar): A의 구체적인 내용을 표시하는 tab입니다. C(Editor): 스크립트 작성/수정하는 메인 화면으로 2개 이상의 editor를 여는 것이 가능합니다. D(Panel): 스크립트 실행 결과, terminal 화면, debug console 등을 출력하는 화면입니다. E(Status Bar): line number, 환경설정, programming language 등 작업중인 파일과 프로젝트에 대한 정보를 출력하는 화면입니다. ExtensionsExtensions는 개발환경을 구성하고 사용자의 편의를 위한 다양한 프로그램을 제공합니다. Activity Bar에서 extentions 버튼을 클릭하거나 ‘ctrl+shift+X’ 단축키를 사용합니다. 유용한 프로그램을 몇 가지 소개합니다. Python: Code 작성 기본 프로그래밍 언어입니다. 비전공자가 배우기 비교적 수월하다는 평가가 많아서 선택했습니다. Extensions: python Markdown All in One: github blog post 작성할 때 사용하는 markup language입니다. Extensions: markdown All in One Visual Studio IntelliCode: Code 작성시 programming language의 자동완성 기능을 제공합니다. Extensions: Visual Code IntelliCode ftp-simple: local PC와 개발서버를 연동할 때 사용하는 프로그램 입니다. Extensions: ftp-simpleLinting Python CodeLinter는 python code를 정해진 규칙에 따라 일관성 있게 작성할 수 있게 도와주는 보조 수단입니다. Code를 분석하여 각종 에러, 버그, 잘못된 문법 구조를 표시해 줍니다. Python code는 ‘PEP8’, docstring은 ‘Google Python Style Guide’를 준수하기 위해 노력합니다.VS Code에서 linter 설정 및 사용법은 다음과 같습니다. 명령창을 활성화 합니다. (ctrl+shift+P) ‘Python: Select Linter’를 검색한 뒤 ‘PEP8’을 선택합니다. Python code를 열고 활성화 합니다. Debug console을 활성화 합니다. (ctrl+shift+D) ‘Start Debugging’ 버튼을 클릭합니다. (F5) Python code에서 ‘PEP8’에 어긋나는 부분은 error 메시지를 출력합니다. 이를 참고하여 알맞게 수정합니다. Error 메시지가 발생하지 않을 때까지 5~6 과정을 반복합니다. LintingPython coding을 위한 기본 VS code 설정을 완료 했습니다." } ]
