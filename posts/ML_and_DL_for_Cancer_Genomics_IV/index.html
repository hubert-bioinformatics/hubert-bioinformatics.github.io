<!DOCTYPE html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="ML and DL for Cancer Genomics IV - DL Algorithm II" /><meta property="og:locale" content="en" /><meta name="description" content="본 post는 국가생명연구자원정보센터(KOBIC) 주관 경희대학교 이과대학 김권일 교수님의 딥러닝 알고리즘 2를 정리한 내용입니다." /><meta property="og:description" content="본 post는 국가생명연구자원정보센터(KOBIC) 주관 경희대학교 이과대학 김권일 교수님의 딥러닝 알고리즘 2를 정리한 내용입니다." /><link rel="canonical" href="/posts/ML_and_DL_for_Cancer_Genomics_IV/" /><meta property="og:url" content="/posts/ML_and_DL_for_Cancer_Genomics_IV/" /><meta property="og:site_name" content="Hubert Effect" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-06-20T12:29:30+09:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="ML and DL for Cancer Genomics IV - DL Algorithm II" /><meta name="twitter:site" content="@twitter_username" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-06-21T09:52:29+09:00","datePublished":"2023-06-20T12:29:30+09:00","description":"본 post는 국가생명연구자원정보센터(KOBIC) 주관 경희대학교 이과대학 김권일 교수님의 딥러닝 알고리즘 2를 정리한 내용입니다.","headline":"ML and DL for Cancer Genomics IV - DL Algorithm II","mainEntityOfPage":{"@type":"WebPage","@id":"/posts/ML_and_DL_for_Cancer_Genomics_IV/"},"url":"/posts/ML_and_DL_for_Cancer_Genomics_IV/"}</script><title>ML and DL for Cancer Genomics IV - DL Algorithm II | Hubert Effect</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Hubert Effect"><meta name="application-name" content="Hubert Effect"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> </a></div><div class="site-title mt-3"> <a href="/">Hubert Effect</a></div><div class="site-subtitle font-italic">Bioinformatics</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a><li class="nav-item"> <a href="/moment/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>MOMENT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/hubert-bioinformatics" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['kjhyug93','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>ML and DL for Cancer Genomics IV - DL Algorithm II</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>ML and DL for Cancer Genomics IV - DL Algorithm II</h1><div class="post-meta text-muted"><div> By <em> <a href="https://twitter.com/username">Jonghyuk Kim</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" data-ts="1687231770" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2023-06-20 </em> </span> <span> Updated <em class="timeago" data-ts="1687308749" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2023-06-21 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="2453 words"> <em>13 min</em> read</span></div></div></div><div class="post-content"><p>본 post는 국가생명연구자원정보센터(KOBIC) 주관 경희대학교 이과대학 김권일 교수님의 <a href="https://www.edwith.org/deep-learning-2023/lecture/1475086," title="딥러닝 알고리즘 2">딥러닝 알고리즘 2</a>를 정리한 내용입니다.</p><h2 id="intro"><span class="mr-2">Intro</span><a href="#intro" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><hr /><p>Machine learning 관련 기초 개념을 확인하고, 공개된 논문내용 및 데이터를 바탕으로 직접 실습하고 학습하는 과정입니다. <br /><br /></p><h2 id="오차-역전파-알고리즘"><span class="mr-2">오차 역전파 알고리즘</span><a href="#오차-역전파-알고리즘" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><hr /><p>최적의 학습 결과를 갖는 neural network를 설계하려면 근본적으로 입력이나 특정 neuron의 weight를 약간 변경시키면 출력에 작은 변화가 일어난다는 점에 근거하고 있습니다. 여기서 activation function으로 쓰이는 sigmoid function은 0에서 1까지 연속적으로 변하는 출력을 갖기 때문에 weight나 bias를 조금 변화시켰을 때 출력이 조금씩 변하도록 만들 수 있습니다.</p><p>Neural network는 backpropagation(역전파)를 통해 “역방향으로 error를 전파”시키면서 최적의 학습 결과를 찾아가는 것이 가능합니다. Backpropagation을 수행하기 위해 사용되는 cost function(loss function)은 다음과 같이 정의됩니다.</p>\[C(w, b) \equiv \frac{1}{2n} \sum_{x}^{} ||y(x) - a||^2\]<p>n은 training에 사용되는 input node의 수</p><p>y(x)는 입력 x를 넣었을 때 기대 출력</p><p>a는 실제 출력</p><p>을 의미합니다. 이를 mean square error (MSE; 평균제곱 오차)라고 부르며, 학습의 최종 목표는 MSE를 최소화하는 것입니다. Cost function에서 예측 값과 label의 오차를 절대값이 아닌 제곱으로 처리하는 이유는 다음과 같습니다.</p><ul><li><p>오차가 큰 경우에 더 큰 가중치를 주어 학습을 빠르게 처리합니다.</p><li><p>MSE를 볼록함수(convex function)로 만들어 최적의 weight를 효과적으로 찾기 위함입니다.</p><li><p>절대값은 미분불가능 수식이기 때문입니다.</p></ul><p>Gradient descent(경사 하강법)을 기반으로 backpropagation을 진행하며 학습을 수행합니다. <br /><br /></p><h2 id="mse와-gradient-descent"><span class="mr-2">MSE와 Gradient Descent</span><a href="#mse와-gradient-descent" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><hr /><p>MSE를 최소로 만드는 w와 b의 해를 찾는 방법입니다. 우선 b를 무시하고 w에 집중해보면, MSE는 w를 중심으로 한 convex function(볼록 함수)입니다. 아래로 볼록한 convex function이며 이 함수의 최소값을 찾는 것, 즉 error를 최소화하는 값을 찾는 과정입니다.</p><ol><li><p>일단 w를 1로 설정합니다.</p><li><p>w=1에서의 접선의 기울기를 계산하면, 최소값으로 가기 위한 방향과 크기를 찾을 수 있습니다.</p><li><p>접선의 방향이 양수가 나온다는 것은 MSE가 양의 방향으로 증가하는 경향을 보인다는 의미합니다.</p><li><p>증가하면 안되니 반대방향으로 가야합니다.</p><li><p>접선 만큼의 크기를 원래 w에서 빼주면 최소값으로 갈 수 있습니다. <br /><br /></p></ol><p><img data-src="/assets/img/post/MLDL4CancerGenome18.png" alt="Post-Image" data-proofer-ignore> <em>Gradient Descent<br /> https://www.edwith.org/deep-learning-2023/lecture/1475086</em> <br /><br /></p><h2 id="gradient-descent를-위한-편미분"><span class="mr-2">Gradient Descent를 위한 편미분</span><a href="#gradient-descent를-위한-편미분" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><hr /><p>Neural network 크기가 커지고 입력이나 출력의 개수가 많아지면 parameter의 수가 너무 많기 때문에 weight와 bias를 조절하여 cost function을 최소화하는 작업이 매우 어렵게 됩니다.</p><p>입력이나 출력의 개수가 많아진 상태에서 weight나 bias 값을 작게 변화시키면, 출력 쪽에서 생기는 변화 역시 매우 작게 생기며, 작은 구간만 놓고 보았을 때 선형적인 관계가 있습니다. 작은 변화의 관점에서는 선형적인 관계이기 때문에, 출력에서 생긴 오차를 반대의 입력 쪽으로 전파시키면서 weight와 bias 등을 갱신합니다.</p><p>Cost function이 weight와 bias의 함수로 이루어졌기 때문에 출력 부분부터 시작해서 입력 쪽으로(역방향으로) 순차적으로 cost function에 대한 편미분을 구하고 여기에서 얻은 편미분 값을 이용하여 weight와 bias 값을 갱신합니다.</p><p>모든 training data에 대해 이 작업을 반복적으로 수행하다 보면, training data에 최적화된 weight와 bias 값들을 얻을 수 있습니다. Backpropagation은 출력부터 반대 방향으로 순차적으로 편미분을 수행해 나가면서 weight와 bias 값들을 갱신시킨다는 의미입니다. <br /><br /></p><p><img data-src="/assets/img/post/MLDL4CancerGenome19.png" alt="Post-Image" data-proofer-ignore> <em>Neural Network에서의 편미분<br /> https://www.edwith.org/deep-learning-2023/lecture/1475086</em> <br /><br /></p><h2 id="backpropagation-상세-chain-rule"><span class="mr-2">Backpropagation 상세: Chain Rule</span><a href="#backpropagation-상세-chain-rule" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><hr /><p>Chain rule을 이용하면 backpropagation 식을 좀 더 쉽게 풀어낼 수 있습니다. 여기서 chain rule이란, 합성함수 y=f(g(x))가 t=g(x), y=f(t)로 분해될 때 다음이 성립함을 나타내는 법칙입니다.</p><p>\(\frac{dy}{dx} = \frac{dy}{dt} \frac{dt}{dx}\) <br /><br /></p><p><img data-src="/assets/img/post/MLDL4CancerGenome20.png" alt="Post-Image" data-proofer-ignore> <em>Backpropagation<br /> https://www.edwith.org/deep-learning-2023/lecture/1475086</em> <br /><br /></p><h2 id="backpropagation-장단점"><span class="mr-2">Backpropagation 장단점</span><a href="#backpropagation-장단점" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><hr /><p>Hornik et al, 1989의 연구에서 hidden node가 충분히 많다면 activation function으로 무엇을 사용하든 multi-layer feedforward neural network는 어떤 함수라도 원하는 정확도만큼 슨사화할 수 있음을 증명했습니다. 그러나 hidden layer의 neuron 개수를 어떻게 설정하느냐는 아직도 해결되지 않은 문제이며, 시행착오 방법에만 의존해서 조정할 수 밖에 없습니다.</p><p>Backpropagation neural network는 강력한 능력으로 인해 overfitting 현상을 자주 겪게 됩니다. 두 가지 전략을 통해 overfitting을 완화시킬 수 있습니다.</p><ol><li><p>Early stopping(조기 종료): Data를 training set과 validation set으로 분리합니다. Training set은 gradient descent를 계산하고 weight와 bias를 갱신하는데 사용합니다. Validation set는 error를 예측하는데 사용되고 만약 training set의 error가 줄어들 때 validation set의 error가 높아진다면 즉시 훈련을 종료하는 방법입니다.</p><li><p>Regularization(정규화): Cost function에 weight와 bias의 제곱합과 같은 network 복잡도를 표현하는 부분을 추가하는 방법입니다. <br /><br /></p></ol><h2 id="deep-learning"><span class="mr-2">Deep Learning</span><a href="#deep-learning" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><hr /><p>이론상으로 parameter 수가 많으면 많을수록 model의 복잡성이 높아지고 예측 및 분류 능력이 커집니다. 이는 아무리 복잡한 학습 문제라도 parameter를 증가시키면 해결이 가능하다는 것을 의미합니다. 그러나 동시에 복잡한 model의 훈련 효과가 좋지 않고 쉽게 overfitting에 빠집니다.</p><p>최근 클라우드 컴퓨터와 빅데이터 시대가 도래하면서 컴퓨터의 능력은 대대적으로 높아졌고 훈련 성능 저하 문제를 완화시켰습니다. 그리고 training data가 많아짐에 따라 overfitting 위험은 대폭 낮아졌습니다. 이에 따라 deep learning을 대표로 하는 복잡한 model들이 사람들의 관심을 받기 시작했습니다. 전형적인 deep learning model은 깊은 층을 쌓은 neural network입니다. Neural network model의 능력을 향상시킬 수 있는 가장 간단한 방법은 hidden layer 개수를 늘리는 것입니다.</p><p>Hidden layer가 많으면 상응하는 neuron 연결 weight, 임계값 등의 parameter 수가 늘어납니다. Model의 복잡성도 단순히 hidden layer neuron 수를 증가시키는 것만으로 늘릴 수 있습니다. 하지만 model의 복잡성을 증가시키는 관점에서 바라보면 hidden layer의 개수를 증가시키는 것이 hidden layer neuron의 수를 증가시키는 것보다 효율적입니다. Hidden layer의 수를 증가시키면 activation function을 가진 neuron의 개수를 늘리게 될 뿐 아니라 activation function이 내장된 층 수도 증가하기 때문입니다.</p><p>그러나 여러 hidden layer를 가진 neural network는 전통적인 algorithm(backpropagation)을 사용하여 훈련시키기 힘든 점이 있습니다. 오차가 hidden layer에서 backpropagation 될 때 vanishing(소실)되어 update 하기 어려운 점이 있기 때문입니다. 이러한 현상을 vanishing gradient라고 합니다. <br /><br /></p><h2 id="global-minimum-and-local-minimum"><span class="mr-2">Global Minimum and Local Minimum</span><a href="#global-minimum-and-local-minimum" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><hr /><p>만약 E로 neural network의 training set에 대한 error를 나타낸다면, 이는 weight와 bias(threshold)에 관한 함수일 것입니다. 이 때 neural network의 훈련 과정은 하나의 parameter 탐색 과정이라고 볼 수 있습니다. 즉, parameter 공간에서 최적의 parameter를 찾아 E를 최소화 하는 것입니다. 여기에는 두 가지 종류의 ‘최적’이 있습니다. 바로 local minimum과 global minimum입니다.</p><p>Local minimum은 parameter 공간의 어떤 점이 되고 주변 점들의 cost function(loss function, error 함수값)이 해당 점의 함수값보다 작으면 안됩니다. 이와 비슷하게 global minimum의 해는 parameter 공간 내의 모든 점들이 error 함수값보다 작지 않다는 것을 의미합니다.</p><p>Gradient descent 방법은 임의의 시작점에서 출발해 반복적으로 최적의 parameter 값을 찾아 나갑니다. 매번 반복할 때마다 우리는 먼저 cost function이 해당 점에서 갖는 기울기를 계산하고 그 기울기에 따라 탐색 방향을 정합니다. 만약 해당 점에서 cost function의 기울기가 0이라면 이미 local minimum에 도달한 것입니다. 이는 parameter 반복 갱신이 그 점에서 멈출 것이라는 의미입니다. 또한 cost function이 하나의 local minimum만을 갖는다면 해당 값이 바로 global minimum이 됩니다. <br /><br /></p><p><img data-src="/assets/img/post/MLDL4CancerGenome22.png" alt="Post-Image" data-proofer-ignore> <em>Local Minimum 함정 탈출 전략<br /> https://www.edwith.org/deep-learning-2023/lecture/1475086</em> <br /><br /></p><h2 id="take-home-message"><span class="mr-2">Take Home Message</span><a href="#take-home-message" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><hr /><p><img data-src="/assets/img/post/MLDL4CancerGenome21.png" alt="Post-Image" data-proofer-ignore> <em>Summary 1<br /> https://www.edwith.org/deep-learning-2023/lecture/1475086</em> <br /><br /></p><p><img data-src="/assets/img/post/MLDL4CancerGenome23.png" alt="Post-Image" data-proofer-ignore> <em>Summary 2<br /> https://www.edwith.org/deep-learning-2023/lecture/1475086</em> <br /><br /></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/bioinformatics/'>Bioinformatics</a>, <a href='/categories/ml/'>ML</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/bi/" class="post-tag no-text-decoration" >BI</a> <a href="/tags/bioinformatics/" class="post-tag no-text-decoration" >bioinformatics</a> <a href="/tags/cancer/" class="post-tag no-text-decoration" >cancer</a> <a href="/tags/ml/" class="post-tag no-text-decoration" >ML</a> <a href="/tags/dl/" class="post-tag no-text-decoration" >DL</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=ML and DL for Cancer Genomics IV - DL Algorithm II - Hubert Effect&amp;url=/posts/ML_and_DL_for_Cancer_Genomics_IV/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=ML and DL for Cancer Genomics IV - DL Algorithm II - Hubert Effect&amp;u=/posts/ML_and_DL_for_Cancer_Genomics_IV/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=/posts/ML_and_DL_for_Cancer_Genomics_IV/&amp;text=ML and DL for Cancer Genomics IV - DL Algorithm II - Hubert Effect" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Certificate_predict_protein_structure_using_alphafold/">(LAIDD) 알파폴드를 이용한 단백질 구조 예측 및 평가</a><li><a href="/posts/Epigenetics1/">Epigenetics I - 후성유전학의 개요</a><li><a href="/posts/Epigenetics6/">Epigenetics VI - 후성유전체 데이터 생산과 분석1</a><li><a href="/posts/AMP_guideline/">AMP Guideline</a><li><a href="/posts/R_for_Bioinformatics_4/">생물정보학을 위한 R프로그래밍 IV - 데이터 취득과 정제</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/certificate/">certificate</a> <a class="post-tag" href="/tags/bioinformatics/">bioinformatics</a> <a class="post-tag" href="/tags/bi/">BI</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/laidd/">LAIDD</a> <a class="post-tag" href="/tags/ngs/">NGS</a> <a class="post-tag" href="/tags/statistics/">statistics</a> <a class="post-tag" href="/tags/kobic/">KOBIC</a> <a class="post-tag" href="/tags/biology/">biology</a> <a class="post-tag" href="/tags/study/">study</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/ML_and_DL_for_Cancer_Genomics_II/"><div class="card-body"> <em class="timeago small" data-ts="1687215432" > 2023-06-20 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ML and DL for Cancer Genomics II - ML Basic Concpts and Evaluation Methods</h3><div class="text-muted small"><p> 본 post는 국가생명연구자원정보센터(KOBIC) 주관 경희대학교 이과대학 김권일 교수님의 기계학습 기초 개념 및 평가 방법을 정리한 내용입니다. Intro Machine learning 관련 기초 개념을 확인하고, 공개된 논문내용 및 데이터를 바탕으로 직접 실습하고 학습하는 과정입니다. 기계학습(Machine Learning)이란? 기계...</p></div></div></a></div><div class="card"> <a href="/posts/ML_and_DL_for_Cancer_Genomics_III/"><div class="card-body"> <em class="timeago small" data-ts="1687229395" > 2023-06-20 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ML and DL for Cancer Genomics III - DL Algorithm I</h3><div class="text-muted small"><p> 본 post는 국가생명연구자원정보센터(KOBIC) 주관 경희대학교 이과대학 김권일 교수님의 딥러닝 알고리즘 1을 정리한 내용입니다. Intro Machine learning 관련 기초 개념을 확인하고, 공개된 논문내용 및 데이터를 바탕으로 직접 실습하고 학습하는 과정입니다. 인공신경망 개념 - Neural network 구조 생물의 neu...</p></div></div></a></div><div class="card"> <a href="/posts/ML_and_DL_for_Cancer_Genomics_V/"><div class="card-body"> <em class="timeago small" data-ts="1687387370" > 2023-06-22 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>ML and DL for Cancer Genomics VI - 딥러닝 구동 환경 구축 1</h3><div class="text-muted small"><p> 본 post는 국가생명연구자원정보센터(KOBIC) 주관 경희대학교 이과대학 김권일 교수님의 딥러닝 구동 환경 구축 1를 정리한 내용입니다. Intro Machine learning 관련 기초 개념을 확인하고, 공개된 논문내용 및 데이터를 바탕으로 직접 실습하고 학습하는 과정입니다. 데이터를 표현하는 방식: 텐서 텐서는 핵심 속성 세 가지를...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/ML_and_DL_for_Cancer_Genomics_III/" class="btn btn-outline-primary" prompt="Older"><p>ML and DL for Cancer Genomics III - DL Algorithm I</p></a> <a href="/posts/ML_and_DL_for_Cancer_Genomics_V/" class="btn btn-outline-primary" prompt="Newer"><p>ML and DL for Cancer Genomics VI - 딥러닝 구동 환경 구축 1</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://twitter.com/username">Jonghyuk Kim</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/certificate/">certificate</a> <a class="post-tag" href="/tags/bioinformatics/">bioinformatics</a> <a class="post-tag" href="/tags/bi/">BI</a> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/laidd/">LAIDD</a> <a class="post-tag" href="/tags/ngs/">NGS</a> <a class="post-tag" href="/tags/statistics/">statistics</a> <a class="post-tag" href="/tags/kobic/">KOBIC</a> <a class="post-tag" href="/tags/biology/">biology</a> <a class="post-tag" href="/tags/study/">study</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
